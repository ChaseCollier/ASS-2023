# Tuesday November 8, 2022 {.unnumbered}

**“Practice any art, music, singing, dancing, acting, drawing, painting, sculpting, poetry, fiction, essays, reportage, no matter how well or badly, not to get money & fame, but to experience becoming, to find out what's inside you, to make your soul grow.”** - Kurt Vonnegut

Today

- Interpolating to areal units
- Simulating spatial fields
- Interpolating multiple variables

## Interpolating to areal units (block kriging) {-}

Interpolating rainfall across Florida from tropical cyclone Fay (2008).

In 2008, Tropical Cyclone Fay formed from a tropical wave near the Dominican Republic, passed over the island of Hispaniola, Cuba, and the Florida Keys, then crossed the Florida peninsula and moved westward across portions of the panhandle producing heavy rains in parts of the state.

Storm total rainfall amounts from stations in and around the state are in `FayRain.txt`. They are compiled reports from official weather sites and many cooperative sites. The cooperative sites are the Community Collaborative Rain, Hail and Snow Network (CoCoRaHS), a community-based, high density precipitation network made up of volunteers who take measurements of precipitation in their backyards. The data were obtained from NOAA/NCEP/HPC and from the Florida Climate Center.

Import the data.
```{r}
L <- "http://myweb.fsu.edu/jelsner/temp/data/FayRain.txt"
( FR.df <- read.table(L, header = TRUE) )
```

The data frame contains 803 rainfall sites. Longitude and latitude coordinates of the sites are given in the first two columns and total rainfall in inches and millimeters are given in the second two columns. Create a spatial points data frame by specifying columns that contain the spatial coordinates. Then assign a geographic coordinate system and convert the rainfall from millimeters to centimeters.
```{r}
library(sf)

FR.sf <- st_as_sf(x = FR.df,
                  coords = c("lon", "lat"),
                  crs = 4326)

FR.sf$tpm <- FR.sf$tpm/10
summary(FR.sf$tpm)
```

The median rainfall amount is 15.8 cm and the highest amount is 60.2 cm. 

We get the Florida county boundaries from the {USAboundaries} package.
```{r}
FL.sf <- USAboundaries::us_counties(states = "Florida")
```

We create a character string specifying the tags for a planar projection and transform the geographic coordinates of the site locations and map polygons to the projected coordinates. Here we use Florida GDL Albers (EPSG:3087) with meter as the distance unit.
```{r}
FR.sf <- st_transform(FR.sf, crs = 3087)
FL.sf <- st_transform(FL.sf, crs = 3087)
```

We make a map of the rainfall sites and storm totals with the state boundaries.
```{r}
library(tmap)

tm_shape(FR.sf) +
  tm_dots(col = "tpm", size = 1) +
tm_shape(FL.sf) +
  tm_borders()
```

Two areas of heavy rainfall are noted.  One running north-south along the east coast and another across the north. Rainfall collection sites are clustered in and around cities. This will make it difficult to use a spline interpolation.

Rainfall is an example of geostatistical data. In principle it can be measured anywhere, but typically we have values at a sample of sites. The pattern of observation sites is not of much interest as it is a consequence of constraints (convenience, opportunity, economics, etc) unrelated to the phenomenon. Interest centers on inference about how much rain fell across the region.

The empirical variogram is computed using the `variogram()` function. The first argument is the model formula specifying the rainfall column from the data frame and the second argument is the data frame name.  Here `~ 1` in the model formula indicates no covariates or trends in the data. Trends can be included by specifying coordinate names through the `st_coordinates()` function.

We compute the empirical variogram for Fay's rainfall and save it by typing
```{r}
library(gstat)

FR.v <- variogram(tpm ~ 1, 
                  data = FR.sf)
```

We plot the variogram values as a function of lag distance and add text indicating the number of point pairs for each lag distance.
```{r}
library(ggplot2)

v.df <- data.frame(dist = FR.v$dist/1000,
                   gamma = FR.v$gamma,
                   np = FR.v$np)

( pv <- ggplot(v.df, aes(x = dist, y = gamma)) +
  geom_point() +
  geom_text(aes(label = np), nudge_y = -5) +
  scale_y_continuous(limits = c(0, 220)) +
  scale_x_continuous(limits = c(0, 400)) +
  xlab("Lagged distance (h) [km]") +
  ylab(expression(paste("Semivariance (", gamma, ") [", cm^2, "]"))) +
  theme_minimal() )
```

Values start low (~50 cm$^2$) at short lag distance, then increase to over 200 cm$^2$ at lag distance of about 200 km.

The zero-lag semivariance is called the 'nugget' and the semivariance at a level where the variogram values no longer increase is called the 'sill.'  The lag distance to the sill is called the 'range.'  These three parameters (nugget, sill, and range) are used to fit a model to the variogram.

Next we fit a model to the empirical variogram. The variogram model is a mathematical relationship defining the semivariance as a function of lag distance. We first save the family and the initial parameter guesses in a variogram model (`FR.vmi`) object by typing
```{r}
FR.vmi <- vgm(model = "Gau", 
              psill = 150, 
              range = 200 * 1000, 
              nugget = 50)
FR.vmi
```

The `psill` argument is the partial sill as the difference between the sill and the nugget. We get estimates of the parameter values from looking at the empirical variogram. 

Next we use the `fit.variogram()` function to improve the fit.  Given a set of initial parameter values, the method of weighted least squares improves the parameter estimates. Ordinary least squares is not appropriate as the semivariances are correlated across the lag distances and the precision on the estimates varies depending on the number of site pairs for a given lag.
```{r}
FR.vm <- fit.variogram(object = FR.v, 
                       model = FR.vmi)
FR.vm
```

The result is a variogram model with a nugget of 46.8 cm$^2$, a partial sill of 157 cm$^2$, and a range on the sill of 129 km. 

Let $r$ be the range, $c$ the partial sill and $c_o$ the nugget, then the equation defining the curve over the set of lag distances $h$ is
$$
\gamma(h)=c\left(1-\exp\left(-\frac{h^2}{r^2}\right)\right)+c_o
$$

We create a data frame with values of h and gamma using this equation.
```{r}
nug <- FR.vm$psill[1]
ps <- FR.vm$psill[2]
r <- FR.vm$range[2] / 1000
h <- seq(0, 400, .2)
gamma <- ps * (1 - exp(-h^2 / (r^2))) + nug

vm.df <- data.frame(dist = h,
                    gamma = gamma)

pv + geom_line(aes(x = dist, y = gamma), data = vm.df)
```

Check for anisotropy.
```{r}
plot(variogram(tpm ~ 1, 
               data = FR.sf, 
               alpha = c(0, 45, 90, 135)), 
     xlab = "Lag Distance (m)")
```

We see the range of correlations is longer (about 300 km) in the north-south direction (0 degrees). 

Another way to look at directional dependence in variograms is through variogram maps. Instead of classifying point pairs Z(s) and Z(s + h) by direction and distance class separately, you can classify them jointly.

If h = {x, y} is the two-dimensional coordinates of the separation
vector, in the variogram map the semivariance contribution of each point pair (Z(s) − Z(s + h))^2 is attributed to the grid cell in which h lies. The map is centered around (0, 0), as h is distance rather than location. Cutoff and width correspond to some extent to map extent and cell size; the semivariance map is point symmetric around (0, 0), as γ(h) = γ(−h).

```{r}
vgm.map <- variogram(log(zinc) ~ sqrt(dist), 
                     meuse, 
                     cutoff = 1500, 
                     width = 100,
                     map = TRUE)
plot(vgm.map, threshold = 5)
```

We refit the variogram defining an anistropy ellipse with the `anis =` argument. The first parameter is the direction of longest range and the second parameter is the ratio of the longest to shortest. Here about (200/300 = .67).
```{r}
FR.vmi <- vgm(model = "Gau", 
              psill = 150, 
              range = 300 * 1000, 
              nugget = 50,
              anis = c(0, .67))
FR.vm <- fit.variogram(FR.v, FR.vmi)
```

In the final step we use the variogram model together with the rainfall values at the observation sites to create an interpolated surface. Here we use _ordinary_ kriging as there are no spatial trends in the rainfall.

Interpolation is done using the `krige()` function. The first argument is the model specification and the second is the data. Two other arguments are needed. One is the variogram model using the argument name model and the other is a set of locations identifying where the interpolations are to be made. This is specified with the argument name `newdata =`.

Here we interpolate to locations on a regular grid. We create a grid of locations within the boundary of Florida using the `st_sample()` function.
```{r}
grid.sf <- st_sample(FL.sf,
                     size = 5000,
                     type = "regular")
```

We specify the number of locations using the argument `size =`. Note that the actual number of locations will be somewhat different because of the irregular boundary. 

First we use the `krige()` function to interpolate the observed rainfall to the grid locations. Recall that for a given location, the interpolation is a weighted average of the rainfall across the entire region where the weights are determined by the variogram model.
```{r}
ipl <- krige(tpm ~ 1, 
             locations = FR.sf, 
             newdata = grid.sf,
             model = FR.vm)
```

If the variogram model is not included then inverse distance weighted interpolation is performed. The function will not work if different values share the same location. 

The saved object (`ipl`) inherits the spatial object specified in the `newdata` argument, but extends it to a spatial data frame. The data frame with two variables.  The first `var1.pred` is the interpolated rainfall and the second `var1.var` is the prediction variance.

We plot the interpolated field.
```{r}
tm_shape(ipl) +
  tm_dots("var1.pred",
          size = .1,
          palette = "Greens",
          title = "Rainfall (cm)") +
  tm_shape(FL.sf) +
  tm_borders() +
  tm_layout(legend.position = c("left", "bottom"),
            title = "Tropical Cyclone Fay (2008)",
            title.position = c("left", "bottom"),
            legend.outside = TRUE)
```

Note: a portion of the data locations are outside of the state but our interest is only to have values on a grid within the state. 

The spatial interpolation shows that parts of east central and north Florida were deluged by Fay.

We use _block_ kriging to estimate average rainfall within each county. The county-wide rainfall average is relevant for water resource managers. Block kriging produces a smoothed estimate of this area average, which will differ from a simple average over all sites within the county because of spatial autocorrelation.

We use the same function to interpolate but specify the spatial polygons rather than the spatial grid as the new data.
```{r}
ipl2 <- krige(tpm ~ 1, 
              locations = FR.sf, 
              newdata = FL.sf, 
              model = FR.vm)
```

Again we plot the interpolations.
```{r}
tm_shape(ipl2) +
  tm_polygons(col = "var1.pred",
            palette = "Greens",
            title = "Rainfall (cm)") +
  tm_layout(legend.position = c("left", "bottom"),
            title = "Tropical Cyclone Fay (2008)",
            title.position = c("left", "bottom"))
```

The overall pattern of rainfall from Fay featuring the largest amounts along the central east coast and over the eastern panhandle are similar in both maps.

We compare the kriged average with the simple average at the county level with `aggregate()` from the {sf} package.
```{r}
ipl3 <- aggregate(FR.sf, 
                  by = FL.sf, 
                  FUN = mean)
```

The function returns a simple feature data frame of the average rainfall in each county.

The state-wide mean of the kriged estimates at the county level is 
```{r}
round(mean(ipl2$var1.pred), 2)
```

This compares with a state-wide mean from the simple averages.
```{r}
round(mean(ipl3$tpm), 2)
```

The correlation between the two estimates across the 67 counties is 
```{r}
round(cor(ipl3$tpm, ipl2$var1.pred), 2)
```

The variogram model reduces the standard deviation of the kriged estimate relative to the standard deviation of the simple averages because of the local smoothing.
```{r}
round(sd(ipl2$var1.pred), 2)
round(sd(ipl3$tpm), 2)
```

This can be seen with a scatter plot of simple averages versus kriged averages at the county level.
```{r}
compare.df <- data.frame(simpleAvg = ipl3$tpm,
                         krigeAvg = ipl2$var1.pred)
ggplot(compare.df, aes(x = simpleAvg,
                       y = krigeAvg)) +
  geom_point() +
  geom_abline(slope = 1) +
  geom_smooth(method = lm, se = FALSE)
```

An advantage of kriging as a method of spatial interpolation is the accompanying uncertainty estimates. The prediction variances are listed in a column in the spatial data frame saved from apply the `krige()` function. Variances are smaller in regions with more rainfall observations.  

Prediction variances are also smaller with block kriging as much of the variability within the county averages out. To compare the distribution characteristics of the prediction variances for the point and block kriging of the rainfall observations, type
```{r}
round(summary(ipl$var1.var), 1)
round(summary(ipl2$var1.var), 1)
```

The median prediction variance (in cm$^2$) for our point kriging is close to the value of the nugget.
```{r}
round(fivenum(ipl$var1.var)[3], 1)
```

In contrast the median prediction variance for our block kriging is a much smaller 
```{r} 
round(fivenum(ipl2$var1.var)[3], 1)
```

## Simulating spatial fields {-}

Simulations exploit this uncertainty and provide synthetic data for use in deterministic models. 

Conditional simulation, where the simulated field (realization) is generated given the data and the variogram model, is done using the same `krige()` function by adding the argument `nsim =` to specify the number of simulations.  

For a large number it may be necessary to limit the number neighbors in the kriging. This is done using the `nmax` argument. For a given location, the weights assigned to observations far away are very small, so it is efficient to limit how many are used in the simulation.

As an example, here we generate four realizations of the county-level storm total rainfall for Fay and limit the neighborhood to 50 of the closest observation sites. Note that it may take a few seconds.
```{r}
ipl.sim <- krige(tpm ~ 1, 
                 locations = FR.sf, 
                 newdata = FL.sf, 
                 model = FR.vm, 
                 nsim = 4, 
                 nmax = 50)
```

Simulations are conditional on the observed rainfall and the variogram model using block kriging on the counties.
```{r}
library(tmap)

tm_shape(ipl.sim) +
    tm_polygons(col = c("sim1", "sim2", "sim3", "sim4"),
                palette = "Greens",
                title = "Simulated Rainfall [cm]") +
    tm_facets(free.scales = FALSE) 
```

The overall pattern of rainfall remains the same, but there are differences especially in counties with fewer observations and in counties where the rainfall gradients are sharp.

Unconditional simulation (see Section 4 https://www.r-bloggers.com/2022/03/gaussian-simulation-of-spatial-data-using-r/)

## Interpolating multiple variables {-}

Statistical interpolation can be extended to obtain surfaces of multiple field variables. The idea is that if two field variables are correlated then information about the spatial correlation in one field variable can help provide information about values in the other field variable. The spatial variability of one variable is correlated with the spatial variability of the other variable. And this idea is not limited to only two variables. 

Here we consider data measuring concentrations of heavy metals in the flood plain of the Meuse River in Holland. The data are available in the {sp} package.
```{r}
library(gstat)
library(sf)
library(sp)

data(meuse)
names(meuse)

meuse.sf <- st_as_sf(x = meuse,
                    coords = c("x", "y"),
                    crs = 28992)
```

Suppose we are interested in the spatial distribution of all the heavy metals in the soils along the river.

First we need to organize the data as a `gstat` object. This is done with the `gstat()` function which orders (and copies) the field variables into a single object. It is done successively with the `gstat()` function.

Here we specify the trend using the square root of the distance to river as we did previously.
```{r}
g <- gstat(NULL, "logCd", log(cadmium) ~ sqrt(dist), meuse.sf)
g <- gstat(g, "logCu", log(copper) ~ sqrt(dist), meuse.sf)
g <- gstat(g, "logPb", log(lead) ~ sqrt(dist), meuse.sf)
g <- gstat(g, "logZn", log(zinc) ~ sqrt(dist), meuse.sf)
g
```

Next we use the `variogram()` function to compute empirical variograms. The function, when operating on a `gstat` object, computes all direct and cross variograms.
```{r}
v <- variogram(g)
plot(v)
```

The plot method displays the set of direct and cross variograms. The direct variograms are shown in the four panels along the diagonal of the triangle of plots.

The cross variograms are shown in the six panels below the diagonal. For example, the cross variogram between the values of cadmium and copper is given in the second row of the first column. 

Note: The cross variogram is analogous to the `Kcross()` function from the {spatstat} package.

Next we use `fit.lmc()` to fit separate models to each of the empirical variograms. We use an initial partial sill and nugget equal to one and a range of 800.
```{r}
vm <- fit.lmc(v, g, 
              vgm(psill = 1, model = "Sph", 
              range = 800, nugget = 1))
plot(v, vm)
```

As the variograms indicate, the variables have a strong cross correlations. Because these variables are co-located, we can also compute direct correlations.
```{r}
cor(meuse[c("cadmium", "copper", "lead", "zinc")])
```

The correlation matrix confirms strong cross correlation among the four variables at zero lag. The cross variogram generalizes these correlations across lag distance.

Given the variogram models, cokriged maps are produced using the `predict()` method after setting the grid locations for interpolation. The CRS for the grid locations matches the CRS of the data.
```{r}
data(meuse.grid)

grid.sf <- st_as_sf(x = meuse.grid,
                    coords = c("x", "y"),
                    crs = 28992)

cok <- predict(vm, grid.sf)
names(cok)
```

The predictions for logarithm of zinc concentration are plotted.
```{r}
library(tmap)

tm_shape(cok) +
  tm_dots(col = "logZn.pred", size = .2)
```

Compare with predictions using only zinc.
```{r}
v2 <- variogram(log(zinc) ~ sqrt(dist), 
                data = meuse.sf)
vm2 <- fit.variogram(v2, vgm(psill = .15, model = "Sph", 
                             range = 800, nugget = .1))
uk <- krige(log(zinc) ~ sqrt(dist), meuse.sf, newdata = grid.sf, 
              model = vm2)

tm_shape(uk) +
  tm_dots(col = "var1.pred", size = .2)
```

The predicted co-variances between zinc and cadmium are plotted.
```{r}
tm_shape(cok) +
  tm_dots(col = "cov.logCd.logZn", size = .2)
```

The map shows areas of the flood plain with high (and low) correlations between cadmium and zinc.

Obtaining a quality statistical spatial interpolation is a nuanced process but with practice kriging can be an important tool in your toolbox.

Kriging is super useful tool for ‘filling in the gaps’ between sampling sites. Handy if you want to make a map, or need to match up two spatial data sets that overlap in extent, but have samples at different locations.