# Thursday February 23, 2023 {-}

**"We build our computer systems the way we build or cities; over time, without plan, on top of ruins."** â€“ Ellen Ullman

## Fitting and interpreting spatial regression models {-}

Always start with an OLS regression model. Returning to the crime data at the tract level in the city of Columbus, Ohio

```{r}
CC.sf <- sf::st_read(dsn = here::here("data", "columbus"),
                     layer = "columbus")
```

`CRIME` is the response variable and `INC` and `HOVAL` as the explanatory variables. How well do these two explanatory variables statistically explain the amount of crime at the tract level?

Set the formula, then use the formula as the first argument in the `lm()` function. Summarize the results with the `summary()` method

```{r}
f <- CRIME ~ INC + HOVAL

model.ols <- lm(f, 
                data = CC.sf)

model.ols |>
  summary()
```

The model explains 55% of the variation in crime as is seen by looking at the multiple R-squared value

The marginal effect of income on crime is -1.6 and the marginal effect of housing value on crime is -.27

A nice way to visualize the relative significance of the explanatory variables is to make a plot. Here you use the `broom::tidy()` method and then `ggplot()` as follows. Note you don't plot the intercept term (the first row) so you use -1 in the row dimension of the subset operation

```{r}
( d <- broom::tidy(model.ols, 
                   conf.int = TRUE) )

library(ggplot2)

ggplot(d[-1,], aes(x = estimate, 
                   y = term, 
                   xmin = conf.low, 
                   xmax = conf.high, 
                   height = 0)) +
  geom_point(size = 2) +
  geom_vline(xintercept = 0, lty = 4) +
  geom_errorbarh()
```

The maximum likelihood estimate is shown as a point and the confidence interval around the estimate is shown as a horizontal error bar. The default confidence level is 95% (`conf.level = .95`). The effects are statistically significant as the confidence intervals do not intersect the vertical line (dashed-dotted) at the value of 0

Next you check the model residuals for spatial autocorrelation. To determine the amount of autocorrelation in the residuals use the `spdep::lm.morantest()` function, passing the regression model object and the weights object to it. Note that here again use the default neighborhood and weighting schemes to generate the weights matrix `wts`

```{r}
wts <- CC.sf |>
  spdep::poly2nb() |>
  spdep::nb2listw()

model.ols |>
  spdep::lm.morantest(listw = wts)
```

The model residuals have significant spatial autocorrelation so reporting the marginal effects with an OLS regression model is incorrect

Instead, you fit a spatially-lagged Y model using the `lagsarlm()` function from the {spatialreg} package. The model is 

$$
y = \rho W y + X \beta + \varepsilon
$$ 

where $Wy$ is the weighted average of the neighborhood response values (spatial lag variable) with $W$ the spatial weights matrix, and $\rho$ is the autoregression coefficient

The `spatialreg::lagsarlm()` function first determines a value for $\rho$ ( with the internal `optimize()` function) and then the $\beta$'s are obtained using generalized least squares (GLS). The model formula `f` is the same as what you used to fit the OLS regression above. You save the model object as `model.slym`

```{r}
model.slym <- spatialreg::lagsarlm(formula = f, 
                                   data = CC.sf, 
                                   listw = wts)

model.slym |>
  summary()
```

The first batch of output concerns the model residuals (observed crime rates minus predicted rates). The range (maximum minus minimum) of residuals is slightly smaller than with the OLS model. 

Next is the table of coefficients on the explanatory variables. The coefficients on income and housing have the same sign (negative) and they remain statistically significant (-1.05 for income and -.27 for housing value). But you can't interpret these coefficients as the marginal effects

The next set of output is about the coefficient of spatial autocorrelation ($\rho$). The value is .423 and a likelihood ratio test gives a value of 9.41 which translates to a $p$-value of .002. The null hypothesis is the autocorrelation is zero, so you confidently reject it. This is consistent with the significant Moran's I value that you found in the residuals of the OLS model

Two other statistical tests are performed on the value of $\rho$ including a z-test (t-test) using the asymptotic standard error and a Wald test. Both tests confirm (small $p$-values) that the lag term should be included in the model from crime involving income and housing values

In spatial models that contain a lagged response term, the coefficients are not marginal effects. The spatial lag model allows for 'spillover'. That is a change in an explanatory variable ($X_i$) anywhere in the study domain will affect the value of the response variable *everywhere* ($y_j$)

$$ \partial y_j / \partial X_i \ne 0$$
which implies in this case a spillover/impact from housing values in region $i$ impacts the crime in region $j$

Spillover occurs even when the neighborhood weights matrix represents only local contiguity. If the non-zero cross-partial derivative implies an impact on neighboring regions that do not involve endogenous feedback, then it is called a _local_ spillover

In most applied regional modeling situations you know from substantive or theoretical aspects of the problem that a local spillover specification is appropriate. Examples: cross-border shopping for cigarettes to avoid local taxes, crossing school districts for 'better' schools. The key idea for local spillover is that endogenous interaction and feedbacks are not present

The spillover makes interpreting the coefficients more complicated

With a spatially-lagged Y model a change in the value of an explanatory variable results in both *direct* and *indirect* effects on the response variable

For example, the direct effect gives the impact a change in income has on crime averaged over all tracts. It takes into account the effects from a change in the $i$th tract's income on crime across neighboring tracts

The indirect effect gives the impact a change in income has on crime averaged over all *other* tracts. The indirect effect represent spillovers. The influences on the dependent variable $y$ in a region rendered by change in $X$ in some *other* region. For example, if all tracts $i \ne j$ (i not equal to j) increase their income, what will be the impact on crime in region $j$?

The total effect (TE) is the sum of the direct and indirect effects. It measures the total cumulative impact on crime arising from one tract $j$ increasing its income over all other tracts (on average). It is given by 

$$
\hbox{TE} = \left(\frac{\beta_k}{1-\rho^2}\right)\left(1 + \rho\right)
$$ 

where $\beta_k$ is the effect of variable $k$ and $\rho$ is the spatial autocorrelation coefficient. With $\rho = 0$ TE is $\beta_k$

Here $\beta_{INC}$ is -1.0487 and $\rho$ is .4233, so the total effect is

```{r}
( TE_INC <- -1.0487 / (1 - .4233^2) * (1 + .4233) )
```

The direct, indirect, and total effects are shown using the `spatialreg::impacts()` function

```{r}
model.slym |> 
  spatialreg::impacts(listw = wts)
```

The direct effects are the changes in the response variable of a particular region arising from a one unit increase in an explanatory variable in that region

The indirect effects are the changes in the response variable of a particular region arising from a one unit increase in an explanatory variable in another region. For example, due to spatial autocorrelation, a one-unit change in the income variable in region 1 affects the crime rate in regions 2 and 3

The next set of output concerns the overall model fit. It includes the log likelihood value and the AIC (Akaike Information Criterion). The AIC value for the linear model is included. Here it is clear that the spatial lag model is an improvement (smaller AIC) over the aspatial (OLS) model

The larger the likelihood, the better the model and two times the difference in log likelihoods from two competing models divided by the number of observations gives a scale for how much improvement

```{r}
x <- 2 * (logLik(model.slym) - logLik(model.ols))/49
x[1]
```

Improvement table

| Likelihood difference | Qualitative improvement |
|-----------------------|-------------------------|
| 1                     | huge                    |
| .1                    | large                   |
| .01                   | good                    |
| .001                  | okay                    |

The final bit of output is a Lagrange multiplier test for remaining autocorrelation. The null hypothesis is there is no remaining autocorrelation since we have a lag term in the model. The result is a high $p$-value so you are satisfied that the lag term takes care of the autocorrelation

Compare the spatial lag model to a spatial error model. Here you use the `spatialreg::errorsarlm()` function

```{r}
model.sem <- spatialreg::errorsarlm(formula = f, 
                                    data = CC.sf, 
                                    listw = wts)
summary(model.sem)
```

You find the coefficient of spatial autocorrelation ($\lambda$) is significant, but the log likelihood value from the model is smaller (-183.7) and the AIC value is larger (377.5) compared with corresponding values from the lag model

Also you can compare the log likelihoods from the two spatial regression models that you fit

```{r}
x <- 2 * (logLik(model.slym) - logLik(model.sem))/49
x[1]
```

With a value of .04 you conclude that there is good improvement of the lag model over the error model. Again, this is consistent with your decision above to use the lag model

With the spatial error model the coefficients can be interpreted as marginal effects like with the OLS model

If there are large differences (e.g., different signs) between the coefficient estimate from SEM and OLS, this suggests that neither model is yielding parameters estimates matching the underlying parameters of the data generating process

You test whether there is a significant difference in coefficient estimates with the Hausman test under the hypothesis of no difference

```{r}
spatialreg::Hausman.test(model.sem)
```

The $p$-value gives inconclusive evidence that the coefficients are different and that maybe the SEM is not the right way to proceed with these data

The `predict()` method implements the `predict.sarlm()` function to calculate predictions from the spatial regression model. The prediction on a spatial lag Y model is decomposed into a "trend" term (explanatory variable effect) and a "signal" term (spatial smoother). The predicted fit is the sum of the trend and the signal terms when using the spatial lag model

You make predictions with the `predict()` method under the assumption that the mean response is known. You examine the structure of the corresponding predict object

```{r}
( predictedValues <- predict(model.slym) )
```

The predicted values are in the column labeled `fit`. The predicted values are a sum of the trend term ($X\beta$) and the signal term ($\rho W y$). The signal term is called the spatial smoother

As a first-order check if things are what you think they are, compare the first five predicted values with the corresponding observed values

```{r}
predictedValues[1:5]
CC.sf$CRIME[1:5]
```

Some predicted values are lower than the corresponding observed values and some are higher

The predicted values along with the values for the trend and signal are added to the simple features data frame

```{r}
CC.sf$fit <- as.numeric(predictedValues)
CC.sf$trend <- attr(predictedValues, "trend")
CC.sf$signal <- attr(predictedValues, "signal")
```

You plot the observed versus the predicted as a scatter plot with a y = x line and a best-fit regression line

```{r}
ggplot(data = CC.sf,
       mapping = aes(x = CRIME, y = fit)) +
  geom_point() +
  geom_smooth(method = lm, se = FALSE, color = "red") +
  geom_abline() +
  scale_x_continuous(limits = c(0, 70)) +
  scale_y_continuous(limits = c(0, 70)) +
  xlab("Observed Crime") +
  ylab("Predicted Crime")
```

The components of the predictions are mapped and placed on the same plot

```{r}
( g1 <- ggplot() +
    geom_sf(data = CC.sf, aes(fill = fit)) +
    scale_fill_viridis_c() +
    ggtitle("Predicted Crime") )

( g2 <- ggplot() +
    geom_sf(data = CC.sf, aes(fill = trend)) +
    scale_fill_viridis_c() +
    ggtitle("Trend (Explanatory Variables)") )

( g3 <- ggplot() +
    geom_sf(data = CC.sf, aes(fill = signal)) +
    scale_fill_viridis_c() +
    ggtitle("Signal") )

library(patchwork)
g1 + g2 + g3
```

The trend term and the spatial smoother have similar ranges indicating nearly equal contributions to the predictions. The largest difference between the two terms occurs in the city's east side

A map of the difference makes this clear

```{r}
CC.sf <- CC.sf |>
  dplyr::mutate(CovMinusSmooth = trend - signal)

tmap::tm_shape(CC.sf) +
  tmap::tm_fill(col = "CovMinusSmooth")
```

How many tracts have a smaller residual with the lag model versus the OLS model?

```{r}
CC.sf |>
  dplyr::mutate(residualsL = CRIME - fit,
                lagWins = abs(residuals(model.ols)) > abs(residualsL),
                CovMinusSmooth = trend - signal) |>
  sf::st_drop_geometry() |>
  dplyr::summarize(N = sum(lagWins))
```

In 32 out of the 49 tracts the residuals from the spatial model are smaller than the residuals from the OLS model

Another spatial regression option is to modify the linear model to include spatially-lagged explanatory variables. This is called the spatially-lagged X model

$$
y = X \beta + XW \theta + \varepsilon
$$

In this case the weights matrix is (post) multiplied by the matrix of X variables where $W$ is again the weights matrix and $\theta$ is a vector of coefficients for each lagged explanatory variable

Here you fit the spatially-lagged X model using the `spatialreg::lmSLX()` function and save the model object as `model.slxm`

```{r}
( model.slxm <- spatialreg::lmSLX(formula = f, 
                                  data = CC.sf, 
                                  listw = wts) )
```

With this model, beside the direct marginal effects of income and housing value on crime, you also have the spatially-lagged indirect effects

The total effect of income on crime is the sum of the direct effect and indirect effect. And again, using the `spatialreg::impacts()` function you see this

```{r}
model.slxm |>
  spatialreg::impacts(listw = wts)
```

You get the impact measures and their standard errors, z-values and $p$-values with the `summary()` method applied to the output of the `impacts()` function

```{r}
model.slxm |>
  summary(listw = wts)
```

Results show that income has a significant direct *and* indirect effect on crime rates, but housing values only show a significant direct effect and not a significant indirect effect

Again you visualize the relative significance of the effects

```{r}
model.slxm |>
  broom::tidy(conf.int = TRUE) |>
  dplyr::slice(-1) |>
ggplot(aes(x = estimate,
                   y = term, 
                   xmin = conf.low, 
                   xmax = conf.high, 
                   height = 0)) +
  geom_point(size = 2) +
  geom_vline(xintercept = 0, lty = 4) +
  geom_errorbarh()
```

Compare R squared values between the OLS model and the spatially-lagged X model

```{r}
summary(model.ols)$r.squared
summary(model.slxm)$r.squared
```

The spatially lagged model has an R squared value that is higher than the R squared value from the linear regression

Another way to find the correct spatial model is to consider both the spatial Durbin error model and the spatial Durbin model

The spatial Durban error model (SDEM) is a spatial error model with a spatially-lagged X term added

To fit a SDEM use the `spatialreg::errorsarlm()` function but include the argument `etype = "emixed"` to ensure that the spatially lagged X variables are added and the lagged intercept term is dropped when the weights style is row standardized (`"W"`)

```{r}
( model.sdem <- spatialreg::errorsarlm(formula = f, 
                                       data = CC.sf, 
                                       listw = wts,
                                       etype = "emixed") )
```

The spatial Durban model (SDM) is a spatially-lagged Y model with a spatially-lagged X term added to it

To fit a SDM use the `lagsarlm()` function but include the argument `type = "mixed"` to ensure that the spatially lagged X variables are added and the lagged intercept term is dropped when the weights style is row standardized (`"W"`)

```{r}
( model.sdm <- spatialreg::lagsarlm(formula = f, 
                                    data = CC.sf, 
                                    listw = wts,
                                    type = "mixed") )
```

How to do you choose between these two models? Is the relationship between crime and income and housing values a global or local effect? Is there any reason to think that if something happens in one tract it will spillover across the entire city? If crime happens in one tract does it influence crime across the entire city? If so, then it is a global relationship. 

Or might it be a more local effect? If there is more crime in one tract then maybe that influences crime in the neighboring tract but not tracts farther away. If so, then it is a local relationship

If you think it is a local relationship, start with the spatial Durbin error model and look at the $p$-values on the direct and indirect effects

```{r}
summary(spatialreg::impacts(model.sdem, 
                            listw = wts, 
                            R = 500), zstats = TRUE)
```

You see that income has a statistically significant direct and indirect effect on crime. This means that tracts with higher income have lower crime and tracts whose *neighboring tracts* have higher income also have lower crime

On the other hand, housing values have only a statistically significant direct effect on crime. Tracts with more expensive houses have lower crime but tracts whose neighboring tracts have more expensive houses do not imply lower crime. And the total effect of housing values on crime across the city is not significant. So if housing values go up in tracts citywide, there is no statistical evidence that crime will go down (or up)

Try a likelihood ratio test with the null hypothesis being that you should restrict the model

```{r}
spatialreg::LR.Sarlm(model.sdem, 
                     model.slxm)
```

The relatively small $p$-value suggests you shouldn't restrict the spatial Durbin model to just the spatially-lagged X model although the evidence is not overwhelming

More information:

-   <https://youtu.be/b3HtV2Mhmvk> Video explaining the types of spatial regression models and how to implement them in R
-   <https://rrs.scholasticahq.com/article/8081-what-regional-scientists-need-to-know-about-spatial-econometrics> What Regional Scientists Need to Know About Spatial Econometrics