---
output: html_document
editor_options: 
  chunk_output_type: inline
---
# Tuesday November 8, 2022 {.unnumbered}

**"Weeks of coding can save you hours of planning."** - Unknown

Today

- Limitations of distance functions
- Modeling point pattern data 
- Fitting and interpreting an inhibition model
- Fitting and interpreting a cluster model

## Limitations of the distance functions {.unnumbered}

The distance functions ($G$, $K$, etc) used in quantifying clustering are defined and estimated under the assumption that a stationary process produced the events. If this assumption is true then you can treat any sub-region of the domain as an independent and identically distributed (iid) sample from the entire domain.

If the spatial distribution of the locations is influenced by event interaction then the distance curves will deviate from the CSR model curves. 

Two points to keep in mind:

(1) A deviation from CSR detected by an distance function does not necessarily imply event interaction. Rather it could be the result of a non-stationary process.

(2) A distance function characterizes the spatial arrangement of event locations 'on average' so variations in an interaction as a function of scale might be interpreted as CSR.

As an example of this second point, here you generate event locations at random with _clustering_ on a small scale and with _regularity_ on a larger scale. On average the event locations will be indistinguishable from CSR, here as indicated by the $K$ function.

```{r}
library(spatstat)

set.seed(0112)

X <- rcell(nx = 15)
X |>
  plot(main = "")
```

There are two 'local' event clusters one in the north and one in the south. But overall the events appear to be separated from each other more than you might expect by chance.

Based on the $K$ curve you would conclude that the process generating the events is homogeneous Poisson.

```{r}
library(ggplot2)

X |>
  Kest() |>
  as.data.frame() |>
ggplot(mapping = aes(x = r, y = iso)) +
  geom_line() +
  geom_line(aes(y = theo), color = "red") +
  xlab("Lag distance (km)") + ylab("K(r)") +
  theme_minimal()
```

The empirical curve (black line) coincides with the theoretical CSR line (red line) indicating CSR.

And the maximum absolute deviation test under the null hypothesis of CSR returns a large $p$-value so you fail to reject the null.

```{r}
X |>
  mad.test(fun = Kest, 
           nsim = 99)
```

As an example of the first point, here you generate event locations that have no inter-event interactions but instead there is a trend in the spatial intensity.

```{r}
X <- rpoispp(function(x, y){ 300 * exp(-3 * x) })

X |>
  plot(main = "") 
```

By design there is a clear trend toward fewer events moving toward the east.

You compute and plot the $K$ function on these event locations.

```{r}
library(ggplot2)

X |>
  Kest() |>
  as.data.frame() |>
ggplot(mapping = aes(x = r, y = iso)) +
  geom_line() +
  geom_line(aes(y = theo), color = "red") +
  xlab("Lag distance (km)") + ylab("K(r)") +
  theme_minimal()
```

The $K$ function indicates clustering but this is an artifact of the trend in the intensity.

In the case of a known trend in the spatial intensity, you need to use the `Kinhom()` function. For example, compare the uncertainty envelopes from a homogeneous and inhomogeneous Poisson process.

Start by plotting the output from the `envelope()` function with `fun = Kest`. The `global = TRUE` argument indicates that the envelopes are simultaneous rather than point-wise (`global = FALSE` which is the default). Point-wise envelopes assume the estimates are independent (not always a good assumption) across the range of distances so the standard errors will be smaller resulting in narrower bands.

```{r}
envelope(X, 
         fun = Kest, 
         nsim = 999, 
         rank = 1, 
         global = TRUE) |>
  as.data.frame() |>
ggplot(mapping = aes(x = r, y = obs)) +
  geom_ribbon(mapping = aes(ymin = lo, ymax = hi), 
              fill = "gray70") +
  geom_line() +
  geom_line(mapping = aes(y = theo), 
            color = "red", lty = 'dashed') +
  xlab("Lag distance (km)") + ylab("K(r)") +
  theme_minimal()
```

After a distance of about .15 units the empirical curve (black line) is outside the uncertainty band indicating the events are more clustered than CSR.

However when you use the `fun = Kinhom` the empirical curve is completely inside the uncertainty band.

```{r}
envelope(X, 
         fun = Kinhom, 
         nsim = 999, 
         rank = 1, 
        global = TRUE) |>
  as.data.frame() |>
ggplot(mapping = aes(x = r, y = obs)) +
  geom_ribbon(mapping = aes(ymin = lo, ymax = hi), 
              fill = "gray70") +
  geom_line() +
  geom_line(mapping = aes(y = theo), 
            color = "red", lty = 'dashed') +
  xlab("Lag distance (km)") + ylab("K(r)") +
  theme_minimal()
```

You conclude that the point pattern data are more consistent with an inhomogeneous Poisson process.

Let's return to the Kansas tornadoes (EF2+). You import the data and create a point pattern object windowed by the state borders.

```{r}
Torn.sf <- sf::st_read(dsn = here::here("data", 
                                  "1950-2020-torn-initpoint")) |>
  sf::st_transform(crs = 3082) |>
  dplyr::filter(mag >= 2, yr >= 1994) |>
  dplyr::rename(EF = mag) |>
  dplyr::select(EF)

ST.ppp <- Torn.sf |>
  as.ppp() |>
  unmark()

KS.sf <- USAboundaries::us_states(states = "Kansas") |>
  sf::st_transform(crs = sf::st_crs(Torn.sf)$proj4string)

W <- KS.sf |>
  as.owin()

ST.ppp <- ST.ppp[W] |>
  rescale(s = 1000, 
          unitname = "km")

ST.ppp |>
  plot()
```

There are more tornado reports in the west than in the east, especially across the southern part of the state indicating the process producing the events is not homogeneous. This means there are other factors contributing to local event intensity.

Evidence for clustering must account for this inhomogeneity. Here you do this by computing the envelope around the inhomogeneous Ripley K function using the argument `fun = Kinhom`.

```{r}
envelope(ST.ppp,
         fun = Linhom,
         nsim = 99,
         rank = 1,
         global = TRUE) |>
as.data.frame() |>
ggplot(mapping = aes(x = r, y = obs)) +
  geom_ribbon(mapping = aes(ymin = lo, ymax = hi), 
              fill = "gray70") +
  geom_line() +
  geom_line(mapping = aes(y = theo), 
            color = "red", lty = 'dashed') +
  xlab("Lag distance (km)") + ylab("K(r)") +
  theme_minimal()
```

The output reveals no evidence of clustering at distances less than about 70 km. At greater distances there is some evidence of regularity indicated by the black line below the red line and just outside the uncertainty ribbon. This is due to the fact that tornado reports are more common near cities and towns and cities and towns tend to be spread out more regular than CSR.

The variance stabilized Ripley $K$ function called the $L$ function is sometimes used instead of $K$. $L$ is defined as

$$
\hat{L}(r) = \Big( \hat{K}(r)/\pi\Big)^{1/2}.
$$

For data that is CSR, the $L$ function has expected value $r$ and its variance is approximately constant in $r$. A graph of $r - \hat{L}(r)$ against $r$ should follow a diagonal line with constant dispersion if the event locations follow a homogeneous Poisson process.

## Modeling point pattern data {-}

Models are helpful for trying to understanding the processes leading to the event locations when event interaction is suspected. Event interaction means that an event at one location changes the probability of an event nearby.

Cluster models can be derived by starting with a Poisson model. For example, you begin with a homogeneous Poisson model describing a set of events $Y$. Then each individual event $y_i$ in $Y$ is considered a 'parent' that produces 'offspring' events ($x_i$) according to some mechanism. 

The resulting set of offspring forms clustered point pattern data $X$. Said another way, the model is homogeneous Poisson at an unobserved level $Y$ (latent level) but clustered at the level of the observations ($X$).

One example of this parent-child process is the Matern cluster model. Parent events come from a homogeneous Poisson process with intensity $\kappa$ and then each parent has a Poisson ($\mu$) number of offspring that are independent and identically distributed (iid) within a radius $r$ centered on the parent.

For instance here you use the `rMatClust()` function from the {spatstat} package to produce a clustered `ppp` object. You use a disc radius of .1 units and an offspring rate equal to 5 (`mu = 5`).

```{r}
rMatClust(kappa = 10, 
               r = .1, 
               mu = 5) |>
  plot(main = "")
```

The result is a set of event locations and the process that produced them is described as _doubly Poisson_. You can vary $\kappa$, $r$, and $\mu$ to generate more or fewer events.

Other clustered Poisson models include:
- Thomas model: each cluster consists of a Poisson number of random events with each event having an isotropic Gaussian displacement from its parent.  
- Gauss-Poisson model: each cluster is either a single event or a pair of events.  
- Neyman-Scott model: the cluster mechanism is arbitrary.

A Cox model is a homogeneous Poisson model with a random intensity function. Let $\Lambda(s)$ be a function with non-negative values defined at all locations $s$ inside the domain. Then, conditional on $\Lambda$ let $X$ be a Poisson model with an intensity function $\Lambda$. Then $X$ will be a sample from a Cox model.

An example of a Cox model is the mixed Poisson process in which a  variable $\Lambda$ is generated from some distribution that allow only positive number and then, conditional on $\Lambda$, a homogeneous point process is generated. 

Following are two samples from a Cox point process.

```{r}
set.seed(3042)
par(mfrow = c(1, 2))
for (i in 1:2){
  lambda <- rexp(n = 1, rate = 1/100)
  X <- rpoispp(lambda)
  plot(X)
}
par(mfrow = c(1, 1))
```

The statistical moments of Cox models are defined in terms of the moments of $\Lambda$. For instance, the intensity function of $X$ is $\lambda(s)$ = E[$\Lambda(s)$], where E[] is the expected value.

Cox models are convenient for describing clustered point pattern data. A Cox model is over-dispersed relative to a Poisson model (i.e. the variance of the number of events falling in any region of size A, is greater than the mean number of events in those regions). 

The Matern cluster model and the Thomas models are types of Cox models. Another common type of Cox model is the log-Gaussian Cox processes (LGCP) model in which the logarithm of $\Lambda(s)$ is a Gaussian random function.

If you have a way of generating samples from a random function $\Lambda$ of interest, then you can use the `rpoispp()` function to generate the Cox process. The intensity argument `lambda` of `rpoispp()` can be a function of x or y or a pixel image.

Another way to generate clustered point pattern data is by 'thinning'. Thinning refers to deleting some of the events. With 'independent thinning' the fate of each event is independent of the fate of the other events. When independent thinning is applied to a homogeneous Poisson point pattern, the resulting point pattern consisting of the retained events is also Poisson.

An example of this is Matern's Model I model. Here a homogeneous Poisson model first generates a point pattern $Y$, then any event in $Y$ that lies closer than a distance $r$ from another event is deleted. This results in point pattern data whereby close neighbor events do not exist.

```{r}
plot(rMaternI(kappa = 70, 
              r = .05), main = "")

X <- rMaternI(kappa = 70, 
              r = .05)

X |>
  Kest() |>
  plot()
```

Changing $\kappa$ and $r$ will change the event intensity.

The various spatial models for event locations can be described with math. For instance, expanding on the earlier notation you write that a homogeneous Poisson model with intensity $\lambda > 0$ has intensity 

$$\lambda(s, x) = \lambda$$ where $s$ is any location in the window W and $x$ is the set of events.

Then the inhomogeneous Poisson model has conditional intensity

$$\lambda(s, x) = \lambda(s)$$. 
The intensity $\lambda(s)$ depends on a spatial trend or on an explanatory variable.

There is also a class of 'Markov' point process models that allow for clustering (or inhibition) due to event interaction. Markov refers to the fact that the interaction is limited to nearest neighbors. Said another way, a Markov point process generalizes a Poisson process in the case where events are pairwise dependent.

A Markov process with parameters $\beta > 0$ and $0 < \gamma < \infty$ with interaction radius $r > 0$ has conditional intensity $\lambda(s, x)$ given by

$$
\lambda(s, x) = \beta \gamma^{t(s, x)}
$$

where $t(s, x)$ is the number of events that lie within a distance $r$ of location $s$.

Three cases:
- If $\gamma = 1$, then $\lambda(s, x) = \beta$ No interaction between events,  $\beta$ can vary with $s$.
- If $\gamma < 1$, then $\lambda(s, x) < \beta$. Events inhibit nearby events.
- If $\gamma > 1$, then $\lambda(s, x) > \beta$. Events encourage nearby events.

Note the distinction between the interaction term $\gamma$ and the trend term $\beta$. A similar distinction exists between autocorrelation $\rho$ and trend $\beta$ in spatial regression models.

More generally, you write the logarithm of the conditional intensity $\log[\lambda(s, x)]$ as linear expression with two components.

$$
\log\big[\lambda(s, x)\big] = \theta_1 B(s) + \theta_2 C(s, x)
$$

where the $\theta$'s are model parameters that need to be estimated.  

The term $B(s)$ depends only on location so it represents trend and explanatory variable (covariate) effects. It is the 'systematic component' of the model. The term $C(s, x)$ represents stochastic interactions (dependency) between events.

## Fitting and interpreting an inhibition model {-}

The {spatstat} family of packages contains functions for fitting statistical models to point pattern data. Models can include trend, explanatory variables, and event interactions of any order (not restricted to pairwise). Models are fit with the method of maximum likelihood and the method of minimum contrasts.

The method of maximum likelihood estimates the probability of the empirical $K$ curve given the theoretical curve for various parameter values. Parameter values are chosen so as to maximize the likelihood of the empirical curve.

The method of minimum contrasts derives a cost function as the difference between the theoretical and empirical $K$ curves. Parameter values for the theoretical curve are those that minimize this cost function.

The `ppm()` function from {spatstat} is used to fit a spatial point pattern model. The syntax has the form `ppm(X, formula, interaction, ...)` where `X` is the point pattern object of class `ppp`, `formula` describes the systematic (trend and covariate) part of the model, and `interaction` describes the stochastic dependence between events (e.g., Matern process).

Recall a plot the Swedish pine saplings. There was no indication of a trend (no systematic variation in the intensity of saplings).

```{r}
SP <- swedishpines

SP |>
  plot()

SP |>
  intensity()
```

There is no obvious spatial trend in the distribution of saplings and the average intensity is .0074 saplings per unit area.

A plot of the Ripley's $K$ function indicated some regularity relative to CSR for distances between .5 and 1.2 meters.

```{r}
SP |>
  Kest(correction = "iso") |>
  plot()
```

The red dashed line is the $K$ curve under CSR. The black line is the empirical curve. At lag distances of between 5 and 15 units the empirical curve is below the CSR curve indicating there are fewer events within other events at those scales than would be expected by chance.

This suggests a process of between-event inhibition. A simple inhibition model is a Strauss process when the inhibition is constant with a fixed radius (r) around each event. The amount of inhibition ranges between zero (100% chance of a nearby event) to complete (0% chance of a nearby event). In the case of no inhibition the process is equivalent to a homogeneous Poisson process.

If you assume the inhibition process is constant across the domain with a fixed interaction radius (r), then you can fit a Strauss model to the data. You use the `ppm()` function from the {spatstat} package and include the point pattern data as the first argument. You set the trend term to a constant (implying a stationary process) with the argument `trend ~ 1` and the interaction radius to 10 units with the argument `interaction = Strauss(r = 10)`. Finally you use a border correction out to a distance of 10 units from the window with the `rbord =` argument.

Save the output in the object called `model.in` (inhibition model).

```{r}
model.in <- ppm(SP, 
                trend = ~ 1, 
                interaction = Strauss(r = 10), 
                rbord = 10)
```

The value for `r` in the `Strauss()` function is based on our visual inspection of the plot of `Kest()`. A value is chosen to be the distance at which there is the largest departure from a CSR model. 

You inspect the model parameters by typing the object name.

```{r}
model.in
```

The first-order term (`beta`) has a value of .0757. This is the intensity of the 'proposal' events. Beta exceeds the average intensity by a factor of ten. 

Recall the intensity of the events is obtained as

```{r}
SP |>
  intensity()
```

The interaction parameter (`gamma`) is .275. It is less than one, indicating an inhibition process. The logarithm of gamma, called the interaction coefficient (`Interaction`), is -1.29. Interaction coefficients less than zero imply inhibition.

A table with the coefficients including the standard errors and uncertainty ranges is obtained with the `coef()` method.

```{r}
model.in |>
  summary() |>
  coef()
```

The output includes the `Interaction` coefficient along with it's standard error (`S.E.`) and the associated 95% uncertainty interval. The ratio of the `Interaction` coefficient to its standard error is the `Zval`. A large z-value (in absolute magnitude) translates to a low $p$-value and a rejection of the null hypothesis of no interaction between events.

Output also shows the value for the `(Intercept)` term. It is the logarithm of the beta value, so exp(-2.58) = .0757 is the intensity of the proposal events.

You interpret the model output as follows. The process producing the spatial pattern of pine saplings is such that you should see .0757 saplings per unit area [unobserved (latent) rate]. 

But because of event inhibition, where saplings nearby other saplings fail to grow, the number of saplings is reduced to .0074 per unit area. Thus the spatial pattern is suggestive of sibling-sibling interaction. Adults have many offspring, but only some survive due to limited resources.

## Fitting and interpreting a cluster model {-}

Let's compare this inhibition model with a cluster model for describing the Lansing Woods maple trees (in the `ppp` object called `lansing` from the {spatstat} package).

Start by extracting the events marked as `maple` and putting them in a separate `ppp` object called `MT`.

```{r}
data(lansing)
summary(lansing)

MT <- lansing |>
  subset(marks == "maple") |>
  unmark()

summary(MT)
```

There are 514 maple trees over this square region (924 x 924 square feet).

Plots of tree locations and the local intensity function help you examine the first-order property of these data.

```{r}
MT |>
  density() |>
  plot()

plot(MT, add = TRUE)
```

There are maple trees across the southern and central parts of the study domain.

A plot of the $G$ function summarizes the second-order properties under the assumption of no trend.

```{r}
G.df <- MT |>
  Gest() |>
  as.data.frame() |>
  dplyr::filter(r < .033) |>
  dplyr::mutate(r = r * 924)

ggplot(G.df, aes(x = r, y = km)) +
  geom_line() +
  geom_line(aes(y = theo), color = "blue") +
  geom_vline(xintercept = 18, lty = 'dashed') +
  xlab("Lag distance (ft)") + 
  ylab("G(r): Cumulative % of events within a distance r of another maple") +
  theme_minimal()
```

The plot provides evidence that the maple trees are clustered. The empirical curve is above the theoretical curve. About 74% of the maple trees are within 18 feet of another maple tree (vertical blue line). If the trees were arranged as CSR then only 49% of the trees would be within 18 feet of another maple.

Is the clustering due to interaction or trends (or both)?

You start the modeling process by investigating event interaction using a stationary Strauss model with interaction radius of .019 units (18 ft).

```{r}
ppm(MT, 
    trend = ~ 1, 
    interaction = Strauss(r = .019))
```

Here the first order term beta is 345. It is the 'latent' rate (intensity) of maple trees per unit area. This rate is less than the 514 actual maple trees. The fitted interaction parameter (gamma) is 1.72. It is greater than one since the trees are clustered. The logarithm of gamma is positive at .545.

The model is interpreted as follows. The process producing the maple trees is such that you expect to see about 345 maples. Because of clustering where maple trees are more likely in the vicinity of other maple trees, the number of maples increases to the observed 514 per unit area.

Here the physical explanation could be event interaction. But it also could be inhibition with hickory trees. You can model this using a term for cross event type interaction.

The Strauss process is for inhibition models. So although you use it here for diagnostics, you need to fit a cluster model (thus the `*** Model is not valid ***` warning).

For a cluster model the spatial intensity $$\lambda(s) = \kappa \mu(s)$$ where $\kappa$ is the average number of clusters and where $\mu(s)$ is the spatial varying cluster size (number events per cluster).

Cluster models are fit using the `kppm()` function from the {spatstat} package. Here you specify the cluster process with `clusters = "Thomas"`. 

That means each cluster consists of a Poisson number of maple trees and where each tree in the cluster is placed randomly about the 'parent' tree with intensity that varies inversely with distance from the parent as a Gaussian function.

```{r}
( model.cl <- kppm(MT, 
                   trend = ~ 1,
                   clusters = "Thomas") )
```

Here $\kappa$ is 21.75 and $\bar \mu(s)$ (mean cluster size) is 23.6 trees. The product of kappa and the mean cluster size is the number of events. The cluster model describes a parent-child process. The number of parents is about 22. The distribution of the parents can be described as CSR. Each parent produces about 24 offspring distributed randomly about the location of the parent within a characteristic distance. Note: The physical process might be different from the statistical process used to describe it.

The cluster scale parameter indicating the characteristic size (area units) of the clusters is $\sigma^2$. 

A `plot()` method verifies that the cluster process statistically 'explains' the spatial correlation.

```{r}
plot(model.cl, 
     what = "statistic")
```

The model (black line) is very close to the cluster process line (red dashed line). Also note that it is far from the CSR model (green line).

The spatial scale of the clustering is visualized with the `what = "cluster"` argument.

```{r}
plot(model.cl, 
     what = "cluster")
```

The color ramp is the spatial intensity (number of events per unit area) about an arbitrary single event revealing the spatial scale and extent of clustering.

## Assessing how well the model fits {-}

Workflow in fitting spatial event location models

- Analyze/plot the intensity and nearest neighbor statistics
- Select a model including trend, interaction distance, etc informed by the results of step 1
- Choose an inhibition or cluster model
- Fit the model to the event pattern
- Assess how well the model fits the data by generating samples and comparing statistics from the samples with the statistics from the original data

The model should be capable of generating samples of event locations that are statistically indistinguishable from the actual event locations.

Note: The development of spatial point process methods has largely been theory driven (not by actual problems/data). More work needs to be done to apply the theory to environmental data with spatial heterogeneity, properties at the individual level (marks), and with time information.

You produce samples of event locations with the `simulate()` function applied to the model object. 