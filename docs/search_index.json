[["thursday-march-9-2023.html", "Thursday March 9, 2023 Fitting a variogram model to the sample variogram Creating an interpolated surface with the method of kriging Comparing interpolation methods", " Thursday March 9, 2023 “Statistics is such a powerful language for describing data in ways that reveal nothing about their causes. Of course statistics is powerful for revealing causes as well. But it takes some care. Like the difference between talking and making sense.” - Richard McElreath Fitting a variogram model to the sample variogram Some years ago there were three nuclear waste repository sites being proposed. One in Nevada, one in Texas, and one in Washington. The proposed site needed to be large enough for more than 68,000 high-level waste containers placed underground, about 9 m (~30 feet) apart, in trenches surrounded by salt In July of 2002 the Congress approved Yucca Mountain, Nevada, as the nation’s first long-term geological repository for spent nuclear fuel and high-level radioactive waste. The facility has yet to be built The site must isolate nuclear waste for 10,000 years. Leaks could occur, however, or radioactive heat could cause tiny quantities of water in the salt to migrate toward the heat until eventually each canister is surrounded by 22.5 liters of water (~6 gallons). A chemical reaction involving salt and water can create hydrochloric acid that might corrode the canisters. The site needed to be surveyed for the flow of water in underground aquifers The Ogallala Aquifer is a shallow water table aquifer surrounded by sand, silt, clay, and gravel located beneath the Great Plains in the United States. It is one of the world’s largest aquifers underlying an area of approximately 450,000 square kilometers across 8 states including Texas and New Mexico Data at the site were obtained by drilling a narrow pipe into the aquifer and letting water seek its own level and then measuring the water height in the pipe (piezometer). Measurements indicate potential energy in units of feet above sea level. Higher heights indicate greater potential energy. Water flows from areas of higher potential energy to areas of lower energy with water movement in the aquifer proportional to the gradient of energy. The data are in wolfcamp.csv on my website Start by examining the values of piezometric head heights for trends and check to see if the values can adequately described by a normal distribution. Import the csv file as a data frame. Change the name head to head_ft and add a column for heights in meters ( wca.df &lt;- &quot;http://myweb.fsu.edu/jelsner/temp/data/wolfcamp.csv&quot; |&gt; readr::read_csv() |&gt; dplyr::rename(head_ft = head) |&gt; dplyr::mutate(head_m = head_ft * .3048) ) ## # A tibble: 85 × 4 ## lon lat head_ft head_m ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 -101. 35.2 1464 446. ## 2 -102. 34.7 2553 778. ## 3 -102. 34.6 2158 658. ## 4 -102. 34.5 2455 748. ## 5 -100. 34.3 1756 535. ## 6 -100. 34.6 1702 519. ## 7 -100. 34.2 1805 550. ## 8 -100. 34.0 1797 548. ## 9 -100. 33.9 1714 522. ## 10 -100. 34.2 1466 447. ## # … with 75 more rows Create a simple feature data frame. This is done by specifying the columns lon and lat as coordinates with the coords = argument. Then using functions from the {tmap} package ( wca.sf &lt;- sf::st_as_sf(x = wca.df, coords = c(&quot;lon&quot;, &quot;lat&quot;), crs = 4326) ) ## Simple feature collection with 85 features and 2 fields ## Geometry type: POINT ## Dimension: XY ## Bounding box: xmin: -104.55 ymin: 33.51 xmax: -100.02 ymax: 36.09 ## Geodetic CRS: WGS 84 ## # A tibble: 85 × 3 ## head_ft head_m geometry ## * &lt;dbl&gt; &lt;dbl&gt; &lt;POINT [°]&gt; ## 1 1464 446. (-101.25 35.25) ## 2 2553 778. (-102.48 34.71) ## 3 2158 658. (-102.02 34.62) ## 4 2455 748. (-102.33 34.49) ## 5 1756 535. (-100.31 34.32) ## 6 1702 519. (-100.1 34.59) ## 7 1805 550. (-100.45 34.2) ## 8 1797 548. (-100.42 33.95) ## 9 1714 522. (-100.37 33.86) ## 10 1466 447. (-100.29 34.2) ## # … with 75 more rows Note that the simple feature data frame does not have columns labeled lon and lat. They are removed as attributes and used in the geometry column Make a map using functions from the {tmap} package showing the locations and the measured values of the head heights tmap::tmap_mode(&quot;view&quot;) ## tmap mode set to interactive viewing tmap::tm_shape(wca.sf) + tmap::tm_dots(&quot;head_m&quot;) The measurements were taken across the panhandle region of Texas and portions of northeast New Mexico. The aquifer extends northward into Oklahoma, Kansas, Colorado, Nebraska, Wyoming, and South Dakota You will use the spatial coordinates to model the spatial autocorrelation and to remove any spatial trend. The variogram model uses spatial information stored in the geometry column but the spatial trend model needs the coordinates as attributes. So you include them as attribute variables in your spatial data frame First create a matrix from the 2-D coordinates with the sf::st_coordinates() function XY &lt;- wca.sf |&gt; sf::st_coordinates() XY |&gt; head() ## X Y ## 1 -101.25 35.25 ## 2 -102.48 34.71 ## 3 -102.02 34.62 ## 4 -102.33 34.49 ## 5 -100.31 34.32 ## 6 -100.10 34.59 Then attach these column vectors to the simple feature data frame wca.sf$X &lt;- XY[, 1] wca.sf$Y &lt;- XY[, 2] wca.sf |&gt; head() ## Simple feature collection with 6 features and 4 fields ## Geometry type: POINT ## Dimension: XY ## Bounding box: xmin: -102.48 ymin: 34.32 xmax: -100.1 ymax: 35.25 ## Geodetic CRS: WGS 84 ## # A tibble: 6 × 5 ## head_ft head_m geometry X Y ## &lt;dbl&gt; &lt;dbl&gt; &lt;POINT [°]&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1464 446. (-101.25 35.25) -101. 35.2 ## 2 2553 778. (-102.48 34.71) -102. 34.7 ## 3 2158 658. (-102.02 34.62) -102. 34.6 ## 4 2455 748. (-102.33 34.49) -102. 34.5 ## 5 1756 535. (-100.31 34.32) -100. 34.3 ## 6 1702 519. (-100.1 34.59) -100. 34.6 Do all observations have different locations? Duplicate coordinates might be due to an error or might represent multiple measurements at a location You check for duplicates with the {base} duplicated() function applied to the geometry field wca.sf$geometry |&gt; duplicated() ## [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [25] FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE ## [37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [49] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [61] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [73] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [85] FALSE Observation 31 is a location that already has an observed head height. You remove this observation from the data frame wca.sf &lt;- wca.sf |&gt; dplyr::filter(!duplicated(geometry)) wca.sf$geometry |&gt; duplicated() |&gt; any() ## [1] FALSE Summarize the information in the spatial data frame with the summary() method and with the sf::st_bbox() function wca.sf |&gt; summary() ## head_ft head_m geometry X ## Min. :1024 Min. : 312.1 POINT :84 Min. :-104.5 ## 1st Qu.:1543 1st Qu.: 470.2 epsg:4326 : 0 1st Qu.:-102.4 ## Median :1787 Median : 544.7 +proj=long...: 0 Median :-101.7 ## Mean :1998 Mean : 608.9 Mean :-101.7 ## 3rd Qu.:2541 3rd Qu.: 774.5 3rd Qu.:-100.8 ## Max. :3571 Max. :1088.4 Max. :-100.0 ## Y ## Min. :33.51 ## 1st Qu.:33.87 ## Median :34.26 ## Mean :34.55 ## 3rd Qu.:35.31 ## Max. :36.09 wca.sf |&gt; sf::st_bbox(wca.sf) ## xmin ymin xmax ymax ## -104.55 33.51 -100.02 36.09 There are 84 well sites bounded between longitude lines 104.55W and 100.02W and latitude lines 33.51N and 36.09N. The head heights range from a minimum of 312 m to a maximum of 1088 m with an average of 609 m Create a static map with functions from the {ggplot2} package library(ggplot2) ggplot() + geom_sf(data = wca.sf, mapping = aes(color = head_m)) + scale_color_viridis_c() + labs(col = &quot;Head\\nheight (m)&quot;) + theme_minimal() There is a clear trend in head heights with the highest heights (potential energy) over the southwest (yellow) and lowest heights over the northeast (blue) There are two sources of variation in any set of spatial data: trend and spatial autocorrelation. With geostatistical data, trend is modeled with a smooth curve and autocorrelation is modeled with the variogram Compute and plot the sample variogram using the variogram() function from the {gstat} package. Here you are assuming that all spatial variation is due to autocorrelation library(gstat) variogram(head_m ~ 1, data = wca.sf) |&gt; plot() You see nearly continuously increasing variances (m^2) with lag distance (km) with no leveling off (no plateau). Note: since the spatial coordinates are un-projected (decimal latitude/longitude) great circle distances are used and the units are kilometers You compute and plot the variogram this time with the trend removed. You replace the 1 with X + Y on the right hand side of the formula where X and Y are the spatial coordinates as attributes in wca.sf. The variogram is then computed on the residuals from a linear trend model (2-D plane surface) variogram(head_m ~ X + Y, data = wca.sf) |&gt; plot() Here you see an increase in the variance with lag distance out to about 100 km, but then the values fluctuate about a variance of about 4000 (m^2). This is what you want to see if kriging is to be useful for spatial interpolation You save the variogram object computed on the residuals wca.v &lt;- variogram(head_m ~ X + Y, data = wca.sf) Check the structure of the saved object with the str() function wca.v |&gt; str() ## Classes &#39;gstatVariogram&#39; and &#39;data.frame&#39;: 15 obs. of 6 variables: ## $ np : num 36 59 76 105 79 80 102 98 112 116 ... ## $ dist : num 7.15 17 28.44 39.43 50.23 ... ## $ gamma : num 1210 1767 2341 2534 2611 ... ## $ dir.hor: num 0 0 0 0 0 0 0 0 0 0 ... ## $ dir.ver: num 0 0 0 0 0 0 0 0 0 0 ... ## $ id : Factor w/ 1 level &quot;var1&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## - attr(*, &quot;direct&quot;)=&#39;data.frame&#39;: 1 obs. of 2 variables: ## ..$ id : chr &quot;var1&quot; ## ..$ is.direct: logi TRUE ## - attr(*, &quot;boundaries&quot;)= num [1:16] 0 11.2 22.4 33.6 44.8 ... ## - attr(*, &quot;pseudo&quot;)= num 0 ## - attr(*, &quot;what&quot;)= chr &quot;semivariance&quot; np number of observation pairs dist lag distance (km) \\(h\\) gamma semi-variance estimate (km^2) dir.* 0s for omni-directional variogram (vertical &amp; horizontal) \"boundaries\" lag distance +/- lag tolerance \\(\\delta h\\) You use the information contained in the data frame part of the variogram object to anticipate the type of variogram model df &lt;- wca.v |&gt; data.frame() ( p &lt;- ggplot(data = df, mapping = aes(x = dist, y = gamma)) + geom_point() + geom_smooth() + scale_y_continuous(limits = c(0, NA)) + ylab(expression(paste(&quot;Variogram [&quot;, gamma,&quot;(h)]&quot;))) + xlab(&quot;Lag distance (h)&quot;) + theme_minimal() ) ## `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; The blue line is a local regression smoother through the variogram estimates. The fact that it is not a flat horizontal line indicates spatial autocorrelation in the residuals (distinct from the first-order trend) Next you check the assumption of isotropy (spatial autocorrelation depends only on lag distance not orientation). You do this by computing variograms using observational pairs located along the same orientation. Instead of considering all observational pairs within a lag distance \\(h\\) and lag tolerance \\(\\delta h\\), you consider only pairs within a directional segment This is done with the alpha = argument in the variogram() function that specifies the direction in the (x, y) plane in degrees starting with 0 (due north) Here you specify four directions (north-south-0, northeast-southwest-45, east-west-90, and southeast-northeast-135) and compute the corresponding directional variograms. Change the numeric variable dir.hor to a factor called direction and then plot them mapping direction to the color aesthetic wca.vd &lt;- variogram(head_m ~ X + Y, data = wca.sf, alpha = c(0, 45, 90, 135)) df &lt;- wca.vd |&gt; data.frame() |&gt; dplyr::mutate(direction = factor(dir.hor)) ggplot(data = df, mapping = aes(x = dist, y = gamma, color = direction)) + geom_point() + geom_smooth(alpha = .2) + scale_y_continuous(limits = c(0, NA)) + ylab(expression(paste(&quot;Variogram [&quot;, gamma,&quot;(h)]&quot;))) + xlab(&quot;Lag distance (h)&quot;) + theme_minimal() ## `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; All four of the variograms have similar shape and there is large overlap in the uncertainty bands surrounding the smooth curves. Based on this plot you conclude that the assumption of isotropy is reasonable You are now ready to fit a variogram model to the sample variogram. This amounts to fitting a parametric curve through the set of points that make up the sample variogram Start by plotting the (omni-directional) sample variogram saved in object p p ## `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; The shape of the blue line gives you an idea of the type of variogram family of models you should consider. The values increase nearly linearly through a distance of about 80 km and then abruptly level off Now you can guess at a family for the variogram model and eyeball the parameters. A spherical variogram model has a nearly linear increase in variances with lag distance before an abrupt flattening so that is a good choice The parameters for the model can be estimated from the graph as follows p + geom_hline(yintercept = c(1000, 4100), color = &quot;red&quot;) + geom_vline(xintercept = 90, color = &quot;red&quot;) + geom_segment(aes(x = 0, y = 0, xend = 0, yend = 1000,), arrow = arrow(angle = 15, length = unit(.3, &quot;cm&quot;))) + geom_label(aes(x = 10, y = 800, label = &quot;nugget&quot;)) + geom_segment(aes(x = 0, y = 1000, xend = 0, yend = 4100,), arrow = arrow(angle = 15, length = unit(.3, &quot;cm&quot;))) + geom_label(aes(x = 12, y = 3900, label = &quot;partial sill&quot;)) + geom_segment(aes(x = 0, y = 4200, xend = 90, yend = 4200,), arrow = arrow(angle = 15, length = unit(.3, &quot;cm&quot;))) + geom_label(aes(x = 50, y = 4400, label = &quot;range&quot;)) ## `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; The nugget, sill, and range are the parameters in a variogram model Recall - Nugget (nugget, nugget variance, or nugget effect): The height of the variogram at zero lag. The nugget is the variation in the values at the measurement locations without regard to spatial variation. Related to the observation (or measurement) precision - Sill: The height of the variogram at which the values are uncorrelated. The sill is indicated by the height of the plateau in the variogram - Range: The distance beyond which the values are uncorrelated. The range is indicated by distance along the horizontal axis from zero lag until the plateau in the variogram - Relative nugget effect: The ratio of the nugget to the sill expressed as a percentage - Lag distance: Relative distance between observation locations From the figure you estimate the sill at 4100 m^2, the nugget at 1000 m^2 and the range at 90 km To fit a model to the sample variogram you start with the vgm() function that sets the curve family (here spherical) and initial parameter estimates. You save result in an object called wca.vmi. The function needs the partial sill (psill = argument) as the difference between the sill and the nugget (4100 - 1000 = 3100), the range, and the nugget wca.vmi &lt;- vgm(model = &quot;Sph&quot;, psill = 3100, range = 90, nugget = 1000) wca.vmi ## model psill range ## 1 Nug 1000 0 ## 2 Sph 3100 90 Note that the nugget is a separate model with 0 range Next you apply the function fit.variogram(), which uses the method of weighted least squares to improve the parameter estimates from the set of initial estimates. The function takes the sample variogram and the set of initial estimates as object = and model =, respectively wca.vm &lt;- fit.variogram(object = wca.v, model = wca.vmi) wca.vm ## model psill range ## 1 Nug 911.7035 0.0000 ## 2 Sph 3238.1230 106.9951 Note: Ordinary least squares is not an appropriate method for fitting a variogram model to the sample variogram because the semivariances are correlated across the lag distances and the precision on the estimates depends on the number of site pairs for a given lag The output table shows the nugget and spherical models. The nugget is 912 m^2 and the partial sill for the spherical model is 3238 m^2 with a range of 107 km. These values are close to your initial estimates To check the model and fit plot them together with the plot() method wca.v |&gt; plot(wca.vm) The blue line is the variogram model and the points are the sample variogram values Note that the fit.variogram() function will find the optimal fit even if the initial values are not very good. For example, here you lower the partial sill to 2000 m^2, reduce the range to 50 km and set the nugget to 500 m^2 wca.vmi2 &lt;- vgm(model = &quot;Sph&quot;, psill = 2000, range = 50, nugget = 500) wca.vm2 &lt;- fit.variogram(object = wca.v, model = wca.vmi2) wca.vm2 ## model psill range ## 1 Nug 911.7349 0.0000 ## 2 Sph 3238.2141 107.0046 The initial values are poor but good enough for the fit.variogram() function to find the optimal model For comparison, also fit a Gaussian model wca.vmi3 &lt;- vgm(model = &quot;Gau&quot;, psill = 9100, range = 30, nugget = 3000) wca.vm3 &lt;- fit.variogram(object = wca.v, model = wca.vmi3) wca.v |&gt; plot(wca.vm3) The Gaussian model has a S-shaped curve (sigmodial) indicating more spatial autocorrelation at close distances Finally, fit an exponential model wca.vmi4 &lt;- vgm(model = &quot;Exp&quot;, psill = 9100, range = 10, nugget = 3000) wca.vm4 &lt;- fit.variogram(object = wca.v, model = wca.vmi4) wca.v |&gt; plot(wca.vm4) The exponential model has no plateau. All three models fit the sample variogram values reasonably well In practice, the choice often makes little difference in the quality of the spatial interpolation On the other hand, it is possible to optimize over all sets of variogram models and parameters using the autofitVariogram() function from the {automap} package. The package requires the data to be of S4 class but uses the functions from the {gstat} package Here you use the function on the Wolfcamp aquifer data wca.sp &lt;- as(wca.sf, &quot;Spatial&quot;) wca.vm5 &lt;- automap::autofitVariogram(formula = head_m ~ X + Y, input_data = wca.sp) plot(wca.vm5) The automatic fitting results in a Matérn model. The Matérn family of variogram models has an additional parameter kappa (besides the nugget, sill, and range) that allows for local smoothing. With an extra parameter these models will generally outperform models with fewer parameters The general shape is that of the exponential model except at small lags. The Matérn model can describe spatial processes with different local behavior Creating an interpolated surface with the method of kriging Kriging uses the variogram model together with the observed data to estimate values at any location of interest. The kriged estimates are a weighted average of the neighborhood values with the weights defined by the variogram model Estimates can be made anywhere in the domain but are often made at locations defined on a regular grid. Here you create a regular grid of locations within the boundary of the spatial data frame using the sf::st_make_grid() function. You specify the number of locations in the x and y direction using the argument n =. The what = \"centers\" returns the center locations of the grid cells as points grid.sfc &lt;- sf::st_make_grid(wca.sf, n = c(50, 50), what = &quot;centers&quot;) The result is a simple feature column (sfc) of points. Plot the grid locations together with the observation locations sts &lt;- USAboundaries::us_states() tmap::tmap_mode(&quot;plot&quot;) ## tmap mode set to plotting tmap::tm_shape(wca.sf) + tmap::tm_bubbles(size = .25) + tmap::tm_shape(grid.sfc) + tmap::tm_dots(col = &quot;red&quot;) + tmap::tm_shape(sts) + tmap::tm_borders() The observations in gray circles and the grid locations in red dots Since the variogram is done on the residuals after a trend in the X and Y directions is removed you need to add the X and Y coordinates to the simple feature column of the grid. First make it a simple feature data frame then add the columns with dplyr::mutate() XY &lt;- grid.sfc |&gt; sf::st_coordinates() grid.sf &lt;- grid.sfc |&gt; sf::st_as_sf() |&gt; dplyr::rename(geometry = x) |&gt; dplyr::mutate(X = XY[, 1], Y = XY[, 2]) grid.sf |&gt; head() ## Simple feature collection with 6 features and 2 fields ## Geometry type: POINT ## Dimension: XY ## Bounding box: xmin: -104.5047 ymin: 33.5358 xmax: -104.0517 ymax: 33.5358 ## Geodetic CRS: WGS 84 ## geometry X Y ## 1 POINT (-104.5047 33.5358) -104.5047 33.5358 ## 2 POINT (-104.4141 33.5358) -104.4141 33.5358 ## 3 POINT (-104.3235 33.5358) -104.3235 33.5358 ## 4 POINT (-104.2329 33.5358) -104.2329 33.5358 ## 5 POINT (-104.1423 33.5358) -104.1423 33.5358 ## 6 POINT (-104.0517 33.5358) -104.0517 33.5358 Next you interpolate the heights to the grid locations. You do this with the krige() function. The first argument is the formula for the trend, the locations argument is the observed data locations from the simple feature data frame, the new data argument is the locations and independent variables (in this case the trend variables) and the model argument is the variogram model that you fit previously wca.int &lt;- krige(head_m ~ X + Y, locations = wca.sf, newdata = grid.sf, model = wca.vm) ## [using universal kriging] The output says using universal kriging. This is because there is a trend and a variogram model. If there is only a variogram model, then it is called ordinary kriging wca.int |&gt; head() ## Simple feature collection with 6 features and 2 fields ## Geometry type: POINT ## Dimension: XY ## Bounding box: xmin: -104.5047 ymin: 33.5358 xmax: -104.0517 ymax: 33.5358 ## Geodetic CRS: WGS 84 ## var1.pred var1.var geometry ## 1 1102.807 3391.175 POINT (-104.5047 33.5358) ## 2 1095.656 3374.580 POINT (-104.4141 33.5358) ## 3 1088.526 3375.150 POINT (-104.3235 33.5358) ## 4 1080.816 3330.185 POINT (-104.2329 33.5358) ## 5 1072.963 3197.839 POINT (-104.1423 33.5358) ## 6 1065.076 2958.396 POINT (-104.0517 33.5358) The output is a simple feature data frame containing the interpolated values at the grid locations in the column labeled var1.pred (variable 1 predictions). The interpolated uncertainty is given in the column labeled var1.var Plot the interpolated aquifer heights at the grid locations using functions from the {ggplot2} package. Add a plot of the measured head heights using the same color ramp ggplot() + geom_sf(data = wca.int, mapping = aes(col = var1.pred), size = 4) + geom_sf(data = wca.sf, mapping = aes(col = head_m)) + scale_color_viridis_c() + labs(col = &quot;Head\\nheight (m)&quot;) + theme_minimal() Since the sfc geometry is POINT the map is the grid of points colored by the predicted piezometric head heights The trend captures the large scale feature of higher heights in the southwest and lower heights in the northeast while the variogram captures the local spatial autocorrelation. Together they produce an interpolated surface that closely matches the values at the observation locations (exactly matches when the nugget is fixed at zero) Plot the uncertainty in the estimated interpolated values as the square root of the predicted variance. Add the locations of the observations as points ggplot() + geom_sf(data = wca.int, mapping = aes(col = sqrt(var1.var)), size = 4) + scale_color_viridis_c(option = &quot;plasma&quot;) + geom_sf(data = wca.sf, size = .5, col = &quot;white&quot;) + labs(col = &quot;Uncertainty (m)&quot;) + theme_minimal() Standard deviation of the prediction variance in units of meters. Recall the range of head heights was from a low of 312 m to a high of 1088 m so the predictive errors are generally less than 10% Predictive errors are a function of distance to nearest measurement (northwest corner). This makes sense since information about the heights comes from the measurements Comparing interpolation methods Let’s look at another data set. Here you consider a data set of monthly average near-surface air temperatures during April across the Midwest. The data set is available on my website in the file MidwestTemps.txt Start by importing the data as a data frame ( t.df &lt;- &quot;http://myweb.fsu.edu/jelsner/temp/data/MidwestTemps.txt&quot; |&gt; readr::read_table() ) ## # A tibble: 131 × 3 ## lon lat temp ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 -90.7 41.2 51.6 ## 2 -89.9 39.3 55.9 ## 3 -89.0 39.8 54.7 ## 4 -89.5 41.8 51.1 ## 5 -90.0 41.2 52.2 ## 6 -90.7 39.7 55.2 ## 7 -89.5 39.2 54.7 ## 8 -90.2 39.7 54.6 ## 9 -91.0 40.6 53.1 ## 10 -89.4 40.2 53.1 ## # … with 121 more rows The data frame contains three columns. The first two are longitude (lon) and latitude (lat) and the third is average air temperatures (temp) in tens of °F. These are the climate observations at specified locations and you want a continuous field of values across the domain Convert the data frame to a simple feature data frame by specifying which columns you want as coordinates (first X then Y) t.sf &lt;- t.df |&gt; sf::st_as_sf(coords = c(&quot;lon&quot;, &quot;lat&quot;), crs = 4326) Next include the spatial coordinates as attributes (X and Y) in the simple feature data frame. They were removed as attributes by the sf::st_as_sf() function t.sf$X &lt;- t.df$lon t.sf$Y &lt;- t.df$lat Check to see if there are duplicated coordinates t.sf$geometry |&gt; duplicated() |&gt; any() ## [1] FALSE Plot the temperatures at the observation locations on a map sts &lt;- USAboundaries::us_states() tmap::tm_shape(t.sf) + tmap::tm_text(text = &quot;temp&quot;, size = .6) + tmap::tm_shape(sts) + tmap::tm_borders() There is a clear trend in temperatures with the coolest air to the north. Besides this north-south trend, there appears to be some clustering of the temperatures due to local conditions Next, compute and plot the sample variogram (omni-directional) using the residuals after removing the trend. The trend term is specified in the formula as temp ~ X + Y t.v &lt;- variogram(temp ~ X + Y, data = t.sf) t.v |&gt; plot() The sample variogram values confirm spatial autocorrelation as there is an increase in the semi-variance for increasing lag distance out to about 150 km Next, check for anisotropy. Specify four directions and compute the corresponding directional sample variograms t.vd &lt;- variogram(temp ~ X + Y, data = t.sf, alpha = c(0, 45, 90, 135)) df &lt;- t.vd |&gt; as.data.frame() |&gt; dplyr::mutate(direction = factor(dir.hor)) ggplot(data = df, mapping = aes(x = dist, y = gamma, color = direction)) + geom_point() + geom_smooth(alpha = .2) + scale_y_continuous(limits = c(0, NA)) + ylab(expression(paste(&quot;Variogram [&quot;, gamma,&quot;(h)]&quot;))) + xlab(&quot;Lag distance (h)&quot;) + theme_minimal() ## `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; The four sample variograms are all quite similar providing no strong evidence to reject the assumption of isotropy Next, fit a variogram model to the sample variogram. Plot the sample variogram again to eyeball initial estimates of the model parameters t.v |&gt; plot() Choose a nugget of .5, a partial sill of 2.5, and a range of 150 Next set the initial parameters for an exponential model then fit the model t.vmi &lt;- vgm(model = &quot;Exp&quot;, psill = 2.5, range = 150, nugget = .5) t.vm &lt;- fit.variogram(object = t.v, model = t.vmi) t.vm ## model psill range ## 1 Nug 0.000000 0.00000 ## 2 Exp 3.042847 73.81357 Plot the sample variogram together with the variogram model t.v |&gt; plot(t.vm) Next, make a grid of locations at which values will be interpolated. Add the coordinates as attributes to the resulting sfc grid.sfc &lt;- sf::st_make_grid(t.sf, n = c(100, 100), what = &quot;centers&quot;) XY &lt;- grid.sfc |&gt; sf::st_coordinates() grid.sf &lt;- grid.sfc |&gt; sf::st_as_sf() |&gt; dplyr::mutate(X = XY[, 1], Y = XY[, 2]) Next, interpolate the observed temperatures to the grid locations using the method of universal kriging t.int &lt;- krige(temp ~ X + Y, locations = t.sf, newdata = grid.sf, model = t.vm) ## [using universal kriging] The interpolated values at the grid locations are returned in the simple feature data frame you assigned as t.int. Take a glimpse of the the file contents t.int |&gt; dplyr::glimpse() ## Rows: 10,000 ## Columns: 3 ## $ var1.pred &lt;dbl&gt; 56.69103, 56.62371, 56.64901, 56.81402, 57.02691, 57.22771, … ## $ var1.var &lt;dbl&gt; 1.2599718, 0.9075707, 0.7767522, 0.9968012, 1.3129199, 1.587… ## $ geometry &lt;POINT [°]&gt; POINT (-98.4204 38.62435), POINT (-98.3212 38.62435), … There are 10,000 rows (100 by 100 grid locations). The first column labeled var1.pred contains the interpolated temperatures. The second column contains the variance of the interpolated temperatures and the third column is the simple feature column The trend term captures the north-south temperature gradient and the variogram captures the local spatial autocorrelation. Together they make up the interpolated values To see this, you refit the interpolation, first without the variogram model, and second without the trend First, rename the columns t.int &lt;- t.int |&gt; dplyr::rename(uk.pred = var1.pred, uk.var = var1.var) Next, use the krige() function but do not include the model = argument. t.trend &lt;- krige(temp ~ X + Y, locations = t.sf, newdata = grid.sf) ## [ordinary or weighted least squares prediction] Add the interpolated temperature trend (located in t.trend$var1.pred) to the t.int simple feature data frame t.int &lt;- t.int |&gt; dplyr::mutate(trend.pred = t.trend$var1.pred) Next, again use the krige() function but do not include the trend term. That is interpolate using ordinary kriging t.ok &lt;- krige(temp ~ 1, locations = t.sf, newdata = grid.sf, model = t.vm) ## [using ordinary kriging] Again add the interpolated temperatures from ordinary kriging to the t.int simple feature data frame t.int &lt;- t.int |&gt; dplyr::mutate(ok.pred = t.ok$var1.pred) Now you have three interpolations of the temperatures in the t.int simple feature data frame all labeled with .pred t.int |&gt; dplyr::glimpse() ## Rows: 10,000 ## Columns: 5 ## $ uk.pred &lt;dbl&gt; 56.69103, 56.62371, 56.64901, 56.81402, 57.02691, 57.22771,… ## $ uk.var &lt;dbl&gt; 1.2599718, 0.9075707, 0.7767522, 0.9968012, 1.3129199, 1.58… ## $ geometry &lt;POINT [°]&gt; POINT (-98.4204 38.62435), POINT (-98.3212 38.62435),… ## $ trend.pred &lt;dbl&gt; 57.25042, 57.23585, 57.22128, 57.20672, 57.19215, 57.17758,… ## $ ok.pred &lt;dbl&gt; 54.96613, 55.37918, 55.66495, 55.74478, 55.73389, 55.69921,… Map the interpolations tmap::tm_shape(t.int) + tmap::tm_dots(title = &quot;°F&quot;, shape = 15, size = 2, col = c(&quot;uk.pred&quot;, &quot;trend.pred&quot;, &quot;ok.pred&quot;), n = 9, palette = &quot;OrRd&quot;) + tmap::tm_shape(sts) + tmap::tm_borders() + tmap::tm_shape(t.sf) + tmap::tm_text(&quot;temp&quot;, col = &quot;white&quot;, size = .5) + tmap::tm_layout(legend.outside = TRUE, legend.outside.position = &quot;bottom&quot;) The trend term (middle panel) captures the north-south temperature gradient and ordinary kriging (right panel) captures the local spatial autocorrelation. Together they make the universal kriging (left panel) interpolated surface. The pattern obtained with ordinary kriging is similar to that obtained using inverse distance weighting Inverse distance weighting (IDW) is a deterministic method for interpolation. The values assigned to locations are calculated with a weighted average of the values available at the observed locations. The weights are proportional to the inverse of the distance to each location The function krige() performs IDW when there is no trend term and no variogram model given as arguments to the function t.idw &lt;- krige(temp ~ 1, locations = t.sf, newdata = grid.sf) ## [inverse distance weighted interpolation] The IDW interpolation is not statistical so there is no estimate of the uncertainty on the interpolated values. This shows up as NA values in the var1.pred column t.idw |&gt; dplyr::glimpse() ## Rows: 10,000 ## Columns: 3 ## $ var1.pred &lt;dbl&gt; 55.68144, 55.98071, 56.06647, 55.89950, 55.59632, 55.30513, … ## $ var1.var &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ geometry &lt;POINT [°]&gt; POINT (-98.4204 38.62435), POINT (-98.3212 38.62435), … Put the IDW interpolated values into the t.int simple feature data frame and compare them to the universal kriging interpolated values on a map. t.int &lt;- t.int |&gt; dplyr::mutate(idw.pred = t.idw$var1.pred) tmap::tm_shape(t.int) + tmap::tm_dots(title = &quot;°F&quot;, shape = 15, size = 2, col = c(&quot;uk.pred&quot;, &quot;idw.pred&quot;), n = 9, palette = &quot;OrRd&quot;) + tmap::tm_shape(sts) + tmap::tm_borders() + tmap::tm_layout(legend.outside = TRUE) IDW tends to create more ‘bulls-eye’ patterns in the interpolations compared with universal kriging. It also tends to over smooth at the larger scales. t.int &lt;- t.int |&gt; dplyr::mutate(diff.pred = idw.pred - uk.pred) tmap::tm_shape(t.int) + tmap::tm_dots(title = &quot;°F&quot;, shape = 15, size = 2, col = &quot;diff.pred&quot;, n = 9, palette = &quot;BrBG&quot;) + tmap::tm_shape(sts) + tmap::tm_borders() ## Variable(s) &quot;diff.pred&quot; contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette. Relative to universal kriging, IDW over estimates the temperatures in the coldest regions and under estimates the temperatures in the warmest regions. At the largest scales IDW is too smooth and at the smallest scales it is too coarse By taking into account to different models (trend at the largest scale and autocorrelation at the smallest scales) universal kriging produces a ‘goldilocks’ surface Finally, simple kriging is ordinary kriging with a known mean value. This is done by specifying a value for the beta = argument. Here you specify the average value over all observed temperatures krige(temp ~ 1, beta = mean(t.sf$temp), locations = t.sf, newdata = grid.sf, model = t.vm) ## [using simple kriging] ## Simple feature collection with 10000 features and 2 fields ## Geometry type: POINT ## Dimension: XY ## Bounding box: xmin: -98.4204 ymin: 38.62435 xmax: -88.5996 ymax: 45.42565 ## Geodetic CRS: WGS 84 ## First 10 features: ## var1.pred var1.var geometry ## 1 55.03658 1.2219584 POINT (-98.4204 38.62435) ## 2 55.42840 0.8890350 POINT (-98.3212 38.62435) ## 3 55.70226 0.7662341 POINT (-98.222 38.62435) ## 4 55.78486 0.9850783 POINT (-98.1228 38.62435) ## 5 55.78267 1.2960863 POINT (-98.0236 38.62435) ## 6 55.75725 1.5646021 POINT (-97.9244 38.62435) ## 7 55.71768 1.7733525 POINT (-97.8252 38.62435) ## 8 55.66063 1.9329095 POINT (-97.726 38.62435) ## 9 55.58293 2.0570339 POINT (-97.6268 38.62435) ## 10 55.48552 2.1558398 POINT (-97.5276 38.62435) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
