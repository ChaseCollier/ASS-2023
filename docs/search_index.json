[["thursday-october-20-2022.html", "Thursday October 20, 2022 Inferring event interaction from distance functions Removing duplicate event locations and defining the domain Modeling point pattern data Fitting and interpreting an inhibition model", " Thursday October 20, 2022 “Weeks of coding can save you hours of planning.” - Unknown Today - Inferring event interaction from distance functions - Removing duplicate event locations and defining the domain - Modeling point pattern data - Fitting and interpreting an inhibition model Inferring event interaction from distance functions The distance functions (\\(G\\), \\(K\\), etc) that are used to quantify clustering are defined and estimated under the assumption that the process that produced the events is stationary (homogeneous). If this is true then you can treat any sub-region of the domain as an independent and identically distributed (iid) sample from the entire set of data. If the spatial distribution of the event locations is influenced by event interaction then the functions will deviate from the theoretical model of CSR. But a deviation from CSR does not imply event interaction. Moreover, the functions characterize the spatial arrangement of event locations ‘on average’ so variability in an interaction as a function of scale may not be detected. As an example of the latter case, here you generate event locations at random with clustering on a small scale but with regularity on a larger scale. On average the event locations are CSR as indicated by the \\(K\\) function. suppressMessages(library(spatstat)) set.seed(0112) X &lt;- rcell(nx = 15) plot(X, main = &quot;&quot;) There are two ‘local’ clusters one in the north and one in the south. But overall the events appear to be more regular (inhibition) than CSR. Interpretation of the process that created the event locations based on Ripley’s \\(K\\) would be that the arrangement of events is CSR. library(ggplot2) K.df &lt;- X |&gt; Kest() |&gt; as.data.frame() ggplot(K.df, aes(x = r, y = iso)) + geom_line() + geom_line(aes(y = theo), color = &quot;red&quot;) + xlab(&quot;Lag distance (km)&quot;) + ylab(&quot;K(r)&quot;) + theme_minimal() The empirical curve (black line) coincides with the theoretical CSR line (red line) indicating CSR. And the maximum absolute deviation test under the null hypothesis of CSR returns a large \\(p\\)-value so you fail to reject it. mad.test(X, fun = Kest, nsim = 99) ## Generating 99 simulations of CSR ... ## 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, ## 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, ## 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99. ## ## Done. ## ## Maximum absolute deviation test of CSR ## Monte Carlo test based on 99 simulations ## Summary function: K(r) ## Reference function: theoretical ## Alternative: two.sided ## Interval of distance values: [0, 0.25] ## Test statistic: Maximum absolute deviation ## Deviation = observed minus theoretical ## ## data: X ## mad = 0.0023931, rank = 87, p-value = 0.87 As an example of the former case, here you generate event locations that have no inter-event interaction but there is a trend in the spatial intensity. X &lt;- rpoispp(function(x, y){ 300 * exp(-3 * x) }) plot(X, main = &quot;&quot;) By design there is a clear trend toward fewer events moving toward the east. You compute and plot the \\(K\\) function on these event locations. K.df &lt;- X |&gt; Kest() |&gt; as.data.frame() ggplot(K.df, aes(x = r, y = iso)) + geom_line() + geom_line(aes(y = theo), color = &quot;red&quot;) + xlab(&quot;Lag distance (km)&quot;) + ylab(&quot;K(r)&quot;) + theme_minimal() The \\(K\\) function indicates clustering but this is an artifact of the trend in the intensity. In the case of a known trend in the spatial intensity, you need to use the Kinhom() function. For example, compare the uncertainty envelopes from a homogeneous and inhomogeneous Poisson process. Start by plotting the output from the envelope() function with fun = Kest. The global = TRUE argument indicates that the envelopes are simultaneous rather than point-wise (global = FALSE which is the default). Point-wise envelopes assume the estimates are independent (usually not a good assumption) across the range of distances so the standard errors will be smaller resulting in narrower bands. Kenv &lt;- envelope(X, fun = Kest, nsim = 39, rank = 1, global = TRUE) ## Generating 39 simulations of CSR ... ## 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39. ## ## Done. Kenv.df &lt;- as.data.frame(Kenv) ggplot(Kenv.df, aes(x = r, y = obs)) + geom_ribbon(aes(ymin = lo, ymax = hi), fill = &quot;gray70&quot;) + geom_line() + geom_line(aes(y = theo), color = &quot;red&quot;, lty = &#39;dashed&#39;) + xlab(&quot;Lag distance (km)&quot;) + ylab(&quot;K(r)&quot;) + theme_minimal() After a distance of about .15 units the empirical curve (black line) is outside the uncertainty band indicating the events are more clustered than CSR. However when you use the fun = Kinhom the empirical curve is completely inside the uncertainty band. Kenv &lt;- envelope(X, fun = Kinhom, nsim = 99, rank = 1, global = TRUE) ## Generating 99 simulations of CSR ... ## 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, ## 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, ## 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99. ## ## Done. Kenv.df &lt;- as.data.frame(Kenv) ggplot(Kenv.df, aes(x = r, y = obs)) + geom_ribbon(aes(ymin = lo, ymax = hi), fill = &quot;gray70&quot;) + geom_line() + geom_line(aes(y = theo), color = &quot;red&quot;, lty = &#39;dashed&#39;) + xlab(&quot;Lag distance (km)&quot;) + ylab(&quot;K(r), Expected number of additional events\\n within a distance r of an event&quot;) + theme_minimal() You conclude that the point pattern data are consistent with an inhomogeneous Poisson process without event interaction. Let’s return to the Kansas tornadoes (EF1+). You import the data and create a point pattern object windowed by the state borders. Torn.sf &lt;- sf::st_read(dsn = here::here(&quot;data&quot;, &quot;1950-2020-torn-initpoint&quot;)) |&gt; sf::st_transform(crs = 3082) |&gt; dplyr::filter(mag &gt;= 1, yr &gt;= 1994) |&gt; dplyr::mutate(EF = as.factor(mag)) |&gt; dplyr::select(EF) ## Reading layer `1950-2020-torn-initpoint&#39; from data source ## `/Users/jameselsner/Desktop/ClassNotes/ASS-2022/data/1950-2020-torn-initpoint&#39; ## using driver `ESRI Shapefile&#39; ## Simple feature collection with 66244 features and 22 fields ## Geometry type: POINT ## Dimension: XY ## Bounding box: xmin: -163.53 ymin: 17.7212 xmax: -64.7151 ymax: 61.02 ## Geodetic CRS: WGS 84 ST.ppp &lt;- Torn.sf[&quot;EF&quot;] |&gt; as.ppp() KS.sf &lt;- USAboundaries::us_states(states = &quot;Kansas&quot;) |&gt; sf::st_transform(crs = sf::st_crs(Torn.sf)$proj4string) W &lt;- KS.sf |&gt; as.owin() ST.ppp &lt;- ST.ppp[W] |&gt; rescale(s = 1000, unitname = &quot;km&quot;) plot(ST.ppp) There are more tornado reports in the west than in the east, especially across the southern part of the state indicating the process producing the events is not homogeneous. This means there are other factors contributing to local event intensity. Evidence for clustering must account for this inhomogeneity. Here you do this by computing the envelope around the inhomogeneous Ripley K function using the argument fun = Kinhom. Kenv &lt;- envelope(ST.ppp, fun = Kinhom, nsim = 39, rank = 1, global = TRUE) ## Generating 39 simulations of CSR ... ## 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39. ## ## Done. Kenv.df &lt;- as.data.frame(Kenv) ggplot(Kenv.df, aes(x = r, y = obs)) + geom_ribbon(aes(ymin = lo, ymax = hi), fill = &quot;gray70&quot;) + geom_line() + geom_line(aes(y = theo), color = &quot;red&quot;, lty = &#39;dashed&#39;) + xlab(&quot;Lag distance (km)&quot;) + ylab(&quot;K(r)&quot;) + theme_minimal() The output reveals no evidence of clustering at distances less than about 70 km. At greater distances there is evidence of regularity indicated by the black line significantly below the red line. This is due to the fact that tornado reports are more common near cities and towns and cities and towns tend to be spread out more regular than CSR. Removing duplicate event locations and defining the domain The functions in the {spatstat} package require the event locations (as a ppp object) and a domain over which the spatial statistics are computed (as an owin object). If no owin object is specified, the statistics are computed over a rectangle (bounding box) defined by the northern most, southern most, eastern most, and western most event locations. To see this, consider the Florida wildfire data as a simple feature data frame. Extract only fires occurring in Baker County (west of Duval County–Jacksonville). Include only wildfires started by lightning and select the fire size variable. FL_Fires.sf &lt;- sf::st_read(dsn = here::here(&quot;data&quot;, &quot;FL_Fires&quot;)) |&gt; sf::st_transform(crs = 3086) ## Reading layer `FL_Fires&#39; from data source ## `/Users/jameselsner/Desktop/ClassNotes/ASS-2022/data/FL_Fires&#39; ## using driver `ESRI Shapefile&#39; ## Simple feature collection with 90261 features and 37 fields ## Geometry type: POINT ## Dimension: XY ## Bounding box: xmin: -9750382 ymin: 2824449 xmax: -8908899 ymax: 3632749 ## Projected CRS: Mercator_2SP Baker.sf &lt;- USAboundaries::us_counties(states = &quot;FL&quot;) |&gt; dplyr::select(name) |&gt; dplyr::filter(name == &quot;Baker&quot;) |&gt; sf::st_transform(crs = 3086) BakerFires.sf &lt;- FL_Fires.sf |&gt; sf::st_intersection(Baker.sf) |&gt; dplyr::filter(STAT_CAU_1 == &quot;Lightning&quot;) |&gt; dplyr::select(FIRE_SIZE_) ## Warning: attribute variables are assumed to be spatially constant throughout all ## geometries Create a ppp object and an unmarked ppp object. Summarize the unmarked object and make a plot. BF.ppp &lt;- BakerFires.sf |&gt; as.ppp() BFU.ppp &lt;- unmark(BF.ppp) summary(BFU.ppp) ## Planar point pattern: 327 points ## Average intensity 1.797954e-07 points per square unit ## ## *Pattern contains duplicated points* ## ## Coordinates are given to 2 decimal places ## i.e. rounded to the nearest multiple of 0.01 units ## ## Window: rectangle = [547988.2, 587567.5] x [682872.2, 728823.8] units ## (39580 x 45950 units) ## Window area = 1818730000 square units plot(BFU.ppp) The average intensity is 18 wildfires per 10 square km. But the intensity is based on a square domain. The lack of events in the northeast part of the domain is due to the fact that you removed wildfires outside the county border. Further, two event locations are identical if their x,y coordinates are the same, and their marks are the same (if they carry marks). Remove duplicate events with the unique() function, set the domain to be the county border, and set the name for the unit of length to meters. BFU.ppp &lt;- unique(BFU.ppp) W &lt;- Baker.sf |&gt; as.owin() BFU.ppp &lt;- BFU.ppp[W] unitname(BFU.ppp) &lt;- &quot;meters&quot; summary(BFU.ppp) ## Planar point pattern: 322 points ## Average intensity 2.096214e-07 points per square meters ## ## Coordinates are given to 2 decimal places ## i.e. rounded to the nearest multiple of 0.01 meters ## ## Window: polygonal boundary ## single connected closed polygon with 17 vertices ## enclosing rectangle: [547588.2, 587682.5] x [681954.6, 731650.3] meters ## (40090 x 49700 meters) ## Window area = 1536100000 square meters ## Unit of length: 1 meters ## Fraction of frame area: 0.771 plot(BFU.ppp) Now the average intensity is 21 wildfires per 10 sq. km. Apply Ripley’s \\(K\\) function and graph the results. K.df &lt;- BFU.ppp |&gt; Kest() |&gt; as.data.frame() ggplot(K.df, aes(x = r, y = iso * intensity(BFU.ppp))) + geom_line() + geom_line(aes(y = theo * intensity(BFU.ppp)), color = &quot;red&quot;) + xlab(&quot;Lag distance (m)&quot;) + ylab(&quot;K(r), Expected number of additional wildfires\\n within a distance r of any wildfire&quot;) + theme_minimal() We see a difference indicating a cluster of event locations, but is the difference significant against a null hypothesis of a homogeneous Poisson? Kenv.df &lt;- envelope(BFU.ppp, fun = Kest, nsim = 39, rank = 1, global = TRUE) |&gt; as.data.frame() ## Generating 39 simulations of CSR ... ## 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39. ## ## Done. ggplot(Kenv.df, aes(x = r, y = obs)) + geom_ribbon(aes(ymin = lo, ymax = hi), fill = &quot;gray70&quot;) + geom_line() + geom_line(aes(y = theo), color = &quot;red&quot;, lty = &#39;dashed&#39;) + xlab(&quot;Lag distance (m)&quot;) + ylab(&quot;K(r)&quot;) + theme_minimal() Yes it is. Modeling point pattern data Models are helpful for trying to understanding the processes leading to the event locations when event interaction is suspected. Event interaction means that an event at one location changes the probability of an event nearby. Cluster models can be derived by starting with a Poisson model. For example, you begin with a homogeneous Poisson model \\(Y\\) describing a set of events. A model is homogeneous Poisson when the event locations generated by the model are CSR. Then consider each individual event \\(y_i\\) in \\(Y\\) to be a ‘parent’ that produces a set of ‘offspring’ events (\\(x_i\\)) according to some mechanism. The resulting set of offspring forms clustered point pattern data \\(X\\). Said another way, the model is homogeneous Poisson at an unobserved level \\(Y\\) (latent level) but clustered at the level of the observations (\\(X\\)). One example of this parent-child process is the Matern cluster model. Parent events come from a homogeneous Poisson process with intensity \\(\\kappa\\) and then each parent has a Poisson (\\(\\mu\\)) number of offspring that are iid within a radius \\(r\\) centered on the parent. For instance here you use the rMatClust() function from the {spatstat} package to produce a clustered ppp object. We use a disc radius of .1 units and an offspring rate equal to 5 (mu = 5). rMatClust(kappa = 10, r = .1, mu = 5) |&gt; plot(main = &quot;&quot;) The result is a set of event locations and the process that produced them is described as doubly Poisson. You can vary \\(\\kappa\\), \\(r\\), and \\(\\mu\\) to generate more or fewer events. Other clustered Poisson models include: - Thomas model: each cluster consists of a Poisson number of random events with each event having an isotropic Gaussian displacement from its parent. - Gauss-Poisson model: each cluster is either a single event or a pair of events. - Neyman-Scott model: the cluster mechanism is arbitrary. A Cox model is a homogeneous Poisson model with a random intensity function. Let \\(\\Lambda(s)\\) be a function with non-negative values defined at all locations \\(s\\) inside the domain. Then, conditional on \\(\\Lambda\\) let \\(X\\) be a Poisson model with an intensity function \\(\\Lambda\\). Then \\(X\\) will be a sample from a Cox model. An example of a Cox model is the mixed Poisson process in which a random variable \\(\\Lambda\\) is generated and then, conditional on \\(\\Lambda\\), a homogeneous Poisson process with intensity \\(\\Lambda\\) is generated. Following are two samples from a Cox point process. set.seed(3042) par(mfrow = c(1, 2)) for (i in 1:2){ lambda &lt;- rexp(n = 1, rate = 1/100) X &lt;- rpoispp(lambda) plot(X) } par(mfrow = c(1, 1)) The statistical moments of Cox models are defined in terms of the moments of \\(\\Lambda\\). For instance, the intensity function of \\(X\\) is \\(\\lambda(s)\\) = E[\\(\\Lambda(s)\\)], where E[] is the expected value. Cox models are convenient for describing clustered point pattern data. A Cox model is over-dispersed relative to a Poisson model (i.e. the variance of the number of events falling in any region of size A, is greater than the mean number of events in those regions). The Matern cluster model and the Thomas models are Cox models. Another common type of a Cox model is the log-Gaussian Cox processes (LGCP) model in which logarithm of \\(\\Lambda(s)\\) is a Gaussian random function. If you have a way of generating samples from a random function \\(\\Lambda\\) of interest, then you can use the rpoispp() function to generate the Cox process. The intensity argument lambda of rpoispp() can be a function of x or y or a pixel image. Another way to generate clustered point pattern data is by ‘thinning’. Thinning refers to deleting some of the events. With ‘independent thinning’ the fate of each event is independent of the fate of the other events. When independent thinning is applied to a homogeneous Poisson point pattern, the resulting point pattern consisting of the retained events is also Poisson. To simulate a inhibition process you can use a ‘thinning’ mechanism. An example of this is Matern’s Model I model. Here a homogeneous Poisson model first generates a point pattern \\(Y\\), then any event in \\(Y\\) that lies closer than a distance \\(r\\) from another event is deleted. This results in point pattern data whereby close neighbor events do not exist. plot(rMaternI(kappa = 70, r = .05), main = &quot;&quot;) X &lt;- rMaternI(kappa = 70, r = .05) X |&gt; Kest() |&gt; plot() Changing \\(\\kappa\\) and \\(r\\) will change the event intensity. The various spatial models for event locations can be described with math. For instance, expanding on the earlier notation you write that a homogeneous Poisson model with intensity \\(\\lambda &gt; 0\\) has intensity \\[\\lambda(s, x) = \\lambda\\] where \\(s\\) is any location in the window W and \\(x\\) is the set of events. Then the inhomogeneous Poisson model has conditional intensity \\[\\lambda(s, x) = \\lambda(s)\\]. The intensity \\(\\lambda(s)\\) depends on a spatial trend or on an explanatory variable. There is also a class of ‘Markov’ point process models that allow for clustering (or inhibition) due to event interaction. Markov refers to the fact that the interaction is limited to nearest neighbors. Said another way, a Markov point process generalizes a Poisson process in the case where events are pairwise dependent. A Markov process with parameters \\(\\beta &gt; 0\\) and \\(0 &lt; \\gamma &lt; \\infty\\) with interaction radius \\(r &gt; 0\\) has conditional intensity \\(\\lambda(s, x)\\) given by \\[ \\lambda(s, x) = \\beta \\gamma^{t(s, x)} \\] where \\(t(s, x)\\) is the number of events that lie within a distance \\(r\\) of location \\(s\\). Three cases: - If \\(\\gamma = 1\\), then \\(\\lambda(s, x) = \\beta\\) No interaction between events, \\(\\beta\\) can vary with \\(s\\). - If \\(\\gamma &lt; 1\\), then \\(\\lambda(s, x) &lt; \\beta\\). Events inhibit nearby events. - If \\(\\gamma &gt; 1\\), then \\(\\lambda(s, x) &gt; \\beta\\). Events encourage nearby events. Note the distinction between the interaction term \\(\\gamma\\) and the trend term \\(\\beta\\). Note: A similar distinction exists between autocorrelation \\(\\rho\\) and trend \\(\\beta\\) in spatial regression models. More generally, you write the logarithm of the conditional intensity \\(\\log[\\lambda(s, x)]\\) as linear expression with two components. \\[ \\log\\big[\\lambda(s, x)\\big] = \\theta_1 B(s) + \\theta_2 C(s, x) \\] where the \\(\\theta\\)’s are model parameters that need to be estimated. The term \\(B(s)\\) depends only on location so it represents trend and explanatory variable (covariate) effects. It is the ‘systematic component’ of the model. The term \\(C(s, x)\\) represents stochastic interactions (dependency) between events. Fitting and interpreting an inhibition model The {spatstat} package contains functions for fitting statistical models to point pattern data. Models can include trend (to account for non-stationarity), explanatory variables (covariates), and event interactions of any order (in other words, interactions are not restricted to pairwise). Models are fit with the method of maximum likelihood and the method of minimum contrasts. The method of maximum likelihood estimates the probability of the empirical \\(K\\) curve given the theoretical curve for various parameter values. Parameter values are chosen so as to maximize the likelihood of the empirical curve. The method of minimum contrasts derives a cost function as the difference between the theoretical and empirical \\(K\\) curves. Parameter values for the theoretical curve are those that minimize this cost function. The ppm() function is used to fit a spatial point pattern model. The syntax has the form ppm(X, formula, interaction, ...) where X is the point pattern object of class ppp, formula describes the systematic (trend and covariate) part of the model, and interaction describes the stochastic dependence between events (e.g., Matern process). Recall a plot of the Swedish pine saplings. There was no indication of a trend (no systematic variation in the intensity of saplings). SP &lt;- swedishpines plot(SP) intensity(SP) ## [1] 0.007395833 There is no obvious spatial trend in the distribution of saplings and the average intensity is .0074 saplings per unit area. A plot of the Ripley’s \\(K\\) function indicated regularity relative to CSR. SP |&gt; Kest(correction = &quot;iso&quot;) |&gt; plot() The red dashed line is the \\(K\\) curve under CSR. The black line is the empirical curve. At lag distances of between 5 and 15 units the empirical curve is below the CSR curve indicating there are fewer events within other events at those scales than would be expected by chance. This suggests a physical process whereby saplings tend to compete for sunlight, nutrients, etc. A process of between-event inhibition. If you suspect that the spatial distribution of event locations is influenced by inhibition you can model the process statistically. A simple inhibition model is a Strauss process when the inhibition is constant with a fixed radius (r) around each event. The amount of inhibition ranges between zero (100% chance of a nearby event) to complete (0% chance of a nearby event). In the case of no inhibition the process is equivalent to a homogeneous Poisson process. If you assume the inhibition process is constant across the domain with a fixed interaction radius (r), then you can fit a Strauss model to the data. You use the ppm() function from the {spatstat} package and include the point pattern data as the first argument. You set the trend term to a constant (implying a stationary process) with the argument trend ~ 1 and the interaction radius to 10 units with the argument interaction = Strauss(r = 10). Finally you use a border correction out to a distance of 10 units from the window with the rbord = argument. Save the output in the object called model.in (inhibition model). model.in &lt;- ppm(SP, trend = ~ 1, interaction = Strauss(r = 10), rbord = 10) The value for r in the Strauss() function is based on our visual inspection of the plot of Kest(). A value is chosen that represents the distance at which there is the largest departure from a CSR model. You inspect the model parameters by typing the object name. model.in ## Stationary Strauss process ## ## First order term: beta = 0.07567442 ## ## Interaction distance: 10 ## Fitted interaction parameter gamma: 0.2752048 ## ## Relevant coefficients: ## Interaction ## -1.29024 ## ## For standard errors, type coef(summary(x)) The first-order term (beta) has a value of .0757. This is the intensity of the ‘proposal’ events. The value of beta exceeds the average intensity by a factor of ten. Recall the intensity of the events is obtained as intensity(SP) ## [1] 0.007395833 The interaction parameter (gamma) is .275. It is less than one, indicating an inhibition process. The logarithm of gamma, called the interaction coefficient (Interaction), is -1.29. Interaction coefficients less than zero imply inhibition. A table with the coefficients including the standard errors and uncertainty ranges is obtained with the coef() method. model.in |&gt; summary() |&gt; coef() ## Estimate S.E. CI95.lo CI95.hi Ztest Zval ## (Intercept) -2.581315 0.4524077 -3.468018 -1.6946123 *** -5.705728 ## Interaction -1.290240 0.2375515 -1.755832 -0.8246475 *** -5.431411 The output includes the Interaction coefficient along with it’s standard error (S.E.) and the associated 95% uncertainty interval. The ratio of the Interaction coefficient to its standard error is the Zval. A large z-value (in absolute magnitude) translates to a low \\(p\\)-value and a rejection of the null hypothesis of no interaction between events. Output also is the estimated value for the (Intercept) term. It is the logarithm of the beta value, so exp(-2.58) = .0757 is the intensity of the proposal events. You interpret the model output as follows. The process producing the spatial pattern of pine saplings is such that you should see .0757 saplings per unit area [unobserved (latent) rate]. But because of event inhibition, where saplings nearby other saplings fail to grow, the number of saplings is reduced to .0074 per unit area. Thus the spatial pattern is suggestive of sibling-sibling interaction. Adults have many offspring, but only some survive due to limited resources. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
