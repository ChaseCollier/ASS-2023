[["thursday-december-1-2022.html", "Thursday December 1, 2022 Interpolating to areal units (block kriging) Simulating spatial fields Interpolating multiple variables Machine learning for spatial interpolation", " Thursday December 1, 2022 “Practice any art, music, singing, dancing, acting, drawing, painting, sculpting, poetry, fiction, essays, reportage, no matter how well or badly, not to get money &amp; fame, but to experience becoming, to find out what’s inside you, to make your soul grow.” - Kurt Vonnegut Interpolating to areal units (block kriging) As a way to reinforce the procedures involved with a statistical spatial interpolation, let’s look at another example. The example will highlight additional aspects of the procedure like better plots, variogram maps, anisotropy, and block kriging. In 2008 tropical cyclone (TC) Fay formed from a tropical wave near the Dominican Republic, passed over the island of Hispaniola, Cuba, and the Florida Keys, then crossed the Florida peninsula and moved westward across portions of the Panhandle producing heavy rains in parts of the state. Rainfall is an example of geostatistical data. In principle it can be measured anywhere, but typically you have values at a sample of sites. Interest centers on making inferences about how much rain fell across the region. Storm total rainfall amounts from stations in and around the state are in FayRain.txt on my website. They are reports from official weather sites and cooperative sites. The cooperative sites are the Community Collaborative Rain, Hail and Snow Network (CoCoRaHS), a community-based, high density precipitation network made up of volunteers who take measurements of precipitation on their property. The data were obtained from NOAA/NCEP/HPC and from the Florida Climate Center. Import the data. L &lt;- &quot;http://myweb.fsu.edu/jelsner/temp/data/FayRain.txt&quot; ( FR.df &lt;- readr::read_table(L) ) ## ## ── Column specification ──────────────────────────────────────────────────────── ## cols( ## lon = col_double(), ## lat = col_double(), ## tpi = col_double(), ## tpm = col_double() ## ) ## # A tibble: 803 × 4 ## lon lat tpi tpm ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 -82.4 29.7 7.4 188. ## 2 -82.3 29.8 9.99 254. ## 3 -82.4 29.6 8.01 203. ## 4 -82.4 29.6 5.71 145. ## 5 -82.1 30.2 10.8 273. ## 6 -82.3 30.3 14.3 364. ## 7 -80.6 28.0 14.0 356. ## 8 -80.5 28.0 14.5 369. ## 9 -80.6 28.4 0 0 ## 10 -80.7 28.3 13.6 346. ## # … with 793 more rows The data frame contains 803 rainfall sites. Longitude and latitude coordinates of the sites are given in the first two columns and total rainfall in inches and millimeters are given in the second two columns. Create a spatial points data frame by specifying columns that contain the spatial coordinates. Then assign a geographic coordinate system and convert the rainfall from millimeters to centimeters. FR.sf &lt;- sf::st_as_sf(x = FR.df, coords = c(&quot;lon&quot;, &quot;lat&quot;), crs = 4326) |&gt; dplyr::mutate(tpm = tpm/10) summary(FR.sf$tpm) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.000 8.306 15.799 17.631 24.372 60.223 The median rainfall across all available observations is 15.8 cm and the highest is 60.2 cm. Get the Florida county boundaries from the {USAboundaries} package. FL.sf &lt;- USAboundaries::us_counties(states = &quot;Florida&quot;) Transform the geographic coordinates of the site locations and map polygons to projected coordinates. Here you use Florida GDL Albers (EPSG:3087) with meter as the length unit. FR.sf &lt;- sf::st_transform(FR.sf, crs = 3087) FL.sf &lt;- sf::st_transform(FL.sf, crs = 3087) sf::st_crs(FR.sf) ## Coordinate Reference System: ## User input: EPSG:3087 ## wkt: ## PROJCRS[&quot;NAD83(HARN) / Florida GDL Albers&quot;, ## BASEGEOGCRS[&quot;NAD83(HARN)&quot;, ## DATUM[&quot;NAD83 (High Accuracy Reference Network)&quot;, ## ELLIPSOID[&quot;GRS 1980&quot;,6378137,298.257222101, ## LENGTHUNIT[&quot;metre&quot;,1]]], ## PRIMEM[&quot;Greenwich&quot;,0, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ## ID[&quot;EPSG&quot;,4152]], ## CONVERSION[&quot;Florida GDL Albers (meters)&quot;, ## METHOD[&quot;Albers Equal Area&quot;, ## ID[&quot;EPSG&quot;,9822]], ## PARAMETER[&quot;Latitude of false origin&quot;,24, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ## ID[&quot;EPSG&quot;,8821]], ## PARAMETER[&quot;Longitude of false origin&quot;,-84, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ## ID[&quot;EPSG&quot;,8822]], ## PARAMETER[&quot;Latitude of 1st standard parallel&quot;,24, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ## ID[&quot;EPSG&quot;,8823]], ## PARAMETER[&quot;Latitude of 2nd standard parallel&quot;,31.5, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ## ID[&quot;EPSG&quot;,8824]], ## PARAMETER[&quot;Easting at false origin&quot;,400000, ## LENGTHUNIT[&quot;metre&quot;,1], ## ID[&quot;EPSG&quot;,8826]], ## PARAMETER[&quot;Northing at false origin&quot;,0, ## LENGTHUNIT[&quot;metre&quot;,1], ## ID[&quot;EPSG&quot;,8827]]], ## CS[Cartesian,2], ## AXIS[&quot;easting (X)&quot;,east, ## ORDER[1], ## LENGTHUNIT[&quot;metre&quot;,1]], ## AXIS[&quot;northing (Y)&quot;,north, ## ORDER[2], ## LENGTHUNIT[&quot;metre&quot;,1]], ## USAGE[ ## SCOPE[&quot;State-wide spatial data management.&quot;], ## AREA[&quot;United States (USA) - Florida.&quot;], ## BBOX[24.41,-87.63,31.01,-79.97]], ## ID[&quot;EPSG&quot;,3087]] Start by making a map of the rainfall sites and storm total rainfall that includes the state border. tmap::tm_shape(FR.sf) + tmap::tm_dots(col = &quot;tpm&quot;, size = .5) + tmap::tm_shape(FL.sf) + tmap::tm_borders() Two areas of very heavy rainfall are noted. One running north-south along the east coast and another across the north centered on Tallahassee. Rainfall reporting sites are clustered in and around cities and are located only over land. This type of station location arrangement will make it hard for deterministic interpolation methods (e.g., IDW or splines) to produce a reasonable surface. The empirical variogram is computed using the variogram() function from the {gstat} package. The first argument is the model formula specifying the rainfall column from the data frame and the second argument is the data frame name. Here ~ 1 in the model formula indicates no covariates or trends in the data. Trends are included by specifying coordinate names through the st_coordinates() function. Compute the empirical variogram for these set of rainfall values. Use a cutoff distance of 400 km (400,000 m). The cutoff is the separation distance up to which point pairs are included in the semivariogram. The smaller the cutoff value the more the variogram is focused on nearest neighbor locations. library(gstat) v &lt;- variogram(tpm ~ 1, data = FR.sf, cutoff = 400000) Plot the variogram values as a function of lag distance and add text indicating the number of point pairs for each lag distance. Save a copy of the plot. library(ggplot2) v.df &lt;- data.frame(dist = v$dist/1000, gamma = v$gamma, np = v$np) ( pv &lt;- ggplot(v.df, aes(x = dist, y = gamma)) + geom_point() + geom_text(aes(label = np), nudge_y = -5) + scale_y_continuous(limits = c(0, 220)) + scale_x_continuous(limits = c(0, 400)) + xlab(&quot;Lagged distance (h) [km]&quot;) + ylab(expression(paste(&quot;Semivariance (&quot;, gamma, &quot;) [&quot;, cm^2, &quot;]&quot;))) + theme_minimal() ) Values start low (around 50 cm\\(^2\\)) at the shortest lag distance and increase to greater than 200 cm\\(^2\\) at lag distances of 200 km and longer. The semivariance at lag zero is called the ‘nugget’ and the semivariance at a level where the variogram values no longer increase is called the ‘sill.’ The difference between the sill and the nugget is called the ‘partial sill’. The lag distance out to where the sill is reached is called the ‘range.’ These three parameters (nugget, partial sill, and range) are used to model the variogram. Next fit a model to the empirical variogram. The model is a mathematical relationship that defines the semivariance as a function of lag distance. First save the family and the initial parameter guesses in a variogram model (vmi) object. vmi &lt;- vgm(model = &quot;Gau&quot;, psill = 150, range = 200 * 1000, nugget = 50) vmi ## model psill range ## 1 Nug 50 0e+00 ## 2 Gau 150 2e+05 The psill argument is the partial sill along the vertical axis. Estimate the parameter values by looking at the empirical variogram. Next use the fit.variogram() function to improve the fit over these initial values. Given a set of initial parameter values the method of weighted least squares is used to improve the parameter estimates. vm &lt;- fit.variogram(object = v, model = vmi) vm ## model psill range ## 1 Nug 46.58044 0.0 ## 2 Gau 156.24464 127724.3 The result is a variogram model with a nugget of 46.6 cm\\(^2\\), a partial sill of 156 cm\\(^2\\), and a range on the sill of 128 km. Plot the model on top of the empirical variogram. Let \\(r\\) be the range, \\(c\\) the partial sill and \\(c_o\\) the nugget, then the equation defining the function over the set of lag distances \\(h\\) is \\[ \\gamma(h)=c\\left(1-\\exp\\left(-\\frac{h^2}{r^2}\\right)\\right)+c_o \\] Create a data frame with values of h and gamma using this equation. nug &lt;- vm$psill[1] ps &lt;- vm$psill[2] r &lt;- vm$range[2] / 1000 h &lt;- seq(0, 400, .2) gamma &lt;- ps * (1 - exp(-h^2 / (r^2))) + nug vm.df &lt;- data.frame(dist = h, gamma = gamma) pv + geom_line(data = vm.df, mapping = aes(x = dist, y = gamma)) Check for anisotropy. Anisotropy refers to a dependence of the variogram shape on the direction of the location pairs used to compute semivariances. Isotropy refers to a directional independence. plot(variogram(tpm ~ 1, data = FR.sf, alpha = c(0, 45, 90, 135), cutoff = 400000), xlab = &quot;Lag Distance (m)&quot;) The semivariance values reach the sill at a longer range (about 300 km) in the north-south direction (0 degrees) compared to the other three directions. Another way to look at directional dependence in the variogram is through a variogram map. Instead of classifying point pairs Z(s) and Z(s + h) by direction and distance class separately, you classify them jointly. If h = {x, y} is the two-dimensional coordinates of the separation vector, in the variogram map the variance contribution of each point pair (Z(s) − Z(s + h))^2 is attributed to the grid cell in which h lies. The map is centered at (0, 0) and h is lag distance. Cutoff and width correspond to map extent and cell size; the semivariance map is point-wise symmetric around (0, 0), as γ(h) = γ(−h). The variogram map is made with the variogram() function by adding the map = TRUE argument. Here you set the cutoff to be 200 km (200,000 m) and the width (cell size) to be 20 km. vmap &lt;- variogram(tpm ~ 1, data = FR.sf, cutoff = 200000, width = 20000, map = TRUE) plot(vmap) Along the dx = 0 vertical line in the north-south direction (top-to-bottom on the plot), the semivariance values increase away from dy = 0, but the increase is less compared to along the dy = 0 horizontal line in the east-west direction (left-to-right on the plot) indicative of directional dependency. You refit the variogram model defining an anisotropy ellipse with the anis = argument. The first value is the direction of longest range (here north-south) and the second value is the ratio of the longest to shortest ranges. Here about (200/300 = .67, see the directional variogram plot above). vmi &lt;- vgm(model = &quot;Gau&quot;, psill = 150, range = 300 * 1000, nugget = 50, anis = c(0, .67)) vm &lt;- fit.variogram(v, vmi) Use the variogram model together with the rainfall values at the observation sites to create an interpolated surface. Here you use ordinary kriging as there are no spatial trends in the rainfall. Interpolation is done using the krige() function. The first argument is the model specification and the second is the data. Two other arguments are needed. One is the variogram model using the argument name model = and the other is a set of locations identifying where the interpolations are to be made. This is specified with the argument name newdata =. Here you interpolate to locations on a regular grid. You create a grid of locations within the borders of the state using the st_sample() function. grid.sfc &lt;- sf::st_sample(FL.sf, size = 5000, type = &quot;regular&quot;) You specify the number of grid locations using the argument size =. Note that the actual number of locations will be somewhat different because of the irregular boundary. grid.sfc |&gt; plot(pch = &quot;.&quot;) First use the krige() function to interpolate the observed rainfall to the grid locations. For a given location, the interpolation is a weighted average of the rainfall across the entire region where the weights are determined by the variogram model. r.int &lt;- krige(tpm ~ 1, locations = FR.sf, newdata = grid.sfc, model = vm) ## [using ordinary kriging] If the variogram model is not included then inverse distance-weighted interpolation is performed. The function will not work if a location has more than one value. The saved object (r.int) inherits the spatial geometry specified in the newdata = argument but extends it to a spatial data frame. The column var1.pred in the data frame is the interpolated rainfall and the second var1.var is the variability about the interpolated value. Plot the interpolated storm-total rainfall field. tmap::tm_shape(r.int) + tmap::tm_dots(&quot;var1.pred&quot;, size = .1, palette = &quot;Greens&quot;, title = &quot;Rainfall (cm)&quot;) + tmap::tm_shape(FL.sf) + tmap::tm_borders() + tmap::tm_layout(legend.position = c(&quot;left&quot;, &quot;bottom&quot;), title = &quot;TC Fay (2008)&quot;, title.position = c(&quot;left&quot;, &quot;bottom&quot;), legend.outside = TRUE) Note: a portion of the data locations are outside of the state but interest is only interpolated values within the state border as specified by the newdata = argument. The spatial interpolation shows that parts of east central and north Florida were deluged by Fay with rainfall totals exceeding 30 cm (12 in). The interpolation can also be done as an area average. For example what was the storm-total average rainfall for each county? County level rainfall is relevant for water resource managers. Block kriging produces an estimate of this area average, which will differ from a simple average over all sites within the county because of the spatial autocorrelation in rainfall observations. You use the same function to interpolate but specify the spatial polygons rather than the spatial grid as the new data. Here the spatial polygons are the county borders. r.int2 &lt;- krige(tpm ~ 1, locations = FR.sf, newdata = FL.sf, model = vm) ## [using ordinary kriging] Again plot the interpolations. tmap::tm_shape(r.int2) + tmap::tm_polygons(col = &quot;var1.pred&quot;, palette = &quot;Greens&quot;, title = &quot;Rainfall (cm)&quot;) + tmap::tm_layout(legend.position = c(&quot;left&quot;, &quot;bottom&quot;), title = &quot;TC Fay (2008)&quot;, title.position = c(&quot;left&quot;, &quot;bottom&quot;)) The overall pattern of rainfall from Fay featuring the largest amounts along the central east coast and over the Big Bend region are similar in both maps but these estimates answer questions like on average how much rain fell over Leon County during TC Fay? You compare the kriged average with the simple average at the county level with the aggregate() method. The argument FUN = mean says to compute the average of the values in FR.sf across the polygons in FL.sf. r.int3 &lt;- aggregate(FR.sf, by = FL.sf, FUN = mean) The result is a simple feature data frame of the average rainfall in each county. The state-wide mean of the kriged estimates at the county level is r.int2$var1.pred |&gt; mean() |&gt; round(2) ## [1] 21.1 This compares with a state-wide mean from the simple averages. r.int3$tpm |&gt; mean() |&gt; round(2) ## [1] 20.85 The correlation between the two estimates across the 67 counties is round(cor(r.int3$tpm, r.int2$var1.pred), 2) ## [1] 0.87 The variogram model reduces the standard deviation of the kriged estimate relative to the standard deviation of the simple averages because of local smoothing. r.int2$var1.pred |&gt; sd() |&gt; round(2) ## [1] 8.06 r.int3$tpm |&gt; sd() |&gt; round(2) ## [1] 9.83 This can be seen with a scatter plot of simple averages versus kriged averages at the county level. compare.df &lt;- data.frame(simpleAvg = r.int3$tpm, krigeAvg = r.int2$var1.pred) ggplot(compare.df, aes(x = simpleAvg, y = krigeAvg)) + geom_point() + geom_abline(slope = 1) + geom_smooth(method = lm, se = FALSE) ## `geom_smooth()` using formula &#39;y ~ x&#39; The slope of the blue line is less than the black line (y = x line) indicating kriging over estimates at low amounts and under estimates at high amounts relative to simple averaging. Kriging has the advantage of accompanying uncertainty estimates. The prediction variances are listed in a column in the spatial data frame saved from apply the krige() function. Variances are smaller in regions with more rainfall observations. Prediction variances are also smaller with block kriging as much of the variability within the county averages out. To compare the distribution characteristics of the prediction variances for point and block kriging of the rainfall observations, type r.int$var1.var |&gt; summary() |&gt; round(1) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 47.4 49.1 50.2 51.1 52.3 104.5 r.int2$var1.var |&gt; summary() |&gt; round(1) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.6 1.9 2.7 3.1 3.8 9.2 The median prediction variance (in cm\\(^2\\)) for the point kriging is close to the value of the nugget. r.int$var1.var |&gt; median() |&gt; round(1) ## [1] 50.2 In contrast, the median prediction variance for our block kriging is a much smaller. r.int2$var1.var |&gt; median() |&gt; round(1) ## [1] 2.7 Simulating spatial fields Simulations use the interpolated uncertainty to provide additional data for deterministic models. Suppose you have a hydrology model of rainfall runoff. Given a spatial field of rain amounts the model predicts a discharge rate at some location along a river. The uncertainty in the predicted runoff rate at the location is due to the uncertainty in where and how hard the rain fell (in the rainfall field) and not due to the deterministic hydrology model. The uncertainty in the rainfall field is simulated conditional on the observations with the same krige() function by adding the argument nsim = that specifies the number of simulations. For a large number it may be necessary to limit the number neighbors in the kriging. This is done using the nmax argument. For a given location, the weights assigned to observations far away are very small, so it is efficient to limit how many are used in the simulation. As an example, here you generate four realizations of the county-level average storm total rainfall for Fay and limit the neighborhood to 50 of the closest observation sites. This takes a few seconds. r.sim &lt;- krige(tpm ~ 1, locations = FR.sf, newdata = FL.sf, model = vm, nsim = 4, nmax = 50) ## drawing 4 GLS realisations of beta... ## [using conditional Gaussian simulation] Given the variogram model, the simulations are conditional on the observed rainfall. tmap::tm_shape(r.sim) + tmap::tm_polygons(col = c(&quot;sim1&quot;, &quot;sim2&quot;, &quot;sim3&quot;, &quot;sim4&quot;), palette = &quot;Greens&quot;, title = &quot;Simulated Rainfall [cm]&quot;) + tmap::tm_facets(free.scales = FALSE) The overall pattern of rainfall remains the same, but there are differences especially in counties with fewer observations and in counties where the rainfall gradients are sharp. Interpolating multiple variables Spatial interpolation can be extended to obtain surfaces of multiple variables. The idea is that if two variables are correlated then information about the spatial correlation in one variable can help provide information about values in the other variable. The spatial variability of one variable is correlated with the spatial variability of the other variable. And this idea is not limited to two variables. Here you consider observations of heavy metal concentrations (ppm) in the top soil in the flood plain of the river Meuse near the village of Stein. The data are available in {sp} package. library(sp) data(meuse) names(meuse) ## [1] &quot;x&quot; &quot;y&quot; &quot;cadmium&quot; &quot;copper&quot; &quot;lead&quot; &quot;zinc&quot; &quot;elev&quot; ## [8] &quot;dist&quot; &quot;om&quot; &quot;ffreq&quot; &quot;soil&quot; &quot;lime&quot; &quot;landuse&quot; &quot;dist.m&quot; The metals include cadmium, copper, lead, and zinc. Observation locations are given by x and y. Other variables include elevation, soil type and distance to the river (meters). Create a simple feature data frame with a projected coordinate system for the Netherlands. meuse.sf &lt;- sf::st_as_sf(x = meuse, coords = c(&quot;x&quot;, &quot;y&quot;), crs = 28992) Interest is on a spatial interpolation of all four heavy metals in the soil. Map the concentrations at the observation locations. tmap::tmap_mode(&quot;view&quot;) ## tmap mode set to interactive viewing tmap::tm_shape(meuse.sf) + tmap::tm_dots(col = c(&quot;cadmium&quot;, &quot;copper&quot;, &quot;lead&quot;, &quot;zinc&quot;)) All observations (bulk sampled from an area of approximately 15 m x 15 m) have units of ppm. The most abundant heavy metal is zinc followed by lead and copper. For all metals highest concentrations are found nearest to the river. Thus you want to include distance to river as a covariate (trend term) and use universal kriging. The distribution of concentrations is skewed with many locations having only low levels of heavy metals with a few having very high levels. ggplot(data = meuse.sf, mapping = aes(x = lead)) + geom_histogram(bins = 17) + theme_minimal() Thus you use logarithmic transformations. First you organize the data as a gstat object. This is done with the gstat() function which orders (and copies) the variables into a single object. Ordering is done succession. Here you specify the trend using the square root of the distance to river and take the natural logarithm of the heavy metal concentration. You give the dependent variable a new name with the id = argument. g &lt;- gstat(id = &quot;logCd&quot;, formula = log(cadmium) ~ sqrt(dist), data = meuse.sf) g &lt;- gstat(g, id = &quot;logCu&quot;, formula = log(copper) ~ sqrt(dist), data = meuse.sf) g &lt;- gstat(g, id = &quot;logPb&quot;, formula = log(lead) ~ sqrt(dist), data = meuse.sf) g &lt;- gstat(g, id = &quot;logZn&quot;, formula = log(zinc) ~ sqrt(dist), data = meuse.sf) g ## data: ## logCd : formula = log(cadmium)`~`sqrt(dist) ; data dim = 155 x 12 ## logCu : formula = log(copper)`~`sqrt(dist) ; data dim = 155 x 12 ## logPb : formula = log(lead)`~`sqrt(dist) ; data dim = 155 x 12 ## logZn : formula = log(zinc)`~`sqrt(dist) ; data dim = 155 x 12 Next you use the variogram() function to compute multivariable sample variograms. The function, when operating on a gstat object, computes all direct and cross variograms. A direct variogram is the semivariance computed for a single variable (\\(z\\)). \\[ \\gamma(h) = \\frac{1}{2N(h)} \\sum^{N(h)} (z_i - z_j)^2 \\] A cross variogram is the semivariance computed between two variables (\\(z_1\\) and $z_2). \\[ \\gamma_c(h) = \\frac{1}{2N(h)} \\sum^{N(h)} (z_{1i} - z_{2j})^2 \\] v &lt;- g |&gt; variogram() v |&gt; plot() The individual plots are the direct and cross variograms. The direct variograms are shown in the four panels along the diagonal of the triangle of plots. The cross variograms are shown in the six panels below the diagonal. For example, the cross variogram between the values of cadmium (\\(z_1\\) = cadmium) and copper (\\(z_2\\) = copper) is given in the second row of the first column and so on. The cross variogram is analogous to the multi-type \\(K\\) function for analyzing point pattern data. The cross variograms show small semivariance values at short lag distance with increasing semivariance values at longer lags. Because these variables are co-located, you can also compute direct correlations. cor(meuse[c(&quot;cadmium&quot;, &quot;copper&quot;, &quot;lead&quot;, &quot;zinc&quot;)]) ## cadmium copper lead zinc ## cadmium 1.0000000 0.9254499 0.7989466 0.9162139 ## copper 0.9254499 1.0000000 0.8183069 0.9082695 ## lead 0.7989466 0.8183069 1.0000000 0.9546913 ## zinc 0.9162139 0.9082695 0.9546913 1.0000000 The direct correlation between cadmium and copper is .92 and between cadmium and lead is .8. The correlation matrix confirms strong relationships among the four variables at zero lag. The cross variogram generalizes these correlations across lag distance (\\(h\\)). For instance, the cross variogram indicates the strength of the relationship between cadmium at one location and copper at nearby locations. You use the fit.lmc() function to fit separate variogram models to each of the empirical variograms. The first argument in the function is the multivariable sample variogram and the second argument is the gstat object. The third argument is the initial model estimates. Here you set the initial estimates using a spherical model with a nugget of zero, a partial sill of .5 and a range of 800 m. vmi &lt;- vgm(model = &quot;Sph&quot;, psill = .5, nugget = 0, range = 800) vm &lt;- fit.lmc(v, g, model = vmi) plot(v, vm) The final variogram models (blue line) fit the empirical variogram (direct and cross) well. Given the variogram models and the observations, co-kriged maps are produced using the predict() method after setting the grid locations for the interpolations. The meuse.grid data frame is converted to a simple feature data frame and with the CRS for the grid locations matching the CRS of the data. data(meuse.grid) grid.sf &lt;- sf::st_as_sf(x = meuse.grid, coords = c(&quot;x&quot;, &quot;y&quot;), crs = 28992) int &lt;- predict(vm, grid.sf) ## Linear Model of Coregionalization found. Good. ## [using universal cokriging] names(int) ## [1] &quot;logCd.pred&quot; &quot;logCd.var&quot; &quot;logCu.pred&quot; &quot;logCu.var&quot; ## [5] &quot;logPb.pred&quot; &quot;logPb.var&quot; &quot;logZn.pred&quot; &quot;logZn.var&quot; ## [9] &quot;cov.logCd.logCu&quot; &quot;cov.logCd.logPb&quot; &quot;cov.logCu.logPb&quot; &quot;cov.logCd.logZn&quot; ## [13] &quot;cov.logCu.logZn&quot; &quot;cov.logPb.logZn&quot; &quot;geometry&quot; The output include the interpolated values for each of the log heavy metals and the uncertainty. Plot the interpolations. tmap::tmap_mode(&quot;plot&quot;) ## tmap mode set to plotting tmap::tm_shape(int) + tmap::tm_dots(col = c(&quot;logCd.pred&quot;, &quot;logCu.pred&quot;, &quot;logPb.pred&quot;, &quot;logZn.pred&quot;), size = .2, breaks = seq(-2, 8, by = 1), palette = &quot;Reds&quot;, midpoint = NA) The pattern of heavy metal concentrations are similar with highest values along the river bank. It is interesting to compare the interpolations using only a single variable against the interpolations of the same variable when all variables are used. Here you do that for copper. v2 &lt;- variogram(log(copper) ~ sqrt(dist), data = meuse.sf) vm2 &lt;- fit.variogram(v2, model = vgm(psill = .15, model = &quot;Sph&quot;, range = 800, nugget = .1)) int2 &lt;- krige(log(copper) ~ sqrt(dist), locations = meuse.sf, newdata = grid.sf, model = vm2) ## [using universal kriging] Map together and compute the correlation. p1 &lt;- tmap::tm_shape(int2) + tmap::tm_dots(col = &quot;var1.pred&quot;, size = .2, palette = &quot;Reds&quot;) p2 &lt;- tmap::tm_shape(int) + tmap::tm_dots(col = &quot;logCu.pred&quot;, size = .2, palette = &quot;Reds&quot;) tmap::tmap_arrange(p1, p2) cor(int$logCu.pred, int2$var1.pred) ## [1] 0.9852909 Only minor differences are visible on the plot and the correlation between the two interpolations exceeds .98. Plot the covariances between zinc and cadmium. tmap::tm_shape(int) + tmap::tm_dots(col = &quot;cov.logCd.logZn&quot;, size = .2) The map shows areas of the flood plain with high (and low) covariances between cadmium and zinc. Higher values of the covariance indicate lower correlations. There is an inverse relationship between the correlogram and the covariogram. Kriging is useful tool for ‘filling in the gaps’ between sampling sites. Handy if you want to make a map, or need to match up two spatial data sets that overlap in extent, but have samples at different locations. Obtaining a quality statistical spatial interpolation is a nuanced process but with practice kriging can be an important tool in your toolbox. Machine learning for spatial interpolation See https://geocompr.robinlovelace.net/spatial-cv.html "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
