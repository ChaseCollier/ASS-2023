[["tuesday-april-4-2023.html", "Tuesday April 4, 2023 Spatial data as point patterns Theoretical framework for analyzing/modeling point pattern data Working with point pattern data using functions from the spatstat family of packages Quantifying the spatial intensity of events", " Tuesday April 4, 2023 “Give someone a program, you frustrate them for a day; teach them how to program, you frustrate them for a lifetime.” - David Leinweber Spatial data as point patterns We now turn our attention to analyzing and modeling point pattern data. We start with some theory, then learn how to work with functions from the {spatstat} package before focusing on estimating spatial intensity We naturally seek patterns within a collection of events. A pattern that often quickly gets our attention is clustering. Clusters of stars in the night sky were defined by the ancients as a constellation A cluster of events in a particular region begs for an explanation. Why do events occur more often in one region compared to another region? Consider tornado reports in the state of Kansas. Let the start position of a tornado be an event location and let the damage rating (EF scale) provide a mark on the event Here you consider only events since 2007 with marks of 1, 2, 3, 4, and 5. More about the damage rating scale is available here https://en.wikipedia.org/wiki/Enhanced_Fujita_scale Download and unzip the data file from the SPC archive if(!&quot;1950-2021-torn-inipoint&quot; %in% list.files()) { download.file(url = &quot;http://www.spc.noaa.gov/gis/svrgis/zipped/1950-2021-torn-initpoint.zip&quot;, destfile = here::here(&quot;data&quot;, &quot;1950-2021-torn-initpoint.zip&quot;)) unzip(zipfile = here::here(&quot;data&quot;, &quot;1950-2021-torn-initpoint.zip&quot;), exdir = &quot;data&quot;) } Import and filter the data accordingly Torn.sf &lt;- sf::st_read(dsn = here::here(&quot;data&quot;, &quot;1950-2021-torn-initpoint&quot;)) |&gt; dplyr::filter(st == &quot;KS&quot;, yr &gt;= 2007, mag &gt; 0) ## Reading layer `1950-2021-torn-initpoint&#39; from data source ## `/Users/jelsner/Desktop/ClassNotes/ASS-2023/data/1950-2021-torn-initpoint&#39; ## using driver `ESRI Shapefile&#39; ## Simple feature collection with 67558 features and 22 fields ## Geometry type: POINT ## Dimension: XY ## Bounding box: xmin: -163.53 ymin: 17.7212 xmax: -64.7151 ymax: 61.02 ## Geodetic CRS: WGS 84 Create a map of the event locations using functions from the {tmap} package. The state border is obtained as a simple feature data frame. The polygon geometry is plotted first with tm_borders() then the event locations are plotted with the tm_bubbles() and size = \"mag\" KS.sf &lt;- USAboundaries::us_states(states = &quot;Kansas&quot;) tmap::tm_shape(KS.sf) + tmap::tm_borders(col = &quot;grey70&quot;) + tmap::tm_shape(Torn.sf) + tmap::tm_bubbles(size = &quot;mag&quot;, col = &quot;red&quot;, alpha = .4, title.size = &quot;EF Rating&quot;) + tmap::tm_layout(legend.position = c(&quot;left&quot;, &quot;top&quot;), legend.outside = TRUE) Based on this map you ask: (1) Are certain areas of the state more likely to get a tornado? (2) Do tornadoes tend to cluster? (3) Are there places in the state that are completely safe from the threat of tornadoes? The questions are similar but they are not identical To make things more precise we begin with some definitions Event: An occurrence of interest (e.g., tornado, accident, wildfire) Event location: Location of event (e.g., latitude/longitude) Point: Any location in the study area where an event could occur. Across the state of Kansas a tornado can occur anywhere. However, in a forest with a lake, the lake is a place where a tree can not occur Note: Event location is a particular point where an event did occur Point pattern data: A collection of observed (or simulated) event locations together with a domain of interest. The event locations may contain additional information about the event. For example, the age of a tree Domain: Study area that is often defined by data availability (e.g., state or county boundary) or by the extent of the events Complete spatial randomness: Or CSR (not to be confused with CRS–coordinate reference system) defines the situation where an event has an equal chance of occurring at any point in the domain regardless of other nearby events Under the situation of CSR you say the event locations have a uniform probability distribution across space. Note: uniform chance does not mean that the events have an ordered pattern (e.g., trees in an orchard) Consider a set of event locations that are randomly distributed within the unit plane. First create two vectors containing the x and y coordinates, then create a data frame that includes the name of the sample, and then graph the locations using ggplot() library(ggplot2) x &lt;- runif(n = 50, min = 0, max = 1) y &lt;- runif(n = 50, min = 0, max = 1) df1 &lt;- data.frame(x, y, name = &quot;Point Pattern 1&quot;) ggplot(data = df1, mapping = aes(x = x, y = y)) + geom_point(size = 2) The plot shows a sample from a spatial point pattern process. A spatial point process is a mechanism (physical or synthetic) for producing a set of event locations. The pattern of locations produced by the point process is described as CSR. There are areas with relatively few events and areas with relative many events Let’s repeat this procedure creating three more samples. First combine them into a single data frame with the rbind() function and then plot a four-panel figure using the facet_wrap() function df2 &lt;- data.frame(x = runif(n = 30, min = 0, max = 1), y = runif(n = 30, min = 0, max = 1), name = &quot;Point Pattern 2&quot;) df3 &lt;- data.frame(x = runif(n = 30, min = 0, max = 1), y = runif(n = 30, min = 0, max = 1), name = &quot;Point Pattern 3&quot;) df4 &lt;- data.frame(x = runif(n = 30, min = 0, max = 1), y = runif(n = 30, min = 0, max = 1), name = &quot;Point Pattern 4&quot;) df &lt;- rbind(df1, df2, df3, df4) ggplot(data = df, mapping = aes(x = x, y = y)) + geom_point() + facet_wrap(~ name) These patterns illustrate the fact that a certain amount of clustering will occur simply by chance (without cause). This chance clustering confounds visual attempts to assess whether clustering is due to some causal mechanism or not Complete spatial randomness sits on a spectrum between regularity and clustered To illustrate this, here you generate point pattern data that have more regularity than CSR and point pattern data that are more clustered than CSR. You do this using the rMaternI() and rMaternClust() functions from the {spatstat} package m1 &lt;- spatstat.random::rMaternI(kappa = 200, r = .04) df1 &lt;- data.frame(x = m1$x, y = m1$y, name = &quot;Regularity Pattern 1&quot;) m2 &lt;- spatstat.random::rMaternI(kappa = 200, r = .04) df2 &lt;- data.frame(x = m2$x, y = m2$y, name = &quot;Regularity Pattern 2&quot;) m3 &lt;- spatstat.random::rMatClust(kappa = 30, r = .15, mu = 4) df3 &lt;- data.frame(x = m3$x, y = m3$y, name = &quot;Clustered Pattern 1&quot;) m4 &lt;- spatstat.random::rMatClust(kappa = 30, r = .15, mu = 4) df4 &lt;- data.frame(x = m4$x, y = m4$y, name = &quot;Clustered Pattern 2&quot;) df &lt;- rbind(df1, df2, df3, df4) ggplot(data = df, mapping = aes(x = x, y = y)) + geom_point() + facet_wrap(~ name) The difference in the arrangement of events between the two pattern types (clustered in the top two panels) can be visually detected. For example, given an event in a regularity pattern, there appears to always be more distance to the nearest neighbor event But the difference in the arrangement of events between a CSR and regular process and the difference in the arrangement of events between a CSR and cluster process is not And spatial scale matters. A set of event locations can be regular on a small scale but clustered on a larger scale Probability models for spatial patterns motivate methods for detecting event clustering. A probability model generates a point pattern process. For example, you can think of crime as a point pattern process defined by location and influenced by environmental factors. The probability of a crime occurring at a particular location is the random variable and you can estimate the probability of a crime event at any location given factors that influence crime Theoretical framework for analyzing/modeling point pattern data More formally, a spatial point pattern process is a stochastic (statistical) process where event location is the random variable. A sample of the process is a collection of events generated under the probability model A spatial point process is said to be stationary if the statistical properties of the resulting events are invariant to translation. This means that the relationship between two events depends on (1) the distance separating them and on (2) their relative orientation to each other, but not on where the two events are located in the domain A spatial point process is said to be isotropic if the statistical properties of the resulting events are invariant to rotation. This means that the relationship between two events depends only the separation distance. The inter-event distance between events is called the spatial lag The properties of stationarity and isotropy allow you to treat each region within the domain as independent. Assuming a stationary and isotropic point process, two event pairs that are separated by the same distance will have the same relatedness regardless of where the event pairs are located in the domain This is analogous to the assumption you make when computing a weights matrix for spatially aggregated data and when computing the variogram for spatial interpolation. The assumptions of stationarity and isotropy are starting points for modeling point pattern data The Poisson distribution defines a model for complete spatial randomness (CSR). A point process is said to be homogeneous Poisson under the following two criteria The number of events (N) occurring within a finite domain A is a random variable described by a Poisson distribution with mean \\(\\lambda\\) times |A| for some positive constant \\(\\lambda\\), with |A| denoting the area of the domain, and The locations of the N events represent a sample where each point in A is equally likely to be chosen as an event location The first criteria of a Poisson distribution refers to a probability model describing the number of events. It expresses the probability of a given number of events occurring in a fixed interval of space (and time) when the events occur with a known constant rate The Poisson parameter (lambda) defines the intensity of the point process. Given a set of events, an estimate for the mean (rate) parameter of the Poisson distribution is given by the number of events divided by the domain area. The second criteria ensures the events are scattered about the domain without clustering or regularity A procedure to create a homogeneous Poisson point process follows from its definition. Step 1: Choose the number of events from a Poisson distribution with a mean that is proportional to the domain area. Step 2: Place each event within the domain with coordinates given by a uniform distribution For example, let area |A| = 1, and the rate of occurrence \\(\\lambda\\) = 100, then the code below generates a CSR set of events lambda &lt;- 100 N &lt;- rpois(1, lambda) x &lt;- runif(N) y &lt;- runif(N) df &lt;- data.frame(x = x, y = y) ggplot(data = df, mapping = aes(x = x, y = y)) + geom_point(size = 2) The set of events represents a sample from a homogeneous Poisson point process. The intensity of the events is specified first then the locations are placed uniformly inside the domain. The domain need not be regular. The actual number of events varies from one realization to the next. On average the number of events is 100 but it could vary between 50 and 150 or more This point pattern exhibits CSR by construction. However, you are typically in the opposite position. You observe a set of events (e.g., tornadoes on the Plains) and you want to know if the events are regular, clustered, or random The null hypothesis is CSR and you need a test statistic that will summarize the evidence against this hypothesis. The null models are simple so you can use Monte Carlo methods to generate samples and compare summary statistics from those samples with your observed data In some cases the homogeneous Poisson model is not restrictive enough. This means that you can easily reject the null hypothesis but not learn anything interesting about your data. For example, with health events (locations of people with heart disease) CSR is not an appropriate model because a null hypothesis that incidences are equally likely does not consider that people cluster (locations at risk are not uniform) Each person may have the same risk of heart disease, for instance, regardless of location. But you expect more cases in areas with more people at risk. Clusters of cases in high population areas violate the CSR but not necessarily the constant risk hypothesis. The constant risk hypothesis requires the intensity of the spatial process be defined as a spatially varying function. That is, you define the intensity as \\(\\lambda(s)\\), where \\(s\\) denotes location The intensity (density) function is a first-order property of point pattern data. If intensity varies (significantly) across the domain, the process generating the data is said to be heterogeneous. The intensity function describes the expected number of events at any location. Events might be independent of one another, but groups of events appear because of the changing intensity It helps to visualize these concepts. We do that with functions from the {spatstat} family of packages Working with point pattern data using functions from the spatstat family of packages The {spatstat} family of packages contain functions to analyze and model point pattern data. The individual packages have different namespace names beginning with spatstat so it is best to load the functions with the library() function before beginning library(spatstat) ## Loading required package: spatstat.data ## Loading required package: spatstat.geom ## spatstat.geom 3.0-6 ## Loading required package: spatstat.random ## spatstat.random 3.1-3 ## Loading required package: spatstat.explore ## Loading required package: nlme ## spatstat.explore 3.0-6 ## Loading required package: spatstat.model ## Loading required package: rpart ## spatstat.model 3.1-2 ## Loading required package: spatstat.linnet ## spatstat.linnet 3.0-4 ## ## spatstat 3.0-3 ## For an introduction to spatstat, type &#39;beginner&#39; Point pattern data are defined in {spatstat} by an object of class ppp (for planar point pattern) which contains the spatial coordinates of the events (event locations), optional values attached to the events (called ‘marks’), and a description of the domain or ‘window’ over which the events are observed. See ?ppp.object() for details Spatial statistics computed on a ppp object will be sensitive to the choice of the window (domain), so some thought should go into the choice of the domain. As an example, the data swedishpines is available in the package as a ppp object class(swedishpines) ## [1] &quot;ppp&quot; swedishpines ## Planar point pattern: 71 points ## window: rectangle = [0, 96] x [0, 100] units (one unit = 0.1 metres) The data is a planar point pattern object with 71 events Note: Unfortunately events in a ppp object are called ‘points’ rather than events. This terminology differs from that used the theoreticians who define a point as a potential event not an observed event All the events are contained within a rectangle window of size 9.6 by 10 meters There is a plot() method for ppp objects that provides a quick view of the data and the domain window swedishpines |&gt; plot() Events are plotted as open circles inside the domain boundaries. The plot is labeled with the name of the ppp object The function convexhull() from the {spatstat.geom} package as part of the {spatstat} family of packages creates a convex hull around the events. A convex hull defines the minimum-area convex polygon that contains all the events Here you create the hull and add it to the plot swedishpines |&gt; plot() swedishpines |&gt; convexhull() |&gt; plot(add = TRUE) The domain (window) for analysis and modeling should be somewhat larger than the convex hull. The function ripras() computes a spatial domain based on the event locations alone assuming the locations are independent and identically distributed. Here you also overlay this polygon on the plot swedishpines |&gt; plot() swedishpines |&gt; convexhull() |&gt; plot(add = TRUE) swedishpines |&gt; ripras() |&gt; plot(add = TRUE, lty = &quot;dotted&quot;) The window can have an arbitrary shape. A rectangle, a polygon, a collection of polygons including holes, or a binary image (mask). A window can be stored as a separate object of class owin. See ?owin.object() for details Each event may carry information called a ‘mark’. A mark can be continuous (e.g. tree height) or discrete (tree species) Multitype point patterns are point patterns in which the events have a discrete mark (e.g., tree species). The mark values are given in a vector of the same length as the vector of locations. That is, marks[i] is the mark attached to the location (x[i], y[i]) Consider the ppp object demopat from the {spatstat} package demopat |&gt; plot() Here the domain is defined as an irregular concave polygon with a hole. The distinction between inside and outside is important for spatial statistics computed using the events You print the marks with the marks() function. demopat |&gt; marks() ## [1] A B B A B B B A A A B A A B B A A A B B A A A A B B B A A B B B B B A A B ## [38] A A B B A A B B B B A B B B B B B B A A A B A B A B B B B B A B B A A B B ## [75] B B B A B B A A B A B B B A B A B B B B B A A B A B B B B B A A A B A B B ## [112] A ## Levels: A B For a multitype pattern (where the marks are factors) you can use the split() function to separate the point pattern objects by mark type. Consider the Lansing Woods data set (lansing) with marks corresponding to tree species data(lansing) LW &lt;- lansing LW |&gt; split() |&gt; plot() Quantifying the spatial intensity of events The average intensity of events is defined as the number of events per unit area of the domain. The summary() method applied to a ppp object gives the average intensity swedishpines |&gt; summary() ## Planar point pattern: 71 points ## Average intensity 0.007395833 points per square unit (one unit = 0.1 metres) ## ## Coordinates are integers ## i.e. rounded to the nearest unit (one unit = 0.1 metres) ## ## Window: rectangle = [0, 96] x [0, 100] units ## Window area = 9600 square units ## Unit of length: 0.1 metres There are 71 events over a window area (spatial domain) of 9600 square units giving an average intensity of 71/9600 = .0074. That is the average intensity is .0074 events per unit area Average intensity depends on the number of events and on the domain area defined by the owin object The owin object is the first element labeled window in a ppp object W0 &lt;- swedishpines$window class(W0) ## [1] &quot;owin&quot; The default window is a rectangle. plot(W0) Here you change the window to that defined by the event locations using the method of Ripley-Rasson (ripras() function) and then make that the window for the Swedish pines by using the subset operator [ W1 &lt;- swedishpines |&gt; ripras() SP2 &lt;- swedishpines[W1] Since the new window area is slightly larger than the default window the summary method shows that the spatial intensity is lower SP2 |&gt; summary() ## Planar point pattern: 71 points ## Average intensity 0.007096614 points per square unit (one unit = 0.1 metres) ## ## Coordinates are integers ## i.e. rounded to the nearest unit (one unit = 0.1 metres) ## ## Window: polygonal boundary ## single connected closed polygon with 14 vertices ## enclosing rectangle: [-4.5486, 100.36205] x [-3.73614, 104.52272] units ## (104.9 x 108.3 units) ## Window area = 10004.8 square units ## Unit of length: 0.1 metres ## Fraction of frame area: 0.881 The average intensity might not represent the intensity of events locally. You need a way to describe the expected number of events at any location of the region Counting the number of events in equal areas is one way. The quadrat method divides the domain into a grid of rectangular cells and the number of events in each cell is counted. Quadrat counting is done with the quadratcount() function swedishpines |&gt; quadratcount() ## x ## y [0,19.2) [19.2,38.4) [38.4,57.6) [57.6,76.8) [76.8,96] ## [80,100] 3 1 2 3 3 ## [60,80) 4 4 3 1 2 ## [40,60) 3 5 3 7 3 ## [20,40) 1 1 2 3 3 ## [0,20) 1 2 2 4 5 By default the function divides the data into a 5 x 5 grid of cells. The event count in each cell is produced. To change the default number of cells in x and y directions you use the nx = and ny = arguments swedishpines |&gt; quadratcount(nx = 2, ny = 3) ## x ## y [0,48) [48,96] ## [66.7,100] 10 11 ## [33.3,66.7) 14 14 ## [0,33.3) 7 15 The plot method applied to the results of the quadratcount() functions adds the counts to a plot. Here you add the counts and include the event locations swedishpines |&gt; quadratcount() |&gt; plot() swedishpines |&gt; plot(pty = 19, col = &quot;red&quot;, add = TRUE, main = &quot;&quot;) Grid cell areas will not be all equal when the domain boundaries are irregular like with the demopat ppp object demopat |&gt; quadratcount() |&gt; plot() Areas near the borders are smaller than areas completely within the domain When the number of events is large, hexagon grid cells provide a useful alternative to rectangular grid cells The process is: (1) tessellate the domain by a regular grid of hexagons, (2) count the number of events in each hexagon, and (3) use a color ramp to display the events per hexagon As an example here you generate 20K values from the standard normal distribution for the x coordinate and the same number of values for the y coordinate. You then use the hexbin() function from the {hexbin} package and specify 10 bins in the x direction to count the number of events in each hexagon and assign the result to the object hbin. if(!require(hexbin)) install.packages(pkgs = &quot;hexbin&quot;, repos = &quot;http://cran.us.r-project.org&quot;) ## Loading required package: hexbin x &lt;- rnorm(20000) y &lt;- rnorm(20000) hbin &lt;- hexbin::hexbin(x, y, xbins = 10) str(hbin) ## Formal class &#39;hexbin&#39; [package &quot;hexbin&quot;] with 16 slots ## ..@ cell : int [1:86] 7 14 15 16 17 18 23 25 26 27 ... ## ..@ count : int [1:86] 1 1 1 1 4 1 1 6 22 36 ... ## ..@ xcm : num [1:86] 0.947 -1.936 -0.731 -0.45 0.497 ... ## ..@ ycm : num [1:86] -4.2 -3.43 -3.23 -3.54 -3.33 ... ## ..@ xbins : num 10 ## ..@ shape : num 1 ## ..@ xbnds : num [1:2] -3.97 4.26 ## ..@ ybnds : num [1:2] -4.2 4.34 ## ..@ dimen : num [1:2] 14 11 ## ..@ n : int 20000 ## ..@ ncells: int 86 ## ..@ call : language hexbin::hexbin(x = x, y = y, xbins = 10) ## ..@ xlab : chr &quot;x&quot; ## ..@ ylab : chr &quot;y&quot; ## ..@ cID : NULL ## ..@ cAtt : int(0) The {hexbin} package uses S4 data classes so the output is stored in slots. Use the plot() method to make a graph hbin |&gt; plot() Hexagons have symmetric nearest neighbors (there is only rook contiguity). They have the most sides of any polygon that can tessellate the plane. They are generally more efficient than rectangles at covering the events. In other words it takes fewer of them to cover the same number of events. They are visually less biased for displaying local event intensity compared to squares/rectangles Here you generate a large number of random events in the two-dimensional plane. Use a normal distribution in the x-direction and a student t-distribution in the y-direction set.seed(131) x &lt;- rnorm(7777) y &lt;- rt(7777, df = 3) hexbin::hexbin(x, y, xbins = 25) |&gt; plot() The {ggplot2} package has the stat_binhex() function so that also can be used for displaying spatial intensity df &lt;- data.frame(x, y) ggplot(data = df, mapping = aes(x = x, y = y)) + stat_binhex() Another way to quantify the spatial intensity is with kernel density estimation (KDE). Let \\(s_i\\) for \\(i\\) = 1…\\(n\\) be event locations, then an estimate for the intensity of the events at any location \\(s\\) is given by \\[ \\hat \\lambda (s) = \\frac{1}{nh}\\sum_{i=1}^nK\\Big(\\frac{s - s_i}{h}\\Big) \\] where \\(K()\\) is the kernel function and \\(h &gt; 0\\) is a smoothing parameter called the bandwidth. Typically the kernel function is a Gaussian probability density function To help visualize KDE you generate 25 event locations (el) uniformly on the real number line representing a one-dimensional spatial domain between 0 and 1 and then use kernel density estimation to get a continuous intensity function. The density estimation is is done using the function density() and here you compare the intensity function for increasing bandwidths specified with the bw = argument. el &lt;- runif(25) dd1 &lt;- density(el, bw = .025) dd2 &lt;- density(el, bw = .05) dd3 &lt;- density(el, bw = .1) df &lt;- data.frame(x = c(dd1$x, dd2$x, dd3$x), y = c(dd1$y, dd2$y, dd3$y), bw = c(rep(&quot;h = .025&quot;, 512), rep(&quot;h = .05&quot;, 512), rep(&quot;h = .1&quot;, 512))) df2 &lt;- data.frame(x = el, y = 0) ggplot(data = df, mapping = aes(x, y)) + geom_line() + facet_wrap(~ bw, nrow = 3) + geom_point(mapping = aes(x, y), data = df2, color = &quot;red&quot;) As the bandwidth increases the curve (black line) representing the local intensity becomes smoother. The intensity is estimated at every location, not just at the location of the event The density is a summation of the kernels with one kernel centered on top of each event location. Event locations are marked with a point along the x-axis and the kernel is a Gaussian probability density function. The kernel is placed on each event and the bandwidth specifies the distance between the inflection points of the kernel. The one-dimensional KDE extends to two (or more) dimensions Example: The distribution of trees in a tropical forest The object bei is a planar point pattern object from the {spatstat} package containing the locations of trees in a tropical rain forest bei |&gt; summary() ## Planar point pattern: 3604 points ## Average intensity 0.007208 points per square metre ## ## Coordinates are given to 1 decimal place ## i.e. rounded to the nearest multiple of 0.1 metres ## ## Window: rectangle = [0, 1000] x [0, 500] metres ## Window area = 5e+05 square metres ## Unit of length: 1 metre There are 3604 events (trees) over an area of 500,000 square meters giving an average intensity of .0073 trees per unit area The distribution of trees is not uniform (heterogeneous) as can be seen with a plot bei |&gt; plot() The plot shows clusters of trees and large areas with few if any trees Elevation and elevation slope are factors associated with tree occurrence The point pattern data is accompanied by data (bei.extra) on elevation (elev) and slope of elevation (grad) across the region bei.extra |&gt; plot() These data are stored as im (image) objects class(bei.extra$elev) ## [1] &quot;im&quot; The image object contains a list with 10 elements including the matrix of values (v) str(bei.extra$elev) ## List of 10 ## $ v : num [1:101, 1:201] 121 121 121 121 121 ... ## $ dim : int [1:2] 101 201 ## $ xrange: num [1:2] -2.5 1002.5 ## $ yrange: num [1:2] -2.5 502.5 ## $ xstep : num 5 ## $ ystep : num 5 ## $ xcol : num [1:201] 0 5 10 15 20 25 30 35 40 45 ... ## $ yrow : num [1:101] 0 5 10 15 20 25 30 35 40 45 ... ## $ type : chr &quot;real&quot; ## $ units :List of 3 ## ..$ singular : chr &quot;metre&quot; ## ..$ plural : chr &quot;metres&quot; ## ..$ multiplier: num 1 ## ..- attr(*, &quot;class&quot;)= chr &quot;unitname&quot; ## - attr(*, &quot;class&quot;)= chr &quot;im&quot; Specifying a spatial domain (window) allows focuses the analysis on a particular region. Suppose you want to model locations of a certain tree type, but only for trees located at elevations above 145 meters. The levelset() function creates a window from an image object using thresh = and compare = arguments W &lt;- levelset(bei.extra$elev, thresh = 145, compare = &quot;&gt;&quot;) class(W) ## [1] &quot;owin&quot; The result is an object of class owin. The plot method displays the window as a mask, which is the region in black. W |&gt; plot() You subset the ppp object by the window using the bracket operator ([]). Here you assign the reduced ppp object to beiW and then make a plot beiW &lt;- bei[W] beiW |&gt; plot() Now the analysis window is white and the event locations are plotted on top As another example you create a window where altitude is lower than 145 m and slope exceeds .1 degrees. In this case you use the solutionset() function V &lt;- solutionset(bei.extra$elev &lt;= 145 &amp; bei.extra$grad &gt; .1) beiV &lt;- bei[V] beiV |&gt; plot() You compute the spatial intensity function over the domain with the density() method using the default Gaussian kernel and fixed bandwidth determined by the window size beiV |&gt; density() |&gt; plot() The units of intensity are events per unit area (here square meters). The intensity values are computed on a grid (\\(v\\)) and are returned as a pixel image There are over 16K cells that have a value of NA as a result of the masking by elevation and slope den &lt;- beiV |&gt; density() sum(is.na(den$v)) ## [1] 16020 Summarizing: Spatial point patterns play a big role in the analysis of natural occurring systems where the spatial location of events is examined through the lens of statistics in an attempt to understand physical processes Some of the terminology and theory of point pattern data analysis was introduced in this lesson. Including the concept of complete spatial randomness (CSR) and the twin assumptions of stationarity and isotropy The {spatstat} family of packages provides a comprehensive set of functions for analyzing, plotting, and modeling point pattern data. The package requires the data be of spatial class ppp The typical work flow includes importing and munging data as a simple feature data frame and then converting the simple feature data frame to a ppp object for analysis and modeling. But it is sometimes convenient to do at least part of the data munging after conversion to a ppp object The first-order property of spatial point pattern data is spatial intensity. It is defined as the number of events per unit area of the domain. The spatial intensity can vary with domain area even if the number of events is constant. It can also vary across the domain. Quadrat counting and kernel density estimates are used to quantify the spatial varying intensity "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
