[["tuesday-october-4-2022.html", "Tuesday October 4, 2022 Fitting and interpreting geographic regressions Mapping diseases with spatial regression models", " Tuesday October 4, 2022 “We build our computer systems the way we build or cities; over time, without plan, on top of ruins.” – Ellen Ullman Today Fitting and interpreting geographic regressions Mapping diseases with spatial regression models Fitting and interpreting geographic regressions Another approach to modeling spatial data is to assume that the relationships between the response variable and the explanatory variables are modified by contextual factors that depend on location. In this case you fit a separate regression model at each geographic location. The analogy is a local measure of spatial autocorrelation where you estimate the statistic at each location. It is a useful approach for exploratory analysis (e.g., to show where the explanatory variables are most strongly related to the response variable). It is called geographically weighted regression (GWR) or simply geographic regression. GWR is used in epidemiology, particularly for research on infectious diseases and for evaluating health policies and programs. Since GWR fits a separate regression model using data focused at every spatial location in the dataset, it is not a single model but a procedure for fitting a set of models. This is different from the spatial regression such as the spatially-lagged Y model, which are single models with spatial terms. Observations across the entire domain contribute to the model fit at a particular location, but the observations are weighted inversely by their distance to the particular location. At short distances, observations are given the largest weights based on a Gaussian function and a bandwidth. The bandwidth is specified as a single parameter or it is determined through a cross-validation procedure. The bandwidth can also be a function of location. Said another way, linear regression is a model for the conditional mean. The mean of the response variable depends on the explanatory variables. Geographic regressions show how this dependency varies by location. GWR is used as an exploratory technique for determining where local regression coefficients are different from corresponding global values. Continuing with the Columbus crime data. ( CC.sf &lt;- sf::st_read(dsn = here::here(&quot;data&quot;, &quot;columbus&quot;), layer = &quot;columbus&quot;) ) ## Reading layer `columbus&#39; from data source ## `/Users/jameselsner/Desktop/ClassNotes/ASS-2022/data/columbus&#39; ## using driver `ESRI Shapefile&#39; ## Simple feature collection with 49 features and 20 fields ## Geometry type: POLYGON ## Dimension: XY ## Bounding box: xmin: 5.874907 ymin: 10.78863 xmax: 11.28742 ymax: 14.74245 ## CRS: NA ## Simple feature collection with 49 features and 20 fields ## Geometry type: POLYGON ## Dimension: XY ## Bounding box: xmin: 5.874907 ymin: 10.78863 xmax: 11.28742 ymax: 14.74245 ## CRS: NA ## First 10 features: ## AREA PERIMETER COLUMBUS_ COLUMBUS_I POLYID NEIG HOVAL INC CRIME ## 1 0.309441 2.440629 2 5 1 5 80.467 19.531 15.725980 ## 2 0.259329 2.236939 3 1 2 1 44.567 21.232 18.801754 ## 3 0.192468 2.187547 4 6 3 6 26.350 15.956 30.626781 ## 4 0.083841 1.427635 5 2 4 2 33.200 4.477 32.387760 ## 5 0.488888 2.997133 6 7 5 7 23.225 11.252 50.731510 ## 6 0.283079 2.335634 7 8 6 8 28.750 16.029 26.066658 ## 7 0.257084 2.554577 8 4 7 4 75.000 8.438 0.178269 ## 8 0.204954 2.139524 9 3 8 3 37.125 11.337 38.425858 ## 9 0.500755 3.169707 10 18 9 18 52.600 17.586 30.515917 ## 10 0.246689 2.087235 11 10 10 10 96.400 13.598 34.000835 ## OPEN PLUMB DISCBD X Y NSA NSB EW CP THOUS NEIGNO ## 1 2.850747 0.217155 5.03 38.80 44.07 1 1 1 0 1000 1005 ## 2 5.296720 0.320581 4.27 35.62 42.38 1 1 0 0 1000 1001 ## 3 4.534649 0.374404 3.89 39.82 41.18 1 1 1 0 1000 1006 ## 4 0.394427 1.186944 3.70 36.50 40.52 1 1 0 0 1000 1002 ## 5 0.405664 0.624596 2.83 40.01 38.00 1 1 1 0 1000 1007 ## 6 0.563075 0.254130 3.78 43.75 39.28 1 1 1 0 1000 1008 ## 7 0.000000 2.402402 2.74 33.36 38.41 1 1 0 0 1000 1004 ## 8 3.483478 2.739726 2.89 36.71 38.71 1 1 0 0 1000 1003 ## 9 0.527488 0.890736 3.17 43.44 35.92 1 1 1 0 1000 1018 ## 10 1.548348 0.557724 4.33 47.61 36.42 1 1 1 0 1000 1010 ## geometry ## 1 POLYGON ((8.624129 14.23698... ## 2 POLYGON ((8.25279 14.23694,... ## 3 POLYGON ((8.653305 14.00809... ## 4 POLYGON ((8.459499 13.82035... ## 5 POLYGON ((8.685274 13.63952... ## 6 POLYGON ((9.401384 13.5504,... ## 7 POLYGON ((8.037741 13.60752... ## 8 POLYGON ((8.247527 13.58651... ## 9 POLYGON ((9.333297 13.27242... ## 10 POLYGON ((10.08251 13.03377... Start by fitting a ‘global’ ordinarly least squares (OLS) linear regression to the crime rates using income and housing values, exactly as you did earlier. f &lt;- CRIME ~ INC + HOVAL ( model.ols &lt;- lm(formula = f, data = CC.sf) ) ## ## Call: ## lm(formula = f, data = CC.sf) ## ## Coefficients: ## (Intercept) INC HOVAL ## 68.6190 -1.5973 -0.2739 The coefficients on the two explanatory variables indicate that crime decreases in areas of higher income and higher housing values. You compare this result to results from geographic regressions. The functions are in the {spgwr} package. if(!require(spgwr)) install.packages(pkgs = &quot;spgwr&quot;, repos = &quot;http://cran.us.r-project.org&quot;) ## Loading required package: spgwr ## Loading required package: sp ## Loading required package: spData ## To access larger datasets in this package, install the spDataLarge ## package with: `install.packages(&#39;spDataLarge&#39;, ## repos=&#39;https://nowosad.github.io/drat/&#39;, type=&#39;source&#39;)` ## NOTE: This package does not constitute approval of GWR ## as a method of spatial analysis; see example(gwr) The sp part of the package name indicates that the functions were developed to work with S4 spatial objects. The functions allow you to use S3 simple features by specifying the locations as a matrix. Here you extract the centroid from each census tract as a matrix. Locations &lt;- sf::st_coordinates(sf::st_centroid(CC.sf)) ## Warning in st_centroid.sf(CC.sf): st_centroid assumes attributes are constant ## over geometries of x head(Locations) ## X Y ## 1 8.827218 14.36908 ## 2 8.332658 14.03162 ## 3 9.012265 13.81972 ## 4 8.460801 13.71696 ## 5 9.007982 13.29637 ## 6 9.739926 13.47463 These are the X and Y coordinate values specifying the centroid for the first six tracts (out of 49). To determine the optimal bandwidth for the Gaussian kernel (weighting function) you use the spgwr::gwr.sel() function. You need to specify the arguments, model formula (formula =), the data frame (data =), and the coordinates (coords =) as part of the function call. The argument coords = is the matrix of coordinates of points representing the spatial locations of the observations. It can be omitted if the data is an S4 spatial data frame from the {sp} package. ( bw &lt;- spgwr::gwr.sel(formula = f, data = CC.sf, coords = Locations) ) ## Bandwidth: 2.220031 CV score: 7473.853 ## Bandwidth: 3.588499 CV score: 7479.637 ## Bandwidth: 1.374271 CV score: 7404.175 ## Bandwidth: 0.8515626 CV score: 7389.293 ## Bandwidth: 0.7515898 CV score: 7280.867 ## Bandwidth: 0.4667245 CV score: 6319.861 ## Bandwidth: 0.290668 CV score: 7474.967 ## Bandwidth: 0.5755334 CV score: 6754.626 ## Bandwidth: 0.3994769 CV score: 6197.735 ## Bandwidth: 0.3597549 CV score: 6320.012 ## Bandwidth: 0.4132551 CV score: 6200.674 ## Bandwidth: 0.4028088 CV score: 6196.867 ## Bandwidth: 0.4040147 CV score: 6196.817 ## Bandwidth: 0.4038422 CV score: 6196.816 ## Bandwidth: 0.4038829 CV score: 6196.816 ## Bandwidth: 0.4038015 CV score: 6196.816 ## Bandwidth: 0.4038422 CV score: 6196.816 ## [1] 0.4038422 The procedure makes an initial guess at the optimal bandwidth distance and then fits local regression models at each location using weights that decay defined by the kernel (guassian by default) and that bandwidth (distance). The output shows that the first bandwidth chosen was 2.22 in arbitrary distance units. The resulting prediction skill from fitting 49 regression models with that bandwidth is 7474 units. The resulting CV score is based on cross validation whereby skill is computed at each location when data from that location is not used to fit the regression models. The procedure continues by increasing the bandwidth distance (to 3.59) and then computing a new CV score from refitting the regression models. Since the new CV score is higher (7480) than the initial CV score (7474), the bandwidth is changed in the other direction (decreasing from 2.22 to 1.37) and the models again are refit. With that bandwidth, the CV score is 7404, which is lower than the initial bandwidth so the bandwidth is decreased again. The procedure continues until no additional improvement in prediction skill occurs. The output shows that no additional improvement in skill occurs at a bandwidth distance of .404 units, and this single value is assigned to the object you called bw. Once the bandwidth distance is determined you use the spgwr::gwr() function to fit the regressions using that bandwidth. The arguments are the same as before but includes the bandwidth = argument where you specify the object bw. model.gwr &lt;- gwr(formula = f, data = CC.sf, coords = Locations, bandwidth = bw) The model and observed data are assigned to a list object with element names listed using the names() function. names(model.gwr) ## [1] &quot;SDF&quot; &quot;lhat&quot; &quot;lm&quot; &quot;results&quot; &quot;bandwidth&quot; &quot;adapt&quot; ## [7] &quot;hatmatrix&quot; &quot;gweight&quot; &quot;gTSS&quot; &quot;this.call&quot; &quot;fp.given&quot; &quot;timings&quot; The first element is SDF containing the model output as a S4 spatial data frame. class(model.gwr$SDF) ## [1] &quot;SpatialPointsDataFrame&quot; ## attr(,&quot;package&quot;) ## [1] &quot;sp&quot; See Lesson 7 where S4 spatial data objects were covered. The structure of the spatial data frame is obtained with the str() function and by setting the max.level argument to 2. str(model.gwr$SDF, max.level = 2) ## Formal class &#39;SpatialPointsDataFrame&#39; [package &quot;sp&quot;] with 5 slots ## ..@ data :&#39;data.frame&#39;: 49 obs. of 7 variables: ## ..@ coords.nrs : num(0) ## ..@ coords : num [1:49, 1:2] 8.83 8.33 9.01 8.46 9.01 ... ## .. ..- attr(*, &quot;dimnames&quot;)=List of 2 ## ..@ bbox : num [1:2, 1:2] 6.22 11.01 10.95 14.37 ## .. ..- attr(*, &quot;dimnames&quot;)=List of 2 ## ..@ proj4string:Formal class &#39;CRS&#39; [package &quot;sp&quot;] with 1 slot Here there are five slots with the first slot labeled @data indicating that it is a data frame. The number of rows and columns in the data frame are listed with the dim() function. dim(model.gwr$SDF) ## [1] 49 7 There are 49 rows and 7 columns. Each row corresponds to a tract and information about the regressions localized to the tract is given in the columns. Column names are listed with the names() function. names(model.gwr$SDF) ## [1] &quot;sum.w&quot; &quot;(Intercept)&quot; &quot;INC&quot; &quot;HOVAL&quot; &quot;gwr.e&quot; ## [6] &quot;pred&quot; &quot;localR2&quot; They include the sum of the weights sum.w (the larger the sum the more often the tract is included in the local regressions–favoring smaller counties and ones farther from the borders of the spatial domain), the three regression coefficients one for each of the explanatory variables (INC and HOVAL) and an intercept term, the residual (gwr.e), the predicted value (pred) and the local goodness-of-fit (localR2). You create a map displaying where income has the most and least influence on crime by first adding the income coefficient from the data frame (column labeled INC) to the simple feature data frame since the order of the rows in the SDF matches the order in the simple feature data frame and then using functions from the {ggplot2} package. CC.sf$INCcoef &lt;- model.gwr$SDF$INC library(ggplot2) ggplot(CC.sf) + geom_sf(aes(fill = INCcoef)) + scale_fill_viridis_c() Most tracts have coefficients with values less than zero. Recall the global coefficient is less than zero. But areas in yellow show where the coefficient values are greater than zero indicating a direct relationship between crime and income. How about the coefficients on housing values? CC.sf$HOVALcoef &lt;- model.gwr$SDF$HOVAL ggplot(CC.sf) + geom_sf(aes(fill = HOVALcoef)) + scale_fill_viridis_c() While the global coefficient is negative indicating crime rates tend to be lower in areas with higher housing values, the opposite is the case over much of city especially on the south side. You put the vector of GWR predictions into the CC.sf simple feature data frame giving it the column name predGWR and then map the predictions using functions from the {tmap} package. CC.sf$predGWR &lt;- model.gwr$SDF$pred tmap::tm_shape(CC.sf) + tmap::tm_fill(&quot;predGWR&quot;, title = &quot;Predicted crimes\\nper 1000&quot;) + tmap::tm_layout(legend.outside = TRUE) ## Warning: Currect projection of shape CC.sf unknown. Long-lat (WGS84) is assumed. The geographic regressions capture the spatial pattern of crimes across the city. The spread of predicted values matches the observed spread better than the linear model. The pattern of predicted crime is also a smoother than with a global OLS regression. Where is the relationship between crime and the two explanatory variables the tightest? This is answered by mapping the R squared coefficient for each of the models. CC.sf$localR2 &lt;- model.gwr$SDF$localR2 ggplot(CC.sf) + geom_sf(aes(fill = localR2)) + scale_fill_viridis_c() Although crime rates are highest in the center, the relationship between crime and income and housing values is largest in tracts across the eastern part of the city. This type of nuanced exploratory analysis is made possible with GWR. Also, when fitting a regression model to data that vary spatially you are assuming an underlying stationary process. This means you believe the explanatory variables ‘provoke’ the same response (statistically) across the domain. If this is not the case then it shows up in a map of correlated residuals. One way to check the assumption of a stationary process is to use geographic regression. Mapping diseases with spatial regression models Spatial regression models are used in disease mapping where it is common to use a standardized incidence ratio (SIR) defined as the ratio of the observed to the expected number of disease cases. Small areas can give extreme SIRs due to low population sizes or small samples. Extreme values of SIRs can be misleading and unreliable for reporting. Because of this so-called ‘small area problem’ it is better to estimate disease risk using a spatial regression model. Spatial regression models incorporate information from neighboring areas and explanatory information. The result is a smoothing (shrinking) of extreme values. Consider county-level lung cancer cases in Pennsylvania from the {SpatialEpi} package. The county boundaries for the state are in the list object pennLC with element name spatial.polygon. Change the native spatial polygons S4 object to an S3 simple feature data frame using the sf::st_as_sf() function and display a map of the county borders. if(!require(SpatialEpi)) install.packages(&quot;SpatialEpi&quot;, repos = &quot;http://cran.us.r-project.org&quot;) ## Loading required package: SpatialEpi LC.sp &lt;- SpatialEpi::pennLC$spatial.polygon LC.sf &lt;- sf::st_as_sf(LC.sp) ggplot(LC.sf) + geom_sf() For each region (county) \\(i\\), \\(i = 1, \\ldots, n\\) the SIR is defined as the ratio of observed counts (\\(Y_i\\)) to the expected counts (\\(E_i\\)). \\[ \\hbox{SIR}_i = Y_i/E_i. \\] The expected count \\(E_i\\) is the total number of cases expected if the population of area \\(i\\) behaves the way the standard population behaves. If you ignore differences in rates for different stratum (e.g., age groups, race, etc) then you compute the expected counts as \\[ E_i = r^{(s)} n^{(i)}, \\] where \\(r^{(s)}\\) is the rate in the standard population (total number of cases divided by the total population across all regions), and \\(n^{(i)}\\) is the population of region \\(i\\). Then \\(\\hbox{SIR}_i\\) indicates whether region \\(i\\) has higher (\\(\\hbox{SIR}_i &gt; 1\\)), equal (\\(\\hbox{SIR}_i = 1\\)) or lower (\\(\\hbox{SIR}_i &lt; 1\\)) risk than expected relative to the standard population. When applied to mortality data, the ratio is known as the standardized mortality ratio (SMR). The data frame SpatialEpi::pennLC$data contains the number of lung cancer cases and the population of Pennsylvania at county level, stratified on race (white and non-white), gender (female and male) and age (under 40, 40-59, 60-69 and 70+). You compute the number of cases for all the strata together in each county by aggregating the rows of the data frame by county and adding up the number of cases. ( County.df &lt;- SpatialEpi::pennLC$data |&gt; dplyr::group_by(county) |&gt; dplyr::summarize(Y = sum(cases)) ) ## # A tibble: 67 × 2 ## county Y ## &lt;fct&gt; &lt;int&gt; ## 1 adams 55 ## 2 allegheny 1275 ## 3 armstrong 49 ## 4 beaver 172 ## 5 bedford 37 ## 6 berks 308 ## 7 blair 127 ## 8 bradford 59 ## 9 bucks 454 ## 10 butler 158 ## # … with 57 more rows You then calculate the expected number of cases in each county using indirect standardization. The expected counts in each county represent the total number of disease cases one would expect if the population in the county behaved the way the population of Pennsylvania behaves. You do this by using the SpatialEpi::expected() function. The function has three arguments including population (vector of population counts for each strata in each area), cases (vector with the number of cases for each strata in each area), and n.strata (number of strata). The vectors population and cases need to be sorted by area first and then, within each area, the counts for all strata need to be listed in the same order. All strata need to be included in the vectors, including strata with 0 cases. Here you use the dplyr::arrange() function. Strata.df &lt;- SpatialEpi::pennLC$data |&gt; dplyr::arrange(county, race, gender, age) head(Strata.df) ## county cases population race gender age ## 1 adams 0 365 o f 40.59 ## 2 adams 1 68 o f 60.69 ## 3 adams 0 73 o f 70+ ## 4 adams 0 1492 o f Under.40 ## 5 adams 0 387 o m 40.59 ## 6 adams 0 69 o m 60.69 Then you get the expected counts (E) in each county by calling the SpatialEpi::expected() function, where you set population equal to Strata.df$population and cases equal to Strata.df$cases. There are two races, two genders and four age groups for each county, so number of strata is set to 2 x 2 x 4 = 16. ( E &lt;- SpatialEpi::expected(population = Strata.df$population, cases = Strata.df$cases, n.strata = 16) ) ## [1] 69.627305 1182.428036 67.610123 172.558055 44.190132 300.705979 ## [7] 115.069655 53.237644 428.797481 134.797705 149.846027 5.945905 ## [13] 55.475211 79.404013 300.124058 33.906647 73.853240 33.012029 ## [19] 53.312111 75.025024 170.866603 199.809038 454.545971 31.543736 ## [25] 216.203436 137.810484 5.403583 109.888662 11.594802 33.093112 ## [31] 36.659515 71.090130 42.555800 18.735146 204.172754 357.237966 ## [37] 91.303056 103.076598 259.874790 309.688036 101.231639 40.105227 ## [43] 111.790653 40.774630 100.094714 608.691819 16.081330 222.731099 ## [49] 90.872134 31.037254 1219.102696 39.865269 16.003210 147.937712 ## [55] 28.878902 74.523497 7.419682 36.174266 35.756382 30.833836 ## [61] 51.141014 39.230710 189.097720 44.490161 351.175955 21.009224 ## [67] 288.869666 Now you add the observed count Y, the expected count E the computed SIR to the simple feature data frame LC.sf and make a map of the standardized incidence ratios (SIR) with blue shades below a value of 1 (midpoint) and red shades above a value of 1. LC.sf &lt;- LC.sf |&gt; dplyr::mutate(Y = County.df$Y, E = E, SIR = Y/E) ggplot(LC.sf) + geom_sf(aes(fill = SIR)) + scale_fill_gradient2(midpoint = 1, low = &quot;blue&quot;, mid = &quot;white&quot;, high = &quot;red&quot;) + theme_minimal() In counties with SIR = 1 (white) the number of cancer cases observed is the same as the number of expected cases. In counties with SIR &gt; 1 (red), the number of cancer cases observed is higher than the expected cases. Counties with SIR &lt; 1 (blue) have fewer cancer cases observed than expected. In regions with few people the expected counts may be very low and the SIR value may be misleading. Therefore, it is preferred to estimate disease risk using models that borrow information from neighboring areas, and incorporate explanatory information. This results in smoothing (shrinkage) of extreme values. Let the observed counts \\(Y\\) be modeled with a Poisson distribution having a mean \\(E \\theta\\), where \\(E\\) are the expected counts and \\(\\theta\\) are the relative risks. The logarithm of the relative risk is expressed as the sum of an intercept that models the overall disease risk level, and random effects to account for local variability. The relative risk quantifies whether an area has a higher (\\(\\theta &gt; 1\\)) or lower (\\(\\theta &lt; 1\\)) risk than the average risk in the population. For example if \\(\\theta_i = 2\\), then the risk in area \\(i\\) is twice the average risk in the population. The model is expressed as \\[ Y \\sim \\hbox{Poisson}(E\\theta) \\\\ \\log(\\theta) = \\alpha + u + v \\] The parameter \\(\\alpha\\) is the overall risk in the region of study, \\(u\\) is the spatially structured random effect representing the dependency in risk across neighboring areas, and \\(v\\) is the uncorrelated random noise modeled as \\(v \\sim N(0, \\sigma_v^2)\\). It is common to include explanatory variables to quantify risk factors (e.g., distance to nearest coal plant). Thus the log(\\(\\theta\\)) is expressed as \\[ \\log(\\theta) = \\alpha + X\\beta + u + v \\] where \\(X\\) are the explanatory variables and \\(\\beta\\) are the associated coefficients. A coefficient is interpreted such that a one-unit increase in the explanatory variable value changes the relative risk by a factor \\(\\exp(\\beta)\\), holding the other variables constant. A popular form for the combined spatially structured random effect and the uncorrelated random effect is the Besag-York-Mollié (BYM) model, which assigns a conditional autoregressive distribution to \\(u\\) as \\[ u | u_{j \\ne i} \\sim N(\\bar u_{\\delta}, \\frac{\\sigma_u^2}{n_{\\delta}}) \\] where \\(\\bar u_{\\delta_i} = \\Sigma_{j \\in \\delta_i} u_j/n_{\\delta_i}\\) and where \\(\\delta_i\\) is the set of neighbors of area \\(i\\) and \\(n_{\\delta_i}\\) is the number of neighbors of area \\(i\\). In words, the logarithm of the disease incidence rate in area \\(i\\) conditional on the incidence rates in the neighborhood of \\(i\\) is modeled with a normal distribution centered on the neighborhood average (\\(\\bar u_{\\delta_i}\\)) with a variance scaled by the number of neighbors. This is called the conditional autoregressive (CAR) distribution. The model is fit using an application of Bayes rule through the method of integrated nested Laplace approximation (INLA), which results in posterior densities for the predicted relative risk. This is done with functions in the {INLA} package. You get the package (it is not on CRAN) as follows. options(timeout = 120) install.packages(&quot;INLA&quot;, repos=c(getOption(&quot;repos&quot;), INLA = &quot;https://inla.r-inla-download.org/R/stable&quot;), dep = TRUE) The syntax for the BYM model using functions from the {INLA} package is given as f &lt;- Y ~ f(IDu, model = &quot;besag&quot;, graph = g, scale.model = TRUE) + f(IDv, model = &quot;iid&quot;) The formula includes the response in the left-hand side, and the fixed and random effects on the right-hand side. By default, the formula includes an intercept. The random effects are set using f() with parameters equal to the name of the index variable, the model, and other options. The BYM formula includes a spatially structured random effect with index variable with name IDu and equal to c(1, 2, …, I), where I is the number of regions (here the number of counties) and model \"besag\" with a CAR distribution and with neighborhood structure given by the graph g. The option scale.model = TRUE is used to make the precision parameter of models with different CAR priors comparable. The formula also includes an uncorrelated random effect with index variable with name IDv again equal to c(1, 2, …, I), and model “iid”. This is an independent and identically distributed zero-mean normally distributed random effect. Note that both the ID variables are identical but need to be specified as two different objects since INLA does not allow to include two effects with f() that use the same index variable. The BYM model can also be specified with the model “bym” which defines both the spatially structured random effect and the uncorrelated random effect (\\(u\\) and \\(v\\)). You include these two vectors (call them idu and idv) in the data frame. LC.sf &lt;- LC.sf |&gt; dplyr::mutate(IDu = 1:nrow(LC.sf), IDv = 1:nrow(LC.sf)) LC.sf ## Simple feature collection with 67 features and 5 fields ## Geometry type: POLYGON ## Dimension: XY ## Bounding box: xmin: -80.53494 ymin: 39.72316 xmax: -74.72516 ymax: 42.26137 ## CRS: +proj=longlat ## First 10 features: ## geometry Y E SIR IDu IDv ## 1 POLYGON ((-77.4467 39.96954... 55 69.62730 0.7899200 1 1 ## 2 POLYGON ((-80.14534 40.6742... 1275 1182.42804 1.0782897 2 2 ## 3 POLYGON ((-79.21142 40.9091... 49 67.61012 0.7247435 3 3 ## 4 POLYGON ((-80.1568 40.85189... 172 172.55806 0.9967660 4 4 ## 5 POLYGON ((-78.38063 39.7288... 37 44.19013 0.8372910 5 5 ## 6 POLYGON ((-75.53303 40.4508... 308 300.70598 1.0242563 6 6 ## 7 POLYGON ((-78.11707 40.7373... 127 115.06965 1.1036793 7 7 ## 8 POLYGON ((-76.14609 42.0035... 59 53.23764 1.1082384 8 8 ## 9 POLYGON ((-74.97153 40.0554... 454 428.79748 1.0587749 9 9 ## 10 POLYGON ((-80.14534 40.6742... 158 134.79770 1.1721268 10 10 Create a graph object from a neighbor list object. Write the neighbor list object to a file then read it back in with the inla.read.graph() function. nb &lt;- spdep::poly2nb(LC.sf) spdep::nb2INLA(file = here::here(&quot;data&quot;, &quot;map.adj&quot;), nb) g &lt;- INLA::inla.read.graph(filename = here::here(&quot;data&quot;, &quot;map.adj&quot;)) class(g) ## [1] &quot;inla.graph&quot; You fit the model by calling the inla() function specifying the formula, the family (“poisson”), the data, and the expected counts (E). You also set control.predictor = list(compute = TRUE) to compute the posteriors predictions. model.inla &lt;- INLA::inla(formula = f, family = &quot;poisson&quot;, data = LC.sf, E = E, control.predictor = list(compute = TRUE)) The estimates of the relative risk of lung cancer and their uncertainty for each of the counties are given by the mean posterior and the 95% credible intervals which are contained in the object model.inla$summary.fitted.values. Column mean is the mean posterior and 0.025quant and 0.975quant are the 2.5 and 97.5 percentiles, respectively. You add these to the spatial data frame and then make a map of the posterior mean relative risk. LC.sf$RR &lt;- model.inla$summary.fitted.values[, &quot;mean&quot;] LC.sf$LL &lt;- model.inla$summary.fitted.values[, &quot;0.025quant&quot;] LC.sf$UL &lt;- model.inla$summary.fitted.values[, &quot;0.975quant&quot;] ggplot(LC.sf) + geom_sf(aes(fill = RR)) + scale_fill_gradient2(midpoint = 1, low = &quot;blue&quot;, mid = &quot;white&quot;, high = &quot;red&quot;) + theme_minimal() These relative risk values are smoother and muted in absolute magnitude compared with the empirical SIR estimates. More on this topic is available from https://www.paulamoraga.com/book-geospatial/index.html https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0166895 The second source is a paper we published addressing long and short term views of tornado risk across the eastern half of the United States. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
