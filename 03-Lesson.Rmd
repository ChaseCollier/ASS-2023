# Thursday January 19, 2023 {.unnumbered}

**"When I'm explaining some of the tidy verse principles and philosophy in R statistics, I often break down a home baked chunk of code and illustrate that 'it says what it does and it does what it says.'** --- Diane Beldame

Today

-   Working with data frames using base R
-   Getting data into R
-   Working with data frames using functions from {dplyr}

## Working with data frames using base R {.unnumbered}

Consider the data frame `studentdata` from the {LearnBayes} package. To access this data frame, first install the package with the `install.packages()` function.

You put the name of the package {LearnBayes} in quotes (single or double). Then to make the functions from the package available to your current session use the `library()` function with the name of the package (unquoted) inside the parentheses.

```{r}
if(!require(LearnBayes)) install.packages(pkgs = "LearnBayes", repos = "http://cran.us.r-project.org")

library(LearnBayes)
```

Note: The argument `repos =` in the `install.packages()` function directs where the package can be obtained on CRAN (comprehensive R archive network). The CRAN repository is set automatically when using RStudio and you can install packages by clicking on *Packages* \> *Install* in the lower-right panel.

For interactive use you need to specify the repository and when you use the `Knit` button you don't want to install packages that already exist on your computer so you add the conditional `if()` function that says "only install the package IF it is not (`!`) available".

Make a copy of the data frame by assigning it to an object with the name `df` and print the first six rows using the `head()` function.

```{r}
df <- studentdata
head(df)
```

Data frames are like spreadsheets with rows and columns. The rows are the observations (here each row is a student in an intro stats class at Bowling Green State University) and the columns are the variables. Here the variables are answers to questions like what is your height, choose a number between 1 and 10, what time did you go to bed last night, etc.

The names of the columns are printed using the `names()` function.

```{r}
names(df)
```

All columns are of the same length, but not all students answered all questions so some of the data frame cells contain the missing-value indicator `NA` (not available).

Data values in a data frame are stored in rows and columns and are accessed with bracket notation [row, column] where row is the row number and column is the column number like a matrix.

For example here you specify the data value in the 10th row and 2nd column (`Height` column) of the `df` data frame.

```{r}
df[10, 2]
```

By specifying only the row index and leaving the column index blank you get all values in that row, which corresponds to all the responses given by the 10th student.

```{r}
df[10, ]
```

Drink preference was one of the questions. Responses across all students are available in the column labeled `Drink` as a vector of character values. You list the various drink preferences by typing

```{r}
df$Drink
```

Some students left that response blank and therefore the response is coded with the missing-value indicator.

The variable type depends on the question asked. For example, answers given to the question of student height result in a numeric variable, answers given to the question about drink preference result in a character (or factor) variable.

For integer, character, and factor variables you summarize the set of responses with the `table()` function.

```{r}
table(df$Drink)
```

There are 113 students who prefer milk, 178 prefer soda, and 355 prefer water.

You can use the base R `plot()` method to make a draft plot of this table.

```{r}
plot(x = df$Drink)
```

Notice that the sum of the responses is `r sum(table(df$Drink))`, which is less than the total number of students (`r nrow(df)`).

Students who left that question blank are ignored in the `table()` function. To include the missing values you add the argument `useNA = "ifany"` to the `table()` function.

```{r}
table(df$Drink, 
      useNA = "ifany")
```

Note: When you want code executed directly within the text you separate the code using single back ticks. This is useful when you write reports that need periodic updates when new data becomes available. Instead if you hard code the values in the text then you need to search the document for these values during each update.

Suppose you are interested in examining how long students reported sleeping during the night. This was not asked directly. You compute it from the `ToSleep` and `WakeUp` times columns. You assign the result of the difference to a column we call `SleepHrs`.

```{r}
df$SleepHrs <- df$WakeUp - df$ToSleep
head(df)
```

Now you have a new numeric variable in the data frame called `SleepHrs`.

You can't table numeric variables, but the `summary()` method prints a set of summary statistics for the set of values.

```{r}
summary(df$SleepHrs)
```

The average number of hours slept is 7.4 with a maximum of 12.5 and a minimum of 2.5. There are four students that did not answer either when they went to sleep or when they woke up questions.

You use the `hist()` function to construct a histogram of sleep hours.

```{r}
hist(x = df$SleepHrs)
```

The histogram function divides the number of sleep hours into one-hour bins and counts the number of students whose reported sleep hours falls into each bin. For example based on when they said they went to sleep and when the said they woke up, about 100 students slept between five and six hours the night before the survey.

Since the gender of each student is reported, you can make comparisons between those who identify as male and those who identify as female. For instance, do men sleep more than women? You can answer this question graphically with box plots using the `plot()` method. You specify the character variable on the horizontal axis (x) to be gender with the `x =` argument and the numeric variable on the vertical axis (y) with the `y =` argument.

```{r}
plot(x = df$Gender, 
     y = df$SleepHrs)
```

The plot reveals little difference in the amount of sleep.

Repeat for hair cut prices.

```{r}
plot(x = df$Gender, 
     y = df$Haircut)
```

Big difference.

Finally, is the amount of sleep for a student related to when they go to bed? If you place numeric variables on the x and y axes then you get a scatter plot.

```{r}
plot(x = df$ToSleep,
     y = df$SleepHrs)
```

The `ToSleep` variable is centered on midnight so that -2 means a student went to sleep at 10p.

You describe the decreasing relationship with a line through the points. The least-squares line is fit using the `lm()` function and the line is drawn on the existing plot with the `abline()` function applied to the linear regression object `model`.

```{r}
model <- lm(SleepHrs ~ ToSleep, 
            data = df)

plot(x = df$ToSleep,
     y = df$SleepHrs)
abline(model)
```

## Getting data into R {-}

Most of the time you will start by getting your data stored in a file into R. Secondary source data should be imported directly from repositories on the Web. When there is no API (application programming interface) to the repository, you need to first download the data.

For example, consider the regularly updated reports of tornadoes in the United States. The data repository is the Storm Prediction Center (SPC) <https://www.spc.noaa.gov/wcm/index.html#data>.

Here you are interested in the file called `1950-2021_actual_tornadoes.csv`. First you download the file from the site with the `download.file()` function specifying the location (`url =`) and a name you want the file to be called on your computer (`destfile =`).

```{r}
download.file(url = "http://www.spc.noaa.gov/wcm/data/1950-2021_actual_tornadoes.csv",
              destfile = here::here("data", "Tornadoes.csv"))
```

A file called `Tornadoes.csv` should now be located in the directory `data`. Click on the *Files* tab in the lower-right panel, then select the `data` folder.

Next you read (import) the file as a data frame using the `readr::read_csv()` function from the {tidyverse} group of packages.

```{r}
Torn.df <- readr::read_csv(file = here::here("data", "Tornadoes.csv"))
```

You preview the data frame using the `head()` function.

```{r}
head(Torn.df)
```

Each row is a unique tornado report. Observations for each report include the day and time, the state (`st`), the maximum EF rating (`mag`), the number of injuries (`inj`), the number of fatalities (`fat`), estimated property losses (`loss`), estimated crop losses (`closs`), start and end locations in decimal degrees longitude and latitude, length of the damage path in miles (`len`), width of the damage in yards (`wid`).

The total number of tornado reports in the data set is returned using the `nrow()` function.

```{r}
nrow(Torn.df)
```

To create a subset of the data frame that contains only tornadoes in years (`yr`) since 2001, you include the logical operator `yr >= 2001` inside the subset operator. The logical operator is placed in front of the comma since you want all *rows* where the result of the operator returns a value `TRUE`.

```{r}
Torn2.df <- Torn.df[Torn.df$yr >= 2001, ]
```

You see that there are fewer rows (tornado reports) in this new data frame assigned the object name `Torn2.df`.

You subset again, keeping only tornadoes with EF ratings (`mag` variable) greater than zero. Here you *recycle* the name `Torn2.df`.

```{r}
Torn2.df <- Torn2.df[Torn2.df$mag > 0, ]
```

Now you compute the correlation between EF rating (`mag`) and path length (`len`) with the `cor()` function. The first argument is the vector of EF ratings and the second argument is the vector of path lengths.

```{r}
cor(Torn2.df$mag, Torn2.df$len)
```

Path length is recorded in miles and path width in yards and the EF damage rating variable `mag` is numeric. Here you convert path length to kilometers, path width to meters, and the EF rating to a factor and include these changes as new columns in the data frame.

```{r}
Torn2.df$Length <- Torn2.df$len * 1609.34
Torn2.df$Width <- Torn2.df$wid * .9144
Torn2.df$EF <- factor(Torn2.df$mag)
```

Create side-by-side box plots of path length (in kilometers) by EF rating.

```{r}
plot(x = Torn2.df$EF, 
     y = Torn2.df$Length/1000)
```

Example: Annual U.S. hurricane counts

Here you import the data directly from the Web by specifying the URL as a character string using the `file =` argument.

```{r}
loc <- "http://myweb.fsu.edu/jelsner/temp/data/US.txt"
USHur.df <- readr::read_table(file = loc)
```

The `dim()` function returns the size of the data frame defined as the number of rows and the number of columns.

```{r}
dim(USHur.df)
```

There are 166 rows and 6 columns in the data frame. Each row is a year and the columns include `Year`, number of hurricanes (`All`), number of major hurricanes (`MUS`), number of Gulf coast hurricanes (`G`), number of Florida hurricanes (`FL`), and number of East coast hurricanes (`E`) in that order.

To get a glimpse of the data values you list the first six lines of the data frame using the `head()` function.

```{r}
head(USHur.df)
```

The distribution of Florida hurricane counts by year is obtained using the `table()` function and specifying the `FL` column with `df$FL`.

```{r}
table(USHur.df$FL)
```

There are 93 years without a FL hurricane, 43 years with exactly one hurricane, 24 years with two hurricanes, and so on.

Example: Statewide average rainfall in Florida

The data are monthly statewide average rainfall (in inches) for Florida starting in 1895. The data were obtained from <http://www.esrl.noaa.gov/psd/data/timeseries/>. 

I put values into a text editor and then uploaded the file to the Web at location <http://myweb.fsu.edu/jelsner/temp/data/FLprecip.txt>.

You get the data into R with the `readr::read_table()` function. You assign the data object the name `FLp.df`. You type the name of the object to see that it is a tabled data frame (tibble) with 117 rows and 13 columns.

```{r}
loc <- "http://myweb.fsu.edu/jelsner/temp/data/FLprecip.txt"
FLp.df <- readr::read_table(file = loc)
FLp.df
```

The first column is the year and the next 12 columns are the months.

What was the statewide rainfall during June of 1900?

What happens when you check the column (vector) labeled `Year` to see what elements are equal to 1900?

```{r}
FLp.df$Year == 1900
```

Returns a vector with one element equal to `TRUE`.

What happens when we use this vector to select the vector of June rainfall values?

```{r}
FLp.df$Jun[FLp.df$Year == 1900]
```

What year had the wettest March?

```{r}
FLp.df$Mar

max(FLp.df$Mar)

which.max(FLp.df$Mar)

FLp.df$Year[which.max(FLp.df$Mar)]
```

What month during 1965 was the wettest? How wet was it?

```{r}
FLp.df$Year == 1965

FLp.df[FLp.df$Year == 1965, ]

which.max(FLp.df[FLp.df$Year == 1965, 2:12])

which.max(FLp.df[FLp.df$Year == 1965, 2:12])

max(FLp.df[FLp.df$Year == 1965, 2:12])
```

## Working with data frames using functions from {dplyr} {-}

The functions in the {dplyr} package (part of the tidyverse set of packages) simplify working with data frames. The functions work only on data frames.

Function names are English language *verbs* so they are easier to remember. The verbs help you translate thought into code.

Here we consider some of verbs using the `airquality` data frame. The data frame contains air quality measurements taken in New York City between May and September 1973 (`?airquality`) at time when pollution levels in the city were at an all time high.

```{r}
dim(airquality)
head(airquality)
```

The columns include `Ozone` (ozone concentration in ppb), `Solar.R` (solar radiation in langleys), `Wind` (wind speed in mph), `Temp` (air temperature in degrees F), `Month`, and `Day`.

You get summary statistics on the values in each column with the `summary()` method.

```{r}
summary(airquality)
```

Note that columns that have missing values are tabulated. For example, there are 37 missing ozone measurements and 7 missing radiation measurements.

Importantly for making your code more human readable you can apply the `summary()` function on the `airquality` data frame using the pipe operator (`|>`).

```{r}
airquality |> summary()
```

You read the pipe as THEN. "take the `airquality` data frame THEN summarize the columns".

The pipe operator allows you to string together functions that when read by a human makes it easy to understand what is being done.

Think of it this way: suppose the object of interest is called `me` and there is a function called `wake_up()`. I could apply this function called `wake_up()` in two ways.

```{r, eval=FALSE}
wake_up(me)  # way number one, classical way

me |> wake_up()  # way number two, tidyverse way
```

The second way involves more typing but it is easier to read (the subject comes before the predicate like simple English grammar) and thus easier to understand. This becomes clear when stringing together functions.

Continuing with the made-up example, what happens to the result of `me` after the function `wake_up()` has been applied? I `get_out_of_bed()` and then `get_dressed()`.

Again, you can apply these functions in two ways.

```{r, eval=FALSE}
get_dressed(get_out_of_bed(wake_up(me)))

me |>
  wake_up() |>
  get_out_of_bed() |>
  get_dressed()
```

The order of the functions usually matters to the outcome. I can't get dressed before I wake up but I could get dressed without getting out of bed.

Note how I format the code. Each line is gets only one verb and each line ends with the pipe (except the last one). This makes it easier to read.

Continuing...

```{r, eval=FALSE}
me |>
  wake_up() |>
  get_out_of_bed() |>
  get_dressed() |>
  make_coffee() |>
  drink_coffee() |>
  leave_house()
```

Which is much better in terms of 'readability' then `leave_house(drink_coffee(make_coffee(get_dressed(get_out_of_bed(wake_up(me))))))`.

Tibbles are data frames that make working with data frames a little easier. R is an old language, and some things that were useful 10 or 20 years ago now get in your way. To make a data frame a tibble (tabular data frame) use the `as_tibble()` function.

```{r}
class(airquality)
airquality <- dplyr::as_tibble(airquality)
class(airquality)
```

Click on `airquality` in the environment. It is a data frame. We will use the terms 'tibble' and 'data frame' interchangeably in this class.

Now you are ready to look at some of the commonly used verbs and to see how to apply them to a data frame.

The function `select()` chooses variables by name. For example, choose the month (`Month`), day (`Day`), and temperature (`Temp`) columns.

```{r}
airquality |>
  dplyr::select(Month, Day, Temp)
```

The result is a data frame containing only the three columns with column names listed in the `select()` function.

Suppose you want a new data frame with only the temperature and ozone concentrations. You include an assignment operator (`<-`) and an object name (here `df`).

```{r}
df <- airquality |>
        dplyr::select(Temp, Ozone)
df
```

The verbs take data frames as input and return data frames.

The function `filter()` chooses observations based on specific values. Suppose you want only the observations where the temperature is at or above 80 F.

```{r}
airquality |>
  dplyr::filter(Temp >= 80)
```

The result is a data frame with the same 6 columns but now only 73 observations. Each of the observations has a temperature of at least 80 F.

Suppose you want a new data frame keeping only observations when temperature is at least 80 F and when winds are less than 5 mph.

```{r}
df <- airquality |> 
  dplyr::filter(Temp >= 80 & Wind < 5)
df
```

The function `arrange()` orders the rows by values given in a particular column.

```{r}
airquality |>
  dplyr::arrange(Solar.R)
```

The ordering is done from the lowest value of radiation to highest value. Here you see the first 10 rows. Note `Month` and `Day` are no longer chronological.

Repeat, but order by the value of air temperature.

```{r}
airquality |>
  dplyr::arrange(Temp)
```

Importantly you can string the functions together. For example select the variables radiation, wind, and temperature then filter by temperatures above 90 F and arrange by temperature.

```{r}
airquality |>
  dplyr::select(Solar.R, Wind, Temp) |>
  dplyr::filter(Temp > 90) |>
  dplyr::arrange(Temp)
```

The result is a data frame with three columns and 14 rows arranged by increasing temperatures above 90 F.

The `mutate()` function adds new columns to the data frame. For example, create a new column called `TempC` as the temperature in degrees Celsius. Also create a column called `WindMS` as the wind speed in meters per second.

```{r}
airquality |>
  dplyr::mutate(TempC = (Temp - 32) * 5/9,
                WindMS = Wind * .44704) 
```

The resulting data frame has 8 columns (two new ones) labeled `TempC` and `WindMS`.

On days when the temperature is below 60 F add a column giving the apparent temperature based on the cooling effect of the wind (wind chill) and then arrange from coldest to warmest apparent temperature.

```{r}
airquality |>
  dplyr::filter(Temp < 60) |>
  dplyr::mutate(TempAp = 35.74 + .6215 * Temp - 35.75 * Wind^.16 + .4275 * Temp * Wind^.16) |>
  dplyr::arrange(TempAp)
```

The `summarize()` function reduces the data frame based on a function that computes a statistic. For example, to compute the average wind speed during July or the average temperature during June type

```{r}
airquality |>
  dplyr::filter(Month == 7) |>
  dplyr::summarize(Wavg = mean(Wind))

airquality |>
  dplyr::filter(Month == 6) |>
  dplyr::summarize(Tavg = mean(Temp))
```

You've seen functions that compute statistics including `sum()`, `sd()`, `min()`, `max()`, `var()`, `range()`, `median()`. Others include:

|      Summary function | Description               |
|----------------------:|:--------------------------|
|          `dplyr::n()` | Length of the column      |
|      `dplyr::first()` | First value of the column |
|       `dplyr::last()` | Last value of the column  |
| `dplyr::n_distinct()` | Number of distinct values |

Find the maximum and median wind speed and maximum ozone concentration values during the month of May. Also determine the number of observations during May.

```{r}
airquality |>
  dplyr::filter(Month == 5) |>
  dplyr::summarize(Wmax = max(Wind),
                   Wmed = median(Wind),
                   OzoneMax = max(Ozone),
                   NumDays = dplyr::n())
```

The result gives an `NA` for the maximum value of ozone (`OzoneMax`) because there is at least one missing value in the `Ozone` column. You fix this with the `na.rm = TRUE` argument in the function `max()`.

```{r}
airquality |>
  dplyr::filter(Month == 5) |>
  dplyr::summarize(Wmax = max(Wind),
                   Wmed = median(Wind),
                   OzoneMax = max(Ozone, na.rm = TRUE),
                   NumDays = dplyr::n())
```

If you want to summarize separately for each month you use the `group_by()` function. You split the data frame by some variable (e.g., `Month`), apply a function to the individual data frames, and then combine the output.

Find the highest ozone concentration by month. Include the number of observations (days) in the month.

```{r}
airquality |>
  dplyr::group_by(Month) |>
  dplyr::summarize(OzoneMax =  max(Ozone, na.rm = TRUE),
                   NumDays = dplyr::n())
```

Find the average ozone concentration when temperatures are above and below 70 F. Include the number of observations (days) in the two groups.

```{r}
airquality |>
  dplyr::group_by(Temp >= 70) |>
  dplyr::summarize(OzoneAvg =  mean(Ozone, na.rm = TRUE),
                   NumDays = dplyr::n())
```

On average ozone concentration is higher on warm days (Temp \>= 70 F) days. Said another way; mean ozone concentration statistically depends on temperature.

The mean is a model for the data. The statistical dependency of the mean implies that a model for ozone concentration will be improved by including temperature as an explanatory variable.

In summary, the important verbs are

|          Verb | Description                                                                    |
|--------------------------------------:|:--------------------------------|
|    `select()` | selects columns; pick variables by their names                                 |
|    `filter()` | filters rows; pick observations by their values                                |
|   `arrange()` | re-orders the rows                                                             |
|    `mutate()` | creates new columns; create new variables with functions of existing variables |
| `summarize()` | summarizes values; collapse many values down to a single summary               |
|  `group_by()` | allows operations to be grouped                                                |

The six functions form the basis of a grammar for data. You can only alter a data frame by reordering the rows (`arrange()`), picking observations and variables of interest (`filter()` and `select()`), adding new variables that are functions of existing variables (`mutate()`), collapsing many values to a summary (`summarise()`), and conditioning on variables (`group_by()`).

The syntax of the functions are all the same:

-   The first argument is a data frame. This argument is implicit when using the `|>` operator.
-   The subsequent arguments describe what to do with the data frame. You refer to columns in the data frame directly (without using `$`).
-   The result is a new data frame

These properties make it easy to chain together many simple lines of code to do complex data manipulations and summaries all while making it easy to read by humans.
