# Thursday September 1, 2022 {-}

**"Good coding style is like correct punctuation: you can manage without it, butitsuremakesthingseasiertoread."** --- Hadley Wickham

## Today {-}

- Making graphs

Working with data frames is part of the iterative cycle of data science, along with visualizing, and modeling.

The iterative cycle of data science:

1. Generate questions about our data.
2. Look for answers by visualizing and modeling the data after the data are in suitably arranged data frames.
3. Use what we learn to refine our questions and/or ask new ones.

Questions are tools to guide your investigation. When you ask a question, the question focuses your attention on a specific part of the data set and helps you decide what to do.

For additional practice working with data frames using functions from the {tidyverse} set of packages.

* See http://r4ds.had.co.nz/index.html
* Cheat sheets http://rstudio.com/cheatsheets

Before moving on, let's consider another data frame. The data frame contains observations on Palmer penguins and is available from https://education.rstudio.com/blog/2020/07/palmerpenguins-cran/. 

You import the data frame using the `read_csv()` function.
```{r}
loc <- "https://raw.githubusercontent.com/allisonhorst/palmerpenguins/master/inst/extdata/penguins.csv"
penguins <- read_csv(file = loc)
penguins
```

The observations are 344 individual penguins each described by species (Adelie, Chinstrap, Gentoo), where it was found (island name), length of bill (mm), depth of bill (mm), body mass (g), male or female, and year.

Each penguin belongs to one of three species. To see how many of the 344 penguins are in each species you use the `table()` function.
```{r}
table(penguins$species)
```

There are 152 Adelie, 68 Chinstrap, and 124 Gentoo penguins.

To create a data frame that includes only the female penguins you type
```{r}
( df <- penguins |> 
          filter(sex == "female") )
```
  
To create a data frame that includes only penguins that are not of species Adalie you type
```{r}
( df <- penguins |> 
          filter(species != "Adelie") )
```

To create a data frame containing only penguins that weigh more than 6000 grams you type
```{r}
( df <- penguins |> 
          filter(body_mass_g > 6000) )
```

To create a data frame with female penguins that have flippers longer than 220 mm we type
```{r}
( df <- penguins |> 
          filter(flipper_length_mm > 220 & 
                 sex == "female") )
```

To create a data frame containing rows where the bill length value is NOT missing.
```{r}
( df <- penguins |> 
          filter(!is.na(bill_length_mm)) )
```

Note that this filtering will keep rows with other column values missing values but there will be no penguins where the `bill_length` value is `NA`.

Finally, to compute the average bill length for each species.
```{r}
penguins |>
  group_by(species) |>
  summarize(AvgBL = mean(bill_length_mm, na.rm = TRUE))
```

## Making graphs {-}

The {ggplot2} package is a popular graphics tool among data scientists (e.g., New York Times and 538). It is built on principles of good data visualization.

1.  Mapping data to aesthetics
2.  Layering
3.  Building plots step by step

You make the functions available to our current working directory by typing
```{r}
if(!require(ggplot2)) install.packages(pkgs = "ggplot2", repos = "http://cran.us.r-project.org")

library(ggplot2)
```

Map data to aesthetics

Consider the following numeric vectors (`foo`, `bar` and `zaz`). Create a data frame `df` using the `data.frame()` function.
```{r}
foo <- c(-122.419416,-121.886329,-71.05888,-74.005941,-118.243685,-117.161084,-0.127758,-77.036871,
         116.407395,-122.332071,-87.629798,-79.383184,-97.743061,121.473701,72.877656,2.352222,
         77.594563,-75.165222,-112.074037,37.6173)

bar <- c(37.77493,37.338208,42.360083,40.712784,34.052234,32.715738,51.507351,38.907192,39.904211,
         47.60621,41.878114,43.653226,30.267153,31.230416,19.075984,48.856614,12.971599,39.952584,
         33.448377,55.755826)

zaz <- c(6471,4175,3144,2106,1450,1410,842,835,758,727,688,628,626,510,497,449,419,413,325,318)

df <- data.frame(foo, bar, zaz)

head(df)
```

To make a scatter plot using {ggplot2} syntax, you use the `ggplot()` function. Note that the package name is {ggplot2} but the function is `ggplot()` (without the 2).

Inside the `ggplot()` function you specify the data frame with the `data =` argument. You also specify what columns from the data frame are to be mapped to what 'aesthetics' with the `aes()` function using the `mapping =` argument. The `aes()` function is nested inside the `ggplot()` function or inside a layer function.

For a scatter plot the aesthetics must include the x and y coordinates at a minimum, and for this example they are in the columns labeled `foo` and `bar` respectively.

Then, to render the scatter plot, you include the function `geom_point()` as a layer with the `+` symbol. Numeric values are specified using the arguments `x =` and `y =` in the `aes()` function and are rendered as points on a plot.
```{r}
ggplot(data = df, 
       mapping = aes(x = foo, y = bar)) +
  geom_point()
```

You map data values to aesthetic attributes. The *points* in the scatter plot are geometric objects that get drawn. In {ggplot2} lingo, the points are *geoms*. More specifically, the points are point *geoms* that are denoted syntactically with the function `geom_point()`.

All geometric objects have aesthetic attributes (aesthetics):

-   x-position
-   y-position
-   color
-   size
-   transparency

You create a mapping between variables in your data frame and the aesthetic attributes of geometric objects. In the scatter plot you mapped `foo` to the x-position aesthetic and `bar` to the y-position aesthetic. This may seem trivial `foo` is the x-axis and `bar` is on the y-axis. You can do that in Excel.

Here there is a deeper structure. Theoretically, geometric objects (i.e., the things you draw in a plot, like points) don't just have attributes like position. They have a color, size, etc.

For example here you map a new variable to the size aesthetic.
```{r}
ggplot(data = df, 
       mapping = aes(x = foo, y = bar)) +
  geom_point(mapping = aes(size = zaz))
```

You changed the scatter plot to a bubble chart by mapping a new variable to the size aesthetic. Any visualization can be deconstructed into *geom* specifications and a mapping from data to the aesthetic attributes of the geometric objects.

Build plots in layers

The principle of layering is important. To create good visualizations you often need to:

-   Plot multiple datasets, or
-   Plot a dataset with additional contextual information contained in a second dataset, or
-   Plot summaries or statistical transformations over the raw data

Let's modify the bubble chart by getting additional data and plotting it as a new layer below the bubbles. First get the data from the {maps} package using the `map_data()` function and specifying the name of the map (here `"World"`) and assigning it to a data frame with the name `df2`.
```{r}
if(!require(maps)) install.packages(pkgs = "maps", repos = "http://cran.us.r-project.org")
library(maps)

library(tidyverse)

df2 <- map_data(map = "world") |>
  glimpse()
```

Plot the new data as a new layer underneath the bubbles.
```{r}
ggplot(data = df, 
       aes(x = foo, y = bar)) +
  geom_polygon(data = df2, 
               mapping = aes(x = long, y = lat, group = group)) +
  geom_point(mapping = aes(size = zaz), color = "red")
```

This is the same bubble chart but now with a new layer added. You changed the bubble chart into a new visualization called a "dot distribution map," which is more insightful and visually interesting.

The bubble chart is a modified scatter plot and the dot distribution map is a modified bubble chart.

You used two of the data visualization principles (mapping & layering) to build this plot:

-   To create the scatter plot, you mapped `foo` to the x-aesthetic and mapped `bar` to the y-aesthetic
-   To create the bubble chart, you mapped a `zaz` to the size-aesthetic
-   To create the dot distribution map, you added a layer of polygon data under the bubbles.

Iteration (step by step)

The third principle is about process. The graphing process begins with mapping and layering but ends with iteration when you add layers that modify scales, legends, colors, etc. The syntax of `ggplot` *layerability* enables and rewards iteration.

Instead of plotting the result of the above code for making a bubble chart, assign the result to an object called `p1`. Coping/paste the code from above then include the assignment operator `p1 <-`.
```{r}
p1 <- ggplot(data = df, 
             mapping = aes(x = foo, y = bar)) +
        geom_polygon(data = df2, 
                     mapping = aes(x = long, y = lat, group = group)) +
        geom_point(aes(size = zaz), color = "red")
```

Now modify the axes labels saving the new plot to an object called `p2`.
```{r}
( p2 <- p1 + xlab("Longitude") + ylab("Latitude") )
```

Next modify the scale label.
```{r}
p2 + scale_size_continuous(name = "Venture Capital Investment\n(USD, Millions)\n")
```

Of course you can do this all together with
```{r}
p1 + xlab("Longitude") + 
     ylab("Latitude") +
     scale_size_continuous(name = "Venture Capital Investment\n(USD, Millions)\n")
```

The `facet_wrap()` function is a layer to iterate (repeat) the entire plot conditional on another variable. It is like the `group_by()` function in the data grammar.

US tornadoes

Consider the tornado records in the file `Tornadoes.csv`. Import the data using the `read_csv()` function then create new columns called `Year`, `Month` and `EF` using the `mutate()` function.
```{r}
library(tidyverse)

( Torn.df <- read_csv(file = "Tornadoes.csv") |>
  mutate(Year = yr,
         Month = as.integer(mo),
         EF = mag) )
```

Next create a data frame (`df`) containing the number of tornadoes by year for the state of Kansas.
```{r}
( df <- Torn.df |>
  filter(st == "KS") |>
  group_by(Year) |>
  summarize(nT = n()) )
```

Then use the functions from the {ggplot2} package to plot the number of tornadoes by year using lines to connect the values in order of the variable on the x-axis. 
```{r}
ggplot(data = df,
       mapping = aes(x = Year, y = nT)) +
  geom_line()
```

Note: In the early production stage of research, I like to break the code into steps as above: (1) Import the data, (2) manipulate the data, and (3) plot the data. It is easier to document but it also introduces the potential for mistakes because of the intermediary objects in the environment (e.g., `Torn.df`, `df`). 

Below you bring together the above code to create the time series of Kansas tornado frequency without producing intermediary objects.
```{r, eval=FALSE}
read_csv(file = "Tornadoes.csv") |>
  mutate(Year = yr,
         Month = as.integer(mo),
         EF = mag) |>
  filter(st == "KS") |>
  group_by(Year) |>
  summarize(nT = n()) |>
ggplot(mapping = aes(x = Year, y = nT)) +
  geom_line() +
  geom_point()
```

Recall that the `group_by()` function allows you to repeat an operation depending on the value (or level) of some variable. For example to count the number of tornadoes by EF damage rating since 2007 and ignoring missing ratings
```{r}
Torn.df |>
  filter(Year >= 2007, EF != -9) |>
  group_by(EF) |>
  summarize(Count = n()) 
```

The result is a table listing the number of tornadoes grouped by EF rating.

Instead of printing the table, you create a bar chart using the `geom_col()` function.
```{r}
Torn.df |>
  filter(Year >= 2007, EF != -9) |>
  group_by(EF) |>
  summarize(Count = n()) |>
ggplot(mapping = aes(x = EF, y = Count)) +
  geom_col()
```

The `geom_bar()` function counts the number of cases at each x position so you don't need the `group_by()` and `summarize()` functions.
```{r}
Torn.df |>
  filter(Year >= 2007, EF != -9) |>
ggplot(mapping = aes(x = EF)) +
  geom_bar()
```

Improve the bar chart and to make it ready for publication.
```{r}
Torn.df |>
  filter(Year >= 2007, EF != -9) |>
  group_by(EF) |>
  summarize(Count = n()) |>
ggplot(mapping = aes(x = factor(EF), y = Count, fill = Count)) +
  geom_bar(stat = "identity") +
  xlab("EF Rating") + 
  ylab("Number of Tornadoes") +
  scale_fill_continuous(low = 'green', high = 'orange') +
  geom_text(aes(label = Count), vjust = -.5, size = 3) +
  theme_minimal() +
  theme(legend.position = 'none') 
```


You create a set of plots with the `facet_wrap()` function. Here you create a set of bar charts showing the frequency of tornadoes by EF rating for each year since 2004. 

You add the function after the `geom_bar()` layer and use the formula syntax (`~ Year`) inside the parentheses. You interpret the syntax as "plot bar charts conditioned on year."
```{r}
Torn.df |>
  filter(Year >= 2004, EF != -9) |>
ggplot(mapping = aes(x = factor(EF))) +
  geom_bar() +
  facet_wrap(~ Year)
```

Hot days in Tallahassee and Las Vegas

Let's consider another set of data. They are [daily weather data](http://www.ncdc.noaa.gov/cdo-web/datasets) from the Tallahassee International Airport.

Import the data.
```{r}
loc <- "http://myweb.fsu.edu/jelsner/temp/data/TLH_DailySummary.csv"
TLH.df <- read_csv(file = loc,
                     na = "-9999")
```

The warning concerns the column labeled `TOBS`. By default the column type is logical but there are cases when the values are numbers. This can be ignored safely.

The variable of interest is the daily high temperature in the column labeled `TMAX`. The values are in tens of degrees C so the value of 128 is 12.8 C.

Mutate to add new columns giving the temperatures (daily maximum and daily minimum) in degrees F (original measuring unit) and the dates in calendar days. Select only the date and maximum and minimum temperature columns.
```{r}
TLH.df <- TLH.df |>
  mutate(TmaxF = round(9/5 * TMAX/10 + 32),
         TminF = round(9/5 * TMIN/10 + 32),
         Date = as.Date(as.character(DATE), 
                        format = "%Y%m%d")) |>
  select(Date, TmaxF, TminF) |>
glimpse()
```

Note we use the `as.Date()` function ({base} see `?as.Date`). The format in the data file is a concatenation of a four-digit year, a two-digit month, and a two-digit day. Thus the format argument is `format = "%Y%m%d"`).

Q: Is it getting hotter in Tallahassee? Let's compute the annual average high temperature and create a time series graph.

We use the `year()` function from the {lubridate} package to get a column called `Year`, the `group_by()` function to group by `Year`, and the `summarize()` function from the {dplyr} package to get the average daily maximum temperature for each year.

```{r}
library(lubridate)

df <- TLH.df |>
  mutate(Year = year(Date)) |>
  group_by(Year) |>
  summarize(AvgT = mean(TmaxF)) |>
glimpse()
```

We now have a data frame with two columns: `Year` and `AvgT` (annual average daily high temperature in degrees F).

We now use functions from the {ggplot2} package to make a plot. We specify the x aesthetic as `Year` and the y aesthetic as the `AvgT`. We include a point layer and a line layer.
```{r}
ggplot(data = df, 
       mapping = aes(x = Year, y = AvgT)) +
  geom_point(size = 3) +
  geom_line() +
  ylab("Average Annual Temperature in Tallahassee, FL (F)")
```

Q: What's wrong? Fix and add a trend line layer. Here we go directly to the graph without saving the resulting data frame. That is, we pipe `|>` the resulting data frame after applying the {dplyr} verbs to the `ggplot()` function. The object in the first argument of the `ggplot()` function is the result (data frame) from the code above.
```{r}
TLH.df |>
  mutate(Year = year(Date)) |>
  filter(Year < 2014) |>
  group_by(Year) |>
  summarize(AvgT = mean(TmaxF)) |>
ggplot(mapping = aes(x = Year, y = AvgT)) +
  geom_point(size = 3) +
  geom_line() +
  ylab("Average Annual Temperature in Tallahassee, FL (F)") +
  geom_smooth() +
  theme_minimal()
```

Q: Is the frequency of extremely hot days increasing over time? Let's consider a daily high temperature of 100 F and above as extremely hot.

Here we count the number of days at or above 100F using the `summarize()` function together with the `sum()` function on the logical operator `>=`. If a day is missing a high temperature, we remove it with the `na.rm = TRUE` argument in the `sum()` function.
```{r}
TLH.df |>
  mutate(Year = year(Date)) |>
  filter(Year < 2014) |>
  group_by(Year) |>
  summarize(N100 = sum(TmaxF >= 100, na.rm = TRUE)) |>
ggplot(mapping = aes(x = Year, y = N100, fill = N100)) + 
  geom_bar(stat = 'identity') + 
  scale_fill_continuous(low = 'orange', high = 'red') +
  geom_text(aes(label = N100), vjust = 1.5, size = 3) +
  scale_x_continuous(breaks = seq(1950, 2013, 10)) +
  ylab(expression(paste("Number of days in Tallahassee, FL at or above 100", {}^o, " F"))) +
  theme_minimal() +
  theme(axis.text.x  = element_text(size = 11), legend.position = "none")
```

How does a histogram of daily high temperatures look?
```{r}
( gTLH <- ggplot(data = TLH.df, 
               mapping = aes(x = TmaxF)) + 
  geom_histogram(binwidth = 1, aes(fill = ..count..)) +
  scale_fill_continuous(low = 'green', high = 'blue') +
  scale_x_continuous(limits = c(30, 120)) +
  scale_y_continuous(limits = c(0, 1000)) +
  ylab("Number of Days") + 
  xlab(expression(paste("Daily High Temperature in Tallahassee, FL (", {}^o, " F)"))) +
  theme_minimal() +
  theme(legend.position = "none") )
```

Q: The most common high temperatures are in the low 90s, but there are relatively few 100+ days. Why?

Compare the histogram of daily high temperatures in Tallahassee with a histogram of daily high temperatures in Las Vegas, Nevada. Here we repeat the code above but for the data frame `LVG.df`. We then use the operators from the {patchwork} package to plot them side by side.
```{r}
LVG.df <- read_csv(file = "http://myweb.fsu.edu/jelsner/temp/data/LV_DailySummary.csv",
                     na = "-9999")

LVG.df <- LVG.df |>
  mutate(TmaxF = round(9/5 * TMAX/10 + 32),
         TminF = round(9/5 * TMIN/10 + 32),
         Date = as.Date(as.character(DATE), 
                        format = "%Y%m%d")) |>
  select(Date, TmaxF, TminF)

gLVG <- ggplot(data = LVG.df, 
               mapping = aes(x = TmaxF)) + 
  geom_histogram(binwidth = 1, aes(fill = ..count..)) +
  scale_fill_continuous(low = 'green', high = 'blue') +
  scale_x_continuous(limits = c(30, 120)) +
  scale_y_continuous(limits = c(0, 1000)) +
  ylab("Number of Days") + 
  xlab(expression(paste("Daily High Temperature in Las Vegas, NV (", {}^o, " F)"))) +
  theme_minimal() +
  theme(legend.position = "none")

#install.packages("patchwork")
library(patchwork)

gTLH / gLVG
```

US population and area by state

The object `us_states` from the {spData} package is a data frame from the U.S. Census Bureau. The variables include the state `GEOID` and `NAME`, the `REGION` (`South`, `West`, etc), `AREA` (in square km), and total population in 2010 (`total_pop_10`) and in 2015 (`total_pop_15`).
```{r}
library(sf)
library(spData)

class(us_states)
head(us_states)
```

The object `us_states` has two classes: simple feature and data frame. It is a data frame that has spatial information stored in the column labeled `geometry`. More about this next lesson.

Note also that the variable `AREA` is numeric with units (km\^2). Thus in order to perform some operations we need to specify units. For example, if we want to filter by area keeping only states with an area greater than 500,000 square km we need to use `set_units()` from the {units} package.
```{r}
us_states |> 
  filter(AREA > units::set_units(500000, km^2))
```

For now, suppose we want to plot area versus population for each state including state names on the plot. We note large differences between the minimum and maximum values for both variables.
```{r}
us_states |>
  summarize(rA = range(AREA),
            rP = range(total_pop_15))
```

Let's start with a simple scatter plot using logarithmic scales. The variable `AREA` has units so we convert it to a numeric with the `as.numeric()` function.
```{r}
ggplot(data = us_states,
       mapping = aes(x = as.numeric(AREA),
                     y = total_pop_15)) +
  geom_point() +
  scale_x_log10() +
  scale_y_log10()
```

Next we use the {scales} package so the tic labels can be expressed in whole numbers with commas.
```{r}
library(scales)

ggplot(data = us_states,
       mapping = aes(x = as.numeric(AREA),
                     y = total_pop_15)) +
  geom_point() +
  scale_x_log10(labels = comma) +
  scale_y_log10(labels = comma)
```

Next we add text labels. We can do this with `geom_text()` or `geom_label()`
```{r}
ggplot(data = us_states,
       mapping = aes(x = as.numeric(AREA),
                     y = total_pop_15)) +
  geom_point() +
  geom_text(aes(label = NAME)) +
  scale_x_log10(labels = comma) +
  scale_y_log10(labels = comma)
```

The labels are centered on top of the points. To fix this we use functions from the {grepel} package.
```{r}
library(ggrepel)

ggplot(data = us_states,
       mapping = aes(x = as.numeric(AREA),
                     y = total_pop_15)) +
  geom_point() +
  geom_text_repel(aes(label = NAME)) +
  scale_x_log10(labels = comma) +
  scale_y_log10(labels = comma)
```

Finally, since the data object is a simple feature data frame we can make a map.
```{r}
ggplot(us_states) + 
  geom_sf(aes(fill = total_pop_15)) +
  scale_fill_continuous(labels = comma)
```

## More resources and additional examples {-}

-   ggplot extensions <https://exts.ggplot2.tidyverse.org/>
-   Cheat sheets: <https://rstudio.com/resources/cheatsheets/>
-   More examples: <https://geocompr.robinlovelace.net/> {spData} package.
