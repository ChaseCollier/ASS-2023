# Thursday September 1, 2022 {.unnumbered}

**"Good coding style is like correct punctuation: you can manage without it, butitsuremakesthingseasiertoread."** --- Hadley Wickham

Today

-   Making graphs

Before moving on lets review what you learned last time.

Working with data frames is part of the cycle of data science, along with visualizing, and modeling. The cycle of data science:

1.  Generate questions about your data.
2.  Look for answers by visualizing and modeling the data after the data are in suitably arranged data frames.
3.  Use what you learn to refine your questions and/or ask new ones.

Questions are tools to guide your investigation. When you ask a question, the question focuses your attention on a specific part of the data and helps you decide what to do next.

Example: Penguins in the Antarctic. The data frame contains observations on Palmer penguins and is available from <https://education.rstudio.com/blog/2020/07/palmerpenguins-cran/>.

Import the data frame using the `read_csv()` function.

```{r}
loc <- "https://raw.githubusercontent.com/allisonhorst/palmerpenguins/master/inst/extdata/penguins.csv"

( penguins <- readr::read_csv(file = loc) )
```

The observations are 344 individual penguins each described by species (Adelie, Chinstrap, Gentoo), where it was found (island name), length of bill (mm), depth of bill (mm), body mass (g), male or female, and year.

Each penguin belongs to one of three species. To see how many of the 344 penguins are in each species you use the `table()` function.

```{r}
table(penguins$species)
```

There are 152 Adelie, 68 Chinstrap, and 124 Gentoo penguins.

To create a data frame that includes only the female penguins type

```{r}
( df <- penguins |> 
          dplyr::filter(sex == "female") )
```

To create a data frame that includes only penguins that are not of species Adalie you type

```{r}
( df <- penguins |> 
          dplyr::filter(species != "Adelie") )
```

To create a data frame containing only penguins that weigh more than 6000 grams you type

```{r}
( df <- penguins |> 
          dplyr::filter(body_mass_g > 6000) )
```

To create a data frame with female penguins that have flippers longer than 220 mm type

```{r}
( df <- penguins |> 
          dplyr::filter(flipper_length_mm > 220 &
                        sex == "female") )
```

To create a data frame containing rows where the bill length value is NOT missing type

```{r}
( df <- penguins |> 
          dplyr::filter(!is.na(bill_length_mm)) )
```

Note that this filtering will keep rows with other column values missing values but there will be no penguins where the `bill_length` value is `NA`.

Finally, to compute the average bill length for each species type

```{r}
penguins |>
  dplyr::group_by(species) |>
  dplyr::summarize(AvgBL = mean(bill_length_mm, na.rm = TRUE))
```

For more practice working with data frames using functions from the {tidyverse} set of packages.

-   See <http://r4ds.had.co.nz/index.html>
-   Cheat sheets <https://www.rstudio.com/resources/cheatsheets/>

## Making graphs {.unnumbered}

The {ggplot2} package is a popular graphics tool among data scientists (e.g., New York Times and 538). Functionality is built on principles of good data visualization.

1.  Map data to aesthetics
2.  Layer
3.  Build in steps

You make the functions available to your current working directory by typing

```{r}
library(ggplot2)
```

Consider the following numeric vectors (`foo`, `bar` and `zaz`). Create a data frame `df` using the `data.frame()` function.

```{r}
foo <- c(-122.419416,-121.886329,-71.05888,-74.005941,-118.243685,-117.161084,-0.127758,-77.036871,
         116.407395,-122.332071,-87.629798,-79.383184,-97.743061,121.473701,72.877656,2.352222,
         77.594563,-75.165222,-112.074037,37.6173)

bar <- c(37.77493,37.338208,42.360083,40.712784,34.052234,32.715738,51.507351,38.907192,39.904211,
         47.60621,41.878114,43.653226,30.267153,31.230416,19.075984,48.856614,12.971599,39.952584,
         33.448377,55.755826)

zaz <- c(6471,4175,3144,2106,1450,1410,842,835,758,727,688,628,626,510,497,449,419,413,325,318)

df <- data.frame(foo, bar, zaz)

head(df)
```

To make a scatter plot you use the `ggplot()` function. Note that the package name is {ggplot2} but the function is `ggplot()` (without the 2).

Inside the `ggplot()` function you first specify the data frame with the `data =` argument. You next specify what columns from the data frame are to be mapped to what 'aesthetics' with the `aes()` function using the `mapping =` argument. The `aes()` function is nested inside the `ggplot()` function or inside a layer function.

For a scatter plot the aesthetics must include the x and y coordinates. For this example they are in the columns labeled `foo` and `bar` respectively.

Then to render the scatter plot you include the function `geom_point()` as a layer with the `+` symbol. Numeric values are specified using the arguments `x =` and `y =` in the `aes()` function and are rendered as points on a plot.

```{r}
ggplot(data = df, 
       mapping = aes(x = foo, y = bar)) +
  geom_point()
```

You map data values to aesthetic attributes. The *points* in the scatter plot are geometric objects that get drawn. In {ggplot2} lingo, the points are *geoms*. More specifically, the points are point *geoms* that are denoted syntactically with the function `geom_point()`.

All geometric objects have aesthetic attributes (aesthetics):

-   x-position
-   y-position
-   color
-   size
-   transparency

You create a mapping between variables from your data frame to the aesthetic attributes of geometric objects. In the scatter plot you mapped `foo` to the x-position aesthetic and `bar` to the y-position aesthetic. This may seem trivial `foo` is the x-axis and `bar` is on the y-axis. You certainly can do that in Excel.

Here there is a deeper structure. Theoretically, geometric objects (i.e., the things you draw in a plot, like points) don't just have attributes like position. They have a color, size, etc.

For example here you map a new variable to the size aesthetic.

```{r}
ggplot2::ggplot(data = df, 
                mapping = ggplot2::aes(x = foo, y = bar)) +
  ggplot2::geom_point(mapping = ggplot2::aes(size = zaz))
```

You changed the scatter plot to a bubble chart by mapping a new variable to the size aesthetic. Any visualization can be deconstructed into *geom* specifications and a mapping from data to aesthetic attributes of the geometric objects.

The principle of layering is also important. To create good visualizations you often need to:

-   Plot multiple data sets, or
-   Plot data with additional contextual information contained in other data, or
-   Plot summaries or statistical transformations from the data

Let's modify the bubble chart by getting additional data and plotting it as a new layer below the bubbles. First get the data from the {ggplot2} package using the `map_data()` function and specifying the name of the map (here `"world"`) and assigning it to a data frame with the name `df2`.

```{r}
df2 <- ggplot2::map_data(map = "world") |>
  dplyr::glimpse()
```

Plot the new data as a new layer underneath the bubbles.

```{r}
ggplot(data = df, 
       mapping = aes(x = foo, y = bar)) +
  geom_polygon(data = df2, 
               mapping = aes(x = long, y = lat, group = group)) +
  geom_point(mapping = aes(size = zaz), color = "red")
```

This is the same bubble chart but now with a new layer added. You changed the bubble chart into a new visualization called a dot distribution map, which is more insightful and visually interesting.

The bubble chart is a modified scatter plot and the dot distribution map is a modified bubble chart.

You used two of the data visualization principles (mapping & layering) to build this plot:

-   To create the scatter plot, you mapped `foo` to the x-aesthetic and mapped `bar` to the y-aesthetic
-   To create the bubble chart, you mapped a `zaz` to the size-aesthetic
-   To create the dot distribution map, you added a layer of polygon data under the bubbles.

The third principle is about process. The graphing process begins with mapping and layering but ends with iteration when you add layers that modify scales, legends, colors, etc. The syntax of `ggplot` *layerability* enables and rewards iteration.

Instead of plotting the result of the above code for making a bubble chart, assign the result to an object called `p1`. Coping/paste the code from above but then include the assignment operator `p1 <-`.

```{r}
p1 <- ggplot(data = df, 
             mapping = aes(x = foo, y = bar)) +
        geom_polygon(data = df2, 
                     mapping = aes(x = long, y = lat, 
                                   group = group)) +
        geom_point(mapping = aes(size = zaz), color = "red")
```

Now modify the axes labels saving the new plot to an object called `p2`.

```{r}
( p2 <- p1 + xlab("Longitude") + ylab("Latitude") )
```

Next modify the scale label.

```{r}
p2 + scale_size_continuous(name = "Venture Capital Investment\n(USD, Millions)\n")
```

Of course you can do these steps together.

```{r}
p1 + xlab("Longitude") + 
     ylab("Latitude") +
     scale_size_continuous(name = "Venture Capital Investment\n(USD, Millions)\n")
```

The `facet_wrap()` function is a layer to iterate (repeat) the entire plot conditional on another variable. It is like the `dplyr::group_by()` function in the data grammar.

Example: U.S. tornadoes: Consider the tornado records in the file `Tornadoes.csv`. Import the data using the `readr::read_csv()` function then create new columns called `Year`, `Month` and `EF` using the `dplyr::mutate()` function.

```{r}
( Torn.df <- readr::read_csv(file = here::here("data", "Tornadoes.csv")) |>
  dplyr::mutate(Year = yr,
                Month = as.integer(mo),
                EF = mag) )
```

Next create a new data frame (`df`) that contains the number of tornadoes by year for the state of Kansas.
  
```{r}
( df <- Torn.df |>
  dplyr::filter(st == "KS") |>
  dplyr::group_by(Year) |>
  dplyr::summarize(nT = dplyr::n()) )
```

Then use the functions from the {ggplot2} package to plot the number of tornadoes by year using lines to connect the values in order of the variable on the x-axis.

```{r}
ggplot(data = df,
       mapping = aes(x = Year, y = nT)) +
  geom_line() +
  geom_point()
```

Note: In the early production stage of research, I like to break the code into steps as above: (1) Import the data, (2) manipulate the data, and (3) plot the data. It is easier to document but it  introduces the potential for mistakes because of the intermediary objects in the environment (e.g., `Torn.df`, `df`).

Below you bring together the above code to create the time series of Kansas tornado frequency without creating intermediary objects.

```{r, eval=FALSE}
readr::read_csv(file = here::here("data", "Tornadoes.csv")) |>
  dplyr::mutate(Year = yr,
                Month = as.integer(mo),
                EF = mag) |>
  dplyr::filter(st == "KS") |>
  dplyr::group_by(Year) |>
  dplyr::summarize(nT = dplyr::n()) |>
ggplot(mapping = aes(x = Year, y = nT)) +
  geom_line() +
  geom_point()
```

Recall that the `group_by()` function allows you to repeat an operation depending on the value (or level) of some variable. For example to count the number of tornadoes by EF damage rating since 2007 and ignoring missing ratings

```{r}
Torn.df |>
  dplyr::filter(Year >= 2007, EF != -9) |>
  dplyr::group_by(EF) |>
  dplyr::summarize(Count = dplyr::n()) 
```

The result is a table listing the number of tornadoes grouped by EF rating.

Instead of printing the table, you create a bar chart using the `geom_col()` function.

```{r}
Torn.df |>
  dplyr::filter(Year >= 2007, EF != -9) |>
  dplyr::group_by(EF) |>
  dplyr::summarize(Count = dplyr::n()) |>
ggplot(mapping = aes(x = EF, y = Count)) +
  geom_col()
```

The `geom_bar()` function counts the number of cases at each x position so you don't need the `group_by()` and `summarize()` functions.

```{r}
Torn.df |>
  dplyr::filter(Year >= 2007, EF != -9) |>
ggplot(mapping = aes(x = EF)) +
  geom_bar()
```

Improve the bar chart and to make it ready for publication.

```{r}
Torn.df |>
  dplyr::filter(Year >= 2007, EF != -9) |>
  dplyr::group_by(EF) |>
  dplyr::summarize(Count = dplyr::n()) |>
ggplot(mapping = aes(x = factor(EF), y = Count, fill = Count)) +
  geom_bar(stat = "identity") +
  xlab("EF Rating") + 
  ylab("Number of Tornadoes") +
  scale_fill_continuous(low = 'green', high = 'orange') +
  geom_text(aes(label = Count), vjust = -.5, size = 3) +
  theme_minimal() +
  theme(legend.position = 'none') 
```

You create a set of plots with the `facet_wrap()` function. Here you create a set of bar charts showing the frequency of tornadoes by EF rating for each year in the data set since 2004.

You add the function after the `geom_bar()` layer and use the formula syntax (`~ Year`) inside the parentheses. You interpret the syntax as "plot bar charts conditioned on the variable year."

```{r}
Torn.df |>
  dplyr::filter(Year >= 2004, EF != -9) |>
ggplot(mapping = aes(x = factor(EF))) +
  geom_bar() +
  facet_wrap(~ Year)
```

Example: Comparing hot days in Tallahassee and Las Vegas. The data are [daily weather observations](http://www.ncdc.noaa.gov/cdo-web/datasets) from the Tallahassee International Airport.

Import the data.

```{r}
loc <- "http://myweb.fsu.edu/jelsner/temp/data/TLH_Daily1940-2021.csv"
TLH.df <- readr::read_csv(file = loc)
```

The variables of interest are the daily high (and low) temperature in the column labeled `TMAX` (`TMIN`). The values are in degrees F.

Rename the columns then select only the date and temperature columns.

```{r}
TLH.df <- TLH.df |>
  dplyr::rename(TmaxF = TMAX,
                TminF = TMIN,
                Date = DATE) |>
  dplyr::select(Date, TmaxF, TminF) |>
  dplyr::glimpse()
```

Q: Based on these data, is it getting hotter in Tallahassee? Let's compute the annual average high temperature and create a time series graph.

You use the `year()` function from the {lubridate} package to get a column called `Year`. Since the data only has values through mid May 2022 you keep all observations with the `Year` column value less than 2021. You then use the `group_by()` function to group by `Year`, and the `summarize()` function to get the average daily maximum temperature for each year.

```{r}
df <- TLH.df |>
  dplyr::mutate(Year = lubridate::year(Date)) |>
  dplyr::filter(Year < 2022) |>
  dplyr::group_by(Year) |>
  dplyr::summarize(AvgT = mean(TmaxF, na.rm = TRUE)) |>
dplyr::glimpse()
```

You now have a data frame with two columns: `Year` and `AvgT` (annual average daily high temperature in degrees F). If a day is missing a value it is skipped when computing the average because of the `na.rm = TRUE` argument in the `mean()` function.

Next you use functions from the {ggplot2} package to make a time series graph. You specify the x aesthetic as `Year` and the y aesthetic as the `AvgT` and include point and line layers.

```{r}
ggplot(data = df, 
       mapping = aes(x = Year, y = AvgT)) +
  geom_point(size = 3) +
  geom_line() +
  ylab("Average Annual Temperature in Tallahassee, FL (F)")
```

You can go directly to the graph without saving the resulting data frame. That is, you pipe `|>` the resulting data frame after applying the {dplyr} verbs to the `ggplot()` function. The object in the first argument of the `ggplot()` function is the result (data frame) from the code above. Here you also add a smooth curve through the set of averages with the `geom_smooth()` layer.

```{r}
TLH.df |>
  dplyr::mutate(Year = lubridate::year(Date)) |>
  dplyr::filter(Year < 2022) |>
  dplyr::group_by(Year) |>
  dplyr::summarize(AvgT = mean(TmaxF, na.rm = TRUE)) |>
ggplot(mapping = aes(x = Year, y = AvgT)) +
  geom_point(size = 3) +
  geom_line() +
  ylab("Average Annual Temperature in Tallahassee, FL (F)") +
  geom_smooth() +
  theme_minimal()
```

Q: Is the frequency of extremely hot days increasing over time? Let's consider a daily high temperature of 100 F and above as extremely hot.

Here you count the number of days at or above 100F using the `summarize()` function together with the `sum()` function on the logical operator `>=`. If a day is missing a temperature, you remove it with the `na.rm = TRUE` argument in the `sum()` function.

```{r}
TLH.df |>
  dplyr::mutate(Year = lubridate::year(Date)) |>
  dplyr::filter(Year < 2022) |>
  dplyr::group_by(Year) |>
  dplyr::summarize(N100 = sum(TmaxF >= 100, na.rm = TRUE)) |>
ggplot(mapping = aes(x = Year, y = N100, fill = N100)) + 
  geom_bar(stat = 'identity') + 
  scale_fill_continuous(low = 'orange', high = 'red') +
  geom_text(aes(label = N100), vjust = 1.5, size = 3) +
  scale_x_continuous(breaks = seq(1940, 2020, 10)) +
  labs(title = expression(paste("Number of days in Tallahassee, Florida at or above 100", {}^o, " F")),
       subtitle = "",
       x = "", y = "") +
#  ylab(expression(paste("Number of days in Tallahassee, FL at or above 100", {}^o, " F"))) +
  theme_minimal() +
  theme(axis.text.x  = element_text(size = 11), legend.position = "none")
```

What does the histogram of daily high temperatures look like?

```{r}
( gTLH <- ggplot(data = TLH.df, 
               mapping = aes(x = TmaxF)) + 
  geom_histogram(binwidth = 1, aes(fill = ..count..)) +
  scale_fill_continuous(low = 'green', high = 'blue') +
  scale_x_continuous() +
  scale_y_continuous() +
  ylab("Number of Days") + 
  xlab(expression(paste("Daily High Temperature in Tallahassee, FL (", {}^o, " F)"))) +
  theme_minimal() +
  theme(legend.position = "none") )
```

Q: The most common high temperatures are in the low 90s, but there are relatively few 100+ days. Why?

Compare the histogram of daily high temperatures in Tallahassee with a histogram of daily high temperatures in Las Vegas, Nevada. Here you repeat the code above but for the data frame `LVG.df`.

```{r}
LVG.df <- readr::read_csv(file = "http://myweb.fsu.edu/jelsner/temp/data/LV_DailySummary.csv",
                          na = "-9999")

LVG.df <- LVG.df |>
  dplyr::mutate(TmaxF = round(9/5 * TMAX/10 + 32),
                TminF = round(9/5 * TMIN/10 + 32),
                Date = as.Date(as.character(DATE), 
                               format = "%Y%m%d")) |>
  dplyr::select(Date, TmaxF, TminF)

gLVG <- ggplot(data = LVG.df, 
               mapping = aes(x = TmaxF)) + 
  geom_histogram(binwidth = 1, aes(fill = ..count..)) +
  scale_fill_continuous(low = 'green', high = 'blue') +
  scale_x_continuous() +
  scale_y_continuous() +
  ylab("Number of Days") + 
  xlab(expression(paste("Daily High Temperature in Las Vegas, NV (", {}^o, " F)"))) +
  theme_minimal() +
  theme(legend.position = "none")
```

Then use the operators from the {patchwork} package to plot them side by side.

```{r}
if(!require(patchwork)) install.packages(pkgs = "patchwork", repos = "http://cran.us.r-project.org")

library(patchwork)

gTLH / gLVG
```

Example: US population and area by state. The object `us_states` from the {spData} package is a data frame from the U.S. Census Bureau. The variables include the state `GEOID` and `NAME`, the `REGION` (`South`, `West`, etc), `AREA` (in square km), and total population in 2010 (`total_pop_10`) and in 2015 (`total_pop_15`).

```{r}
us_states <- spData::us_states
class(us_states)
head(us_states)
```

The object `us_states` has two classes: simple feature and data frame. It is a data frame that has spatial information stored in the column labeled `geometry`. More about this next lesson.

Note also that the variable `AREA` is numeric with units (km\^2). Thus in order to perform some operations you need to specify units or convert the column using `as.numeric()`. For example, if you want to filter by area keeping only states with an area greater than 300,000 square km you could do the following

```{r, eval = FALSE}
us_states |> 
  dplyr::mutate(Area = as.numeric(AREA)) |>
  dplyr::filter(Area > 300000)
```

For now, suppose you want to plot area versus population for each state including state names on the plot. You note large differences between the minimum and maximum values for both variables.

```{r}
us_states |>
  dplyr::summarize(rA = range(AREA),
                   rP = range(total_pop_15))
```

Start with a simple scatter plot using logarithmic scales. The variable `AREA` has units so you convert it to a numeric with the `as.numeric()` function.

```{r}
ggplot(data = us_states,
       mapping = aes(x = as.numeric(AREA),
                     y = total_pop_15)) +
  geom_point() +
  scale_x_log10() +
  scale_y_log10()
```

Next use the {scales} package so the tic labels can be expressed in whole numbers with commas.

```{r}
ggplot(data = us_states,
       mapping = aes(x = as.numeric(AREA),
                     y = total_pop_15)) +
  geom_point() +
  scale_x_log10(labels = scales::comma) +
  scale_y_log10(labels = scales::comma)
```

Next add text labels. You can do this with `geom_text()` or `geom_label()`

```{r}
ggplot(data = us_states,
       mapping = aes(x = as.numeric(AREA),
                     y = total_pop_15)) +
  geom_point() +
  geom_text(aes(label = NAME)) +
  scale_x_log10(labels = scales::comma) +
  scale_y_log10(labels = scales::comma)
```

The labels are centered on top of the points. To fix this you use functions from the {grepel} package.

```{r}
ggplot(data = us_states,
       mapping = aes(x = as.numeric(AREA),
                     y = total_pop_15)) +
  geom_point() +
  ggrepel::geom_text_repel(aes(label = NAME)) +
  scale_x_log10(labels = scales::comma) +
  scale_y_log10(labels = scales::comma)
```

Finally, since the data object is a simple feature data frame you can make a map.

```{r}
ggplot() + 
  geom_sf(data = spData::us_states, 
          mapping = aes(fill = total_pop_15)) +
  scale_fill_continuous(labels = scales::comma) +
  theme_void()
```

More resources and additional examples

-   ggplot extensions <https://exts.ggplot2.tidyverse.org/>
-   Cheat sheets: <https://rstudio.com/resources/cheatsheets/>
-   More examples: <https://geocompr.robinlovelace.net/> {spData} package.
